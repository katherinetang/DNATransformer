{"cells":[{"cell_type":"code","execution_count":1,"id":"-VpJn0wO_fL6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30859,"status":"ok","timestamp":1733398321851,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"-VpJn0wO_fL6","outputId":"2504d6fc-ef8d-4307-d3b2-164fcb03516b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Link google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"7f8839ca-b2fc-4009-831a-97a7f6b2eaa2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88230,"status":"ok","timestamp":1733398418593,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"7f8839ca-b2fc-4009-831a-97a7f6b2eaa2","outputId":"d2125b98-cb76-45ec-fc3c-6c3df837283d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total size of combined dataset after filtering: 1294216\n","Training set size: 1292921\n","Test set size: 1295\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import torch\n","import numpy as np\n","\n","# Load all datasets\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database1_allstructs_34ave.pkl', 'rb') as file:\n","    database1_allstructs_34ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database2_allstructs_34ave.pkl', 'rb') as file:\n","    database2_allstructs_34ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database3_allstructs_34ave.pkl', 'rb') as file:\n","    database3_allstructs_34ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database4_1structsonly_34ave.pkl', 'rb') as file:\n","    database4_1structsonly_34ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database5_1structsonly_50ave.pkl', 'rb') as file:\n","    database5_1structsonly_50ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database6_allstructs_50ave.pkl', 'rb') as file:\n","    database6_allstructs_50ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database7_allstructs_50ave.pkl', 'rb') as file:\n","    database7_allstructs_50ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database9_allstructs_40ave.pkl', 'rb') as file:\n","    database9_allstructs_40ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database10_allstructs_40ave.pkl', 'rb') as file:\n","    database10_allstructs_40ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database11_allstructs_45ave.pkl', 'rb') as file:\n","    database11_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database13_allstructs_45ave.pkl', 'rb') as file:\n","    database13_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database14_allstructs_45ave.pkl', 'rb') as file:\n","    database14_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database15_allstructs_45ave.pkl', 'rb') as file:\n","    database15_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database16_allstructs_45ave.pkl', 'rb') as file:\n","    database16_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database17_allstructs_45ave.pkl', 'rb') as file:\n","    database17_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database18_allstructs_45ave.pkl', 'rb') as file:\n","    database18_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database19_allstructs_45ave.pkl', 'rb') as file:\n","    database19_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database20_allstructs_45ave.pkl', 'rb') as file:\n","    database20_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database21_allstructs_45ave.pkl', 'rb') as file:\n","    database21_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database22_allstructs_45ave.pkl', 'rb') as file:\n","    database22_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database23_allstructs_45ave.pkl', 'rb') as file:\n","    database23_allstructs_45ave = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database24_allstructs_45only.pkl', 'rb') as file:\n","    database24_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database25_allstructs_45only.pkl', 'rb') as file:\n","    database25_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database26_allstructs_45only.pkl', 'rb') as file:\n","    database26_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database27_allstructs_45only.pkl', 'rb') as file:\n","    database27_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database28_allstructs_45only.pkl', 'rb') as file:\n","    database28_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database29_allstructs_45only.pkl', 'rb') as file:\n","    database29_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database30_allstructs_45only.pkl', 'rb') as file:\n","    database30_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database31_allstructs_45only.pkl', 'rb') as file:\n","    database31_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database32_allstructs_45only.pkl', 'rb') as file:\n","    database32_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database33_allstructs_45only.pkl', 'rb') as file:\n","    database33_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database34_allstructs_45only.pkl', 'rb') as file:\n","    database34_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database35_allstructs_45only.pkl', 'rb') as file:\n","    database35_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database36_allstructs_45only.pkl', 'rb') as file:\n","    database36_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database37_allstructs_45only.pkl', 'rb') as file:\n","    database37_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database38_allstructs_45only.pkl', 'rb') as file:\n","    database38_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database39_allstructs_45only.pkl', 'rb') as file:\n","    database39_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database40_allstructs_45only.pkl', 'rb') as file:\n","    database40_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database41_allstructs_45only.pkl', 'rb') as file:\n","    database41_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database42_allstructs_45only.pkl', 'rb') as file:\n","    database42_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database43_allstructs_45only.pkl', 'rb') as file:\n","    database43_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database44_allstructs_45only.pkl', 'rb') as file:\n","    database44_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database45_allstructs_45only.pkl', 'rb') as file:\n","    database45_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database46_allstructs_45only.pkl', 'rb') as file:\n","    database46_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database47_allstructs_45only.pkl', 'rb') as file:\n","    database47_allstructs_45only = pickle.load(file)\n","\n","with open('/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/database48_allstructs_45only.pkl', 'rb') as file:\n","    database48_allstructs_45only = pickle.load(file)\n","\n","\n","# Combine datasets into a single dictionary\n","combined_data = {}\n","datasets = [\n","    database1_allstructs_34ave, database2_allstructs_34ave, database3_allstructs_34ave,\n","    database4_1structsonly_34ave, database5_1structsonly_50ave, database6_allstructs_50ave,\n","    database7_allstructs_50ave, database9_allstructs_40ave, database10_allstructs_40ave,\n","    database11_allstructs_45ave, database13_allstructs_45ave, database14_allstructs_45ave,\n","    database15_allstructs_45ave, database16_allstructs_45ave, database17_allstructs_45ave,\n","    database18_allstructs_45ave, database19_allstructs_45ave, database20_allstructs_45ave,\n","    database21_allstructs_45ave, database22_allstructs_45ave, database23_allstructs_45ave,\n","    database24_allstructs_45only, database25_allstructs_45only, database26_allstructs_45only,\n","    database27_allstructs_45only, database28_allstructs_45only, database29_allstructs_45only,\n","    database30_allstructs_45only, database31_allstructs_45only, database32_allstructs_45only,\n","    database33_allstructs_45only, database34_allstructs_45only, database35_allstructs_45only,\n","    database36_allstructs_45only, database37_allstructs_45only, database38_allstructs_45only,\n","    database39_allstructs_45only, database40_allstructs_45only, database41_allstructs_45only,\n","    database42_allstructs_45only, database43_allstructs_45only, database44_allstructs_45only,\n","    database45_allstructs_45only, database46_allstructs_45only, database47_allstructs_45only,\n","    database48_allstructs_45only\n","]\n","\n","for dataset in datasets:\n","    for seq, (temp, structs) in dataset.items():\n","        # Only include if melting temperature is defined and above 20\n","        if temp is not None:\n","            combined_data[seq] = (temp, structs)\n","\n","combined_data2 = {}\n","for i, j in combined_data.items():\n","    if len(i) == len(j[1][-1]):\n","        combined_data2[i] = j\n","\n","combined_data = combined_data2\n","\n","# Verify combined data size after filtering\n","print(f\"Total size of combined dataset after filtering: {len(combined_data)}\")\n","\n","# Prepare data for train-test split\n","sequences = list(combined_data.keys())\n","labels = list(combined_data.values())\n","\n","# Split data into training and test sets (80% training, 20% test)\n","train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n","    sequences, labels, test_size=0.001, random_state=42\n",")\n","\n","# Create train and test sets as dictionaries\n","train_set = {seq: label for seq, label in zip(train_sequences, train_labels)}\n","test_set = {seq: label for seq, label in zip(test_sequences, test_labels)}\n","\n","# Display the split summary\n","print(f\"Training set size: {len(train_set)}\")\n","print(f\"Test set size: {len(test_set)}\")\n"]},{"cell_type":"code","execution_count":3,"id":"d18845b5-4f8e-42fb-aace-c5a264d0b3fb","metadata":{"executionInfo":{"elapsed":2413,"status":"ok","timestamp":1733398434369,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"d18845b5-4f8e-42fb-aace-c5a264d0b3fb"},"outputs":[],"source":["dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n","top_structures = [train_set[seq][1] for seq in dna_sequences]"]},{"cell_type":"code","execution_count":4,"id":"23140db8-0bd2-48b5-a756-4a48cfa6d3f9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1733398436833,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"23140db8-0bd2-48b5-a756-4a48cfa6d3f9","outputId":"2424cac1-53af-4dc3-e17e-fa655dee0d08"},"outputs":[{"data":{"text/plain":["['AGGGGGATACATGTTTCTTATATAGAGTACGTGACGTGCCCTTTT',\n"," 'TCCTGGCGGTTCAAGGATACGATGCCTGCCTTCATTTTTGAGCGA',\n"," 'AAGCACTGCCTTCTCCTTATAACAACTATGTGTTATGTCTGTTTA',\n"," 'TATCTCAAACCACGGCTTTTCAACAAAATTGTGACGACATGCGCC',\n"," 'AGCGTAGTGGAGGTAGAAGTCTTTAAGGCGATCATCTTATCATCA',\n"," 'GTTAAGTATTGTCTCAGTAGACATGGTAGTACGCGTGGGATGAGG',\n"," 'CTGGCATTCTGTTGCCGAGCCCATTGGTGCATCGTCGTGACAGGG',\n"," 'GGTAGACGATACAGAGCTCGAATTCTGCTATGCTGGGACGCTCTG',\n"," 'GTAGCGAGAAGCTAAATGGCCCGAAACGTCTAGGAGTGTCCGGGC',\n"," 'CGGTGCGTCGGAGGATTGGGATCACTATCCATACGGGGGCTAATT']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dna_sequences[:10]"]},{"cell_type":"code","execution_count":5,"id":"5b0f2fef-8766-4b31-9e5d-52bd39902ac7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":890,"status":"ok","timestamp":1733398439048,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"5b0f2fef-8766-4b31-9e5d-52bd39902ac7","outputId":"2a2e819c-42e7-4138-ebd1-9ddf3f57bf57","scrolled":true},"outputs":[{"data":{"text/plain":["[['((((.....(((((.(((.....)))..))))).....))))...',\n","  '..(((.((.(((((.(((.....)))..)))))..)).)))....'],\n"," ['.((....))....(((........))).....((....)).....',\n","  '.(((.........)))................((....)).....',\n","  '....((((..............)))).((..(((....)))))..',\n","  '....(((......(((........))))))..((....)).....',\n","  '....(((((.((........))..)).)))..((....)).....',\n","  '....((((..............))))......((....)).....',\n","  '....((((((.............))).)))..((....)).....',\n","  '....(((((..((.........)).)))))..((....)).....'],\n"," ['.((............)).((((((......)))))).........',\n","  '.((.........))....((((((......)))))).........',\n","  '(((......)))......((((((......)))))).........',\n","  '..((...)).........((((((......)))))).........'],\n"," ['......(((........)))..(((....)))..((.....))..',\n","  '....................(((.....)))...((.....))..',\n","  '..........((((..((((....)))).)))).((.....))..',\n","  '......................(((....)))..((.....))..'],\n"," ['................((....)).....(((......)))....',\n","  '...............((.(((.....)))..))............',\n","  '..............(((.................)))........',\n","  '..(.....).....((....)).......(((......)))....',\n","  '................(((................))).......',\n","  '..............((....)).......(((.........))).',\n","  '..(((......................)))...............',\n","  '..(...).......((....)).......(((......)))....',\n","  '..............((....))..(((........))).......',\n","  '..............((....)).......(((......)))....'],\n"," ['...((...))((((....)))).......................',\n","  '..........((((....))))...((...)).............',\n","  '..........((((....)))).........(.........)...',\n","  '.....(((((((((....))))).....)))).............',\n","  '..........((((....))))........(....).........',\n","  '..........((((....))))...........((.....))...',\n","  '..........((((....)))).......................'],\n"," ['..((((......)))).........(...)...((....))....',\n","  '..((((......))))..((........)).....(......)..',\n","  '((((((......)))).))..............((....))....',\n","  '........((((((((((((........)).)))..)))))))..',\n","  '..((((......))))...(((.(...............)..)))',\n","  '..((((......)))).....((..............))......',\n","  '........((((...((((((....)))......)))..))))..',\n","  '..((((......))))...(((.....((...........)))))',\n","  '..(((.............)))............((....))....',\n","  '..((((......))))..((........))..(((....)).)..',\n","  '..((((......))))...(((..((.(((......))).)))))',\n","  '..((((......))))...(((..((..............)))))',\n","  '..((((......))))...((....))....((.....)).....',\n","  '..((((......)))).....((....))....((....))....',\n","  '..((((......))))...((....))..((......))......',\n","  '..((((......))))...(((....................)))',\n","  '..((((......))))...((....))......((....))....',\n","  '..((((......))))..((........))...((....))....'],\n"," ['.(((.....)))..(((..............)))...........',\n","  '......(((........)))...........((.(...)))....',\n","  '...........((.(((.........))).)).............',\n","  '...........((((........))))....((.(...)))....',\n","  '...........((((((..(...((.((...)).))..)))))))',\n","  '.(((.....)))..(((.........)))..((.(...)))....',\n","  '...........((((((((.................)).))))))',\n","  '...........((((((.......(.((...)).)....))))))',\n","  '...........((((((......................))))))'],\n"," ['..(((.....))).....((((((....)...........)))))',\n","  '......((...)).....(((((..((..........)).)))))',\n","  '(((((.....))))..).(((((..((..........)).)))))',\n","  '..(((.....))).....(((((..((....(....))).)))))',\n","  '..(((.....))).....(((((..........(.....))))))',\n","  '..(((.....))).....(((((..((..(.....).)).)))))',\n","  '..(((.....))).....(((((..((..........)).)))))'],\n"," ['......(((....)))..((((....))))...............',\n","  '....((.(((..((((..(.....).))))...)))..)).....',\n","  '.............(((....))).....((.....))........',\n","  '....((.(((..((((((....))..))))...)))..)).....',\n","  '((...))...........((((....))))...............',\n","  '....((.(((..((((..........))))...)))..)).....',\n","  '.....(((.(((.(((....)))....)))..)))..........',\n","  '.....(((.(((...............)))..)))..........',\n","  '........(...).....((((....))))...............',\n","  '((......))........((((....))))...............',\n","  '..................((((....))))...............']]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["top_structures[:10]"]},{"cell_type":"code","execution_count":6,"id":"57cdfc1c-f97a-446a-9b51-04d3017a6c99","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23559,"status":"ok","timestamp":1733398465813,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"57cdfc1c-f97a-446a-9b51-04d3017a6c99","outputId":"4f48620f-c79c-441c-f67f-9c3c4f1ceeb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","Number of sequences in dna_sequences:  777256\n"]},{"name":"stderr","output_type":"stream","text":["\u003cipython-input-6-0129c9c02453\u003e:91: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  class_weights = torch.load(\"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/class_weights_only45s.pt\").to(device)\n","\u003cipython-input-6-0129c9c02453\u003e:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  sample_weights = torch.load(\"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/sample_weights_only45s.pt\").to(device)\n"]},{"name":"stdout","output_type":"stream","text":["Sample weights stats:\n","Min: 0.1343396008014679, Max: 0.3759748339653015, Mean: 0.22687213122844696\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import OneCycleLR\n","from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n","from sklearn.model_selection import train_test_split\n","import torch.nn.utils as nn_utils\n","import numpy as np\n","\n","# Parameters\n","sequence_length = 45\n","embedding_dim = 256\n","num_heads = 8\n","ff_dim = 512\n","num_shared_transformer_blocks = 12\n","num_task_transformer_blocks = 6\n","dropout_rate = 0.2\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# One-hot encoding functions\n","def one_hot_encode_sequence(seq):\n","    \"\"\"\n","    One-hot encode a DNA sequence.\n","    \"\"\"\n","    mapping = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n","    encoded = np.zeros((len(seq), 4), dtype=np.float32)  # 4 possible bases\n","    for i, base in enumerate(seq):\n","        encoded[i, mapping[base]] = 1\n","    return encoded\n","\n","def one_hot_encode_structure(structure):\n","    \"\"\"\n","    One-hot encode a dot-bracket structure.\n","    \"\"\"\n","    structure_mapping = {'.': 0, '(': 1, ')': 2}\n","    encoded = np.zeros((len(structure), 3), dtype=np.float32)  # 3 possible symbols\n","    for i, char in enumerate(structure):\n","        encoded[i, structure_mapping[char]] = 1\n","    return encoded\n","\n","# Assume train_set is already defined\n","dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n","print(\"Number of sequences in dna_sequences: \", len(dna_sequences))\n","top_structures = [train_set[seq][1] for seq in dna_sequences]\n","\n","# One-hot encode DNA sequences\n","encoded_sequences = [one_hot_encode_sequence(seq) for seq in dna_sequences]\n","\n","# One-hot encode structures using the most favorable structure\n","encoded_structures = [one_hot_encode_structure(structs[-1]) for structs in top_structures]\n","\n","# Convert to tensors\n","X = torch.tensor(np.array(encoded_sequences), dtype=torch.float32)\n","y_struct = torch.tensor(np.array(encoded_structures), dtype=torch.float32)\n","\n","# Split into training and validation sets\n","X_train, X_val, y_struct_train, y_struct_val = train_test_split(X, y_struct, test_size=0.2, random_state=42)\n","\n","\"\"\"\n","class_counts = torch.tensor(\n","    [sum(struct.count(char) for struct in [\"\".join(top_struct) for top_struct in top_structures]) for char in \".()\"],\n","    dtype=torch.float32\n",")\n","\n","# Ensure no division by zero\n","total_count = class_counts.sum()\n","if total_count == 0 or any(class_counts == 0):\n","    raise ValueError(\"Class counts are invalid, resulting in division by zero.\")\n","\n","# Compute class weights (Inverse frequency weighting)\n","class_weights = total_count / (class_counts + 1e-5)\n","class_weights = class_weights / class_weights.sum()\n","class_weights = torch.clamp(class_weights, min=0)  # Ensure non-negative weights\n","class_weights = class_weights.to(device)\n","\n","# Create weighted sampler for the training set\n","sample_weights = []\n","for y in y_struct_train:\n","    # Convert one-hot encoded structure to class indices\n","    valid_indices = torch.argmax(y, dim=1).long()  # Extract class indices (e.g., 0, 1, 2 for '.', '(', ')')\n","    weight = [class_weights[class_idx].item() for class_idx in valid_indices]\n","    sample_weights.append(sum(weight) / len(weight))  # Average weight for the sequence\n","\n","# Convert to tensor and validate\n","sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n","sample_weights = torch.nan_to_num(sample_weights, nan=1.0, posinf=1.0, neginf=1.0)  # Replace NaN/infs with default value\n","sample_weights = torch.clamp(sample_weights, min=0)  # Ensure weights are non-negative\"\"\"\n","\n","class_weights = torch.load(\"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/class_weights_only45s.pt\").to(device)\n","sample_weights = torch.load(\"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/sample_weights_only45s.pt\").to(device)\n","\n","\n","# Debugging: Print sample weights stats\n","print(\"Sample weights stats:\")\n","print(f\"Min: {sample_weights.min()}, Max: {sample_weights.max()}, Mean: {sample_weights.mean()}\")\n","assert torch.all(sample_weights \u003e= 0), \"Sample weights contain negative values!\"\n","assert not torch.any(torch.isnan(sample_weights)), \"Sample weights contain NaN values!\"\n","\n","# Create sampler\n","sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","# Create DataLoaders\n","train_dataset = TensorDataset(X_train, y_struct_train)\n","val_dataset = TensorDataset(X_val, y_struct_val)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n","val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":7,"id":"04f965f5-1330-4772-8776-d457d9a96807","metadata":{"executionInfo":{"elapsed":4282,"status":"ok","timestamp":1733398524735,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"04f965f5-1330-4772-8776-d457d9a96807"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import OneCycleLR\n","from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n","import torch.nn.utils as nn_utils\n","\n","\n","# Model Definition\n","class TransformerEncoderBlockWithPairingAttention(nn.Module):\n","    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.2, sequence_length=45):\n","        super(TransformerEncoderBlockWithPairingAttention, self).__init__()\n","        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n","        self.pairing_bias = nn.Parameter(torch.randn(sequence_length, sequence_length))\n","        self.ffn = nn.Sequential(\n","            nn.Linear(embed_dim, ff_dim),\n","            nn.ReLU(),\n","            nn.Linear(ff_dim, embed_dim)\n","        )\n","        self.layernorm1 = nn.LayerNorm(embed_dim)\n","        self.layernorm2 = nn.LayerNorm(embed_dim)\n","        self.dropout1 = nn.Dropout(dropout)\n","        self.dropout2 = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        attn_output, _ = self.self_attn(x, x, x)\n","        q, k, v = x, x, x\n","        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (q.size(-1) ** 0.5)\n","        seq_len = q.size(1)\n","        pairing_bias_resized = self.pairing_bias[:seq_len, :seq_len]\n","        pairing_bias_resized = pairing_bias_resized.unsqueeze(0).expand(x.size(0), -1, -1).to(x.device)\n","        attn_scores = attn_scores + pairing_bias_resized\n","        attn_weights = F.softmax(attn_scores, dim=-1)\n","        paired_attn_output = torch.matmul(attn_weights, v)\n","        x = x + self.dropout1(attn_output + paired_attn_output)\n","        x = self.layernorm1(x)\n","        x = x + self.dropout2(self.ffn(x))\n","        x = self.layernorm2(x)\n","        return x\n","\n","\n","class StructurePredictor(nn.Module):\n","    def __init__(self, sequence_length, embedding_dim, num_heads, ff_dim, num_shared_blocks, num_task_blocks):\n","        super(StructurePredictor, self).__init__()\n","        self.embedding_layer = nn.Linear(4, embedding_dim)  # Map one-hot DNA input to embedding_dim\n","        self.positional_encoding = self.create_sinusoidal_positional_encoding(sequence_length, embedding_dim)\n","        self.shared_transformer_blocks = nn.ModuleList([\n","            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=sequence_length)\n","            for _ in range(num_shared_blocks)\n","        ])\n","        self.struct_transformer_blocks = nn.ModuleList([\n","            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=sequence_length)\n","            for _ in range(num_task_blocks)\n","        ])\n","        self.structure_head = nn.Sequential(\n","            nn.LayerNorm(embedding_dim),\n","            nn.Linear(embedding_dim, 3)  # Predict probabilities for ., (, )\n","        )\n","\n","    def create_sinusoidal_positional_encoding(self, seq_len, d_model):\n","        pos = torch.arange(0, seq_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n","        pos_enc = torch.zeros(seq_len, d_model)\n","        pos_enc[:, 0::2] = torch.sin(pos * div_term)\n","        pos_enc[:, 1::2] = torch.cos(pos * div_term)\n","        return pos_enc\n","\n","    def forward(self, x):\n","        device = x.device  # Get the device of input tensor\n","        positional_encoding = self.positional_encoding.to(device)  # Move to same device\n","\n","        # Map one-hot input to embedding space\n","        x = self.embedding_layer(x)\n","\n","        # Combine embedded input with positional encoding\n","        x = x + positional_encoding\n","        x = x.permute(1, 0, 2)  # Permute for transformer compatibility\n","\n","        # Shared Transformer blocks\n","        for block in self.shared_transformer_blocks:\n","            x = block(x)\n","\n","        # Task-specific Transformer blocks\n","        for block in self.struct_transformer_blocks:\n","            x = block(x)\n","\n","        # Output layers\n","        output = self.structure_head(x.permute(1, 0, 2))  # Permute back to original shape\n","        return output\n","\n","\n","class RewardedThermodynamicallyBalancedCategoricalCrossEntropy(nn.Module):\n","    def __init__(self, weights, pairing_penalty=0.2, thermo_penalty=0.3, specificity_reward=0.05):\n","        super(RewardedThermodynamicallyBalancedCategoricalCrossEntropy, self).__init__()\n","        self.weights = weights\n","        self.pairing_penalty = pairing_penalty\n","        self.thermo_penalty = thermo_penalty\n","        self.specificity_reward = specificity_reward\n","\n","    def forward(self, y_pred, y_true):\n","        # Mask valid indices\n","        mask = (y_true.sum(dim=-1) != 0)  # Mask entries where y_true is non-zero in any class\n","        y_pred_masked = y_pred[mask]\n","        y_true_masked = y_true[mask]\n","\n","        # Compute weighted categorical cross-entropy\n","        log_probs = F.log_softmax(y_pred_masked, dim=-1)\n","        loss = -torch.sum(self.weights * y_true_masked * log_probs, dim=-1).mean()\n","\n","        # Compute pairing imbalance penalty\n","        pred_labels = torch.argmax(y_pred_masked, dim=-1)\n","        true_labels = torch.argmax(y_true_masked, dim=-1)\n","        open_count = (pred_labels == 1).sum().float()\n","        close_count = (pred_labels == 2).sum().float()\n","        imbalance_penalty = self.pairing_penalty * torch.abs(open_count - close_count)\n","\n","        # Compute thermodynamic penalty for mismatches\n","        mismatch_penalty = ((pred_labels == 1) \u0026 (true_labels == 2)).sum().float() * self.thermo_penalty\n","\n","        # Compute specificity reward for correct pairings\n","        correct_pairings = ((pred_labels == true_labels) \u0026 ((true_labels == 1) | (true_labels == 2))).sum().float()\n","        specificity_reward = self.specificity_reward * correct_pairings\n","\n","        # Total loss\n","        total_loss = loss + imbalance_penalty + mismatch_penalty - specificity_reward\n","        return total_loss\n","\n","\n","\n","# Instantiate model and loss function\n","model = StructurePredictor(sequence_length, embedding_dim, num_heads, ff_dim, num_shared_transformer_blocks, num_task_transformer_blocks).to(device)\n","loss_fn_struct = RewardedThermodynamicallyBalancedCategoricalCrossEntropy(class_weights)\n","\n","# Optimizer and scheduler\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n","\n","# Training loop with early stopping and metrics\n","best_val_loss = float(\"inf\")\n","patience = 100\n","patience_counter = 0\n","\n","def calculate_class_metrics(y_true, y_pred, num_classes=3):\n","    metrics = {}\n","    for class_idx in range(num_classes):\n","        tp = ((y_pred == class_idx) \u0026 (y_true == class_idx)).sum().item()\n","        fp = ((y_pred == class_idx) \u0026 (y_true != class_idx)).sum().item()\n","        fn = ((y_pred != class_idx) \u0026 (y_true == class_idx)).sum().item()\n","        precision = tp / (tp + fp) if tp + fp \u003e 0 else 0\n","        recall = tp / (tp + fn) if tp + fn \u003e 0 else 0\n","        f1 = 2 * precision * recall / (precision + recall) if precision + recall \u003e 0 else 0\n","        metrics[class_idx] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n","    return metrics\n","\n","def print_validation_metrics(val_metrics, printer=True):\n","\n","    # Initialize a variable to store the sum of F1 scores\n","    total_f1 = 0\n","    num_classes = len(val_metrics)\n","\n","    # Print metrics for each class\n","    for cls, metrics in val_metrics.items():\n","        if printer==True:\n","            print(f\"Class {cls} - Precision: {metrics['precision']:.4f}, \"\n","                  f\"Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1']:.4f}\")\n","        total_f1 += metrics['f1']\n","\n","    # Calculate the average F1 score\n","    avg_f1 = total_f1 / num_classes if num_classes \u003e 0 else 0.0\n","\n","    return avg_f1"]},{"cell_type":"code","execution_count":8,"id":"e7d5519d-6457-4ca3-8de0-3a1d750ad502","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1733336732887,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"e7d5519d-6457-4ca3-8de0-3a1d750ad502","outputId":"fd3f8972-c2e9-48c0-e623-976a2c72c22d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# Save sample weights\\ntorch.save(sample_weights, \"sample_weights_onehot.pt\")\\n\\n# Load sample weights\\ntorch.save(class_weights, \"class_weights_onehot.pt\")\\n'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","# Save sample weights\n","torch.save(sample_weights, \"sample_weights_onehot.pt\")\n","\n","# Load sample weights\n","torch.save(class_weights, \"class_weights_onehot.pt\")\n","\"\"\""]},{"cell_type":"code","execution_count":7,"id":"6f7a4014-35f5-4431-b51c-f349c75001ef","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1733368146245,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"6f7a4014-35f5-4431-b51c-f349c75001ef","outputId":"6cc2d80d-2311-4ae8-bede-057a5bf0cbef"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nscheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\\nmodel_path = \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2-onehotenc.pth\"\\nmodel.load_state_dict(torch.load(model_path, map_location=device))'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Only run this cell if the gradients explode!\n","\"\"\"\n","scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n","model_path = \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2-onehotenc.pth\"\n","model.load_state_dict(torch.load(model_path, map_location=device))\"\"\""]},{"cell_type":"code","execution_count":8,"id":"gfT9b2C5xx4e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5448,"status":"ok","timestamp":1733398650466,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"gfT9b2C5xx4e","outputId":"d3108d85-e0d1-4a2c-9381-31043d6783bd"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-8-56e159cf6aa8\u003e:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path, map_location=device))\n"]},{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model_path = \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc.pth\"\n","model.load_state_dict(torch.load(model_path, map_location=device))"]},{"cell_type":"code","execution_count":null,"id":"ab17b5c5-554d-4d1d-8070-50167f6a4b9e","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ab17b5c5-554d-4d1d-8070-50167f6a4b9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Training Loss: -14.7909, Accuracy: 0.7669, F1: 0.7399\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0013\n","struct_transformer_blocks: 0.0187\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9564, Recall: 0.7210, F1-Score: 0.8222\n","Class 1 - Precision: 0.5972, Recall: 0.8897, F1-Score: 0.7147\n","Class 2 - Precision: 0.5949, Recall: 0.8886, F1-Score: 0.7127\n","Validation Loss: -15.4906, Accuracy: 0.7771, F1: 0.7499\n","Best model saved with validation loss: -15.4906\n","\n","\n","Epoch 2, Training Loss: -14.9087, Accuracy: 0.7688, F1: 0.7421\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0009\n","shared_transformer_blocks: 0.0013\n","struct_transformer_blocks: 0.0191\n","structure_head: 0.0185\n","Class 0 - Precision: 0.9569, Recall: 0.7225, F1-Score: 0.8234\n","Class 1 - Precision: 0.6001, Recall: 0.8909, F1-Score: 0.7171\n","Class 2 - Precision: 0.5956, Recall: 0.8901, F1-Score: 0.7137\n","Validation Loss: -15.5020, Accuracy: 0.7785, F1: 0.7514\n","Best model saved with validation loss: -15.5020\n","\n","\n","Epoch 3, Training Loss: -14.9588, Accuracy: 0.7700, F1: 0.7432\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0013\n","struct_transformer_blocks: 0.0193\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9570, Recall: 0.7223, F1-Score: 0.8232\n","Class 1 - Precision: 0.5979, Recall: 0.8929, F1-Score: 0.7162\n","Class 2 - Precision: 0.5975, Recall: 0.8884, F1-Score: 0.7144\n","Validation Loss: -15.4574, Accuracy: 0.7784, F1: 0.7513\n","\n","\n","Epoch 4, Training Loss: -14.9602, Accuracy: 0.7707, F1: 0.7439\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0013\n","struct_transformer_blocks: 0.0195\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9562, Recall: 0.7307, F1-Score: 0.8284\n","Class 1 - Precision: 0.6052, Recall: 0.8906, F1-Score: 0.7207\n","Class 2 - Precision: 0.6038, Recall: 0.8880, F1-Score: 0.7188\n","Validation Loss: -15.5440, Accuracy: 0.7836, F1: 0.7560\n","Best model saved with validation loss: -15.5440\n","\n","\n","Epoch 5, Training Loss: -14.9875, Accuracy: 0.7717, F1: 0.7448\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0013\n","struct_transformer_blocks: 0.0197\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9580, Recall: 0.7237, F1-Score: 0.8245\n","Class 1 - Precision: 0.5996, Recall: 0.8932, F1-Score: 0.7175\n","Class 2 - Precision: 0.5995, Recall: 0.8920, F1-Score: 0.7171\n","Validation Loss: -15.6376, Accuracy: 0.7800, F1: 0.7530\n","Best model saved with validation loss: -15.6376\n","\n","\n","Epoch 6, Training Loss: -15.0040, Accuracy: 0.7718, F1: 0.7450\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0013\n","struct_transformer_blocks: 0.0198\n","structure_head: 0.0185\n","Class 0 - Precision: 0.9588, Recall: 0.7208, F1-Score: 0.8229\n","Class 1 - Precision: 0.6006, Recall: 0.8935, F1-Score: 0.7183\n","Class 2 - Precision: 0.5949, Recall: 0.8948, F1-Score: 0.7146\n","Validation Loss: -15.6849, Accuracy: 0.7786, F1: 0.7520\n","Best model saved with validation loss: -15.6849\n","\n","\n","Epoch 7, Training Loss: -15.0713, Accuracy: 0.7728, F1: 0.7461\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0200\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9568, Recall: 0.7304, F1-Score: 0.8284\n","Class 1 - Precision: 0.6062, Recall: 0.8908, F1-Score: 0.7215\n","Class 2 - Precision: 0.6029, Recall: 0.8899, F1-Score: 0.7188\n","Validation Loss: -15.6633, Accuracy: 0.7838, F1: 0.7562\n","\n","\n","Epoch 8, Training Loss: -15.0698, Accuracy: 0.7735, F1: 0.7467\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0201\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9575, Recall: 0.7305, F1-Score: 0.8287\n","Class 1 - Precision: 0.6057, Recall: 0.8925, F1-Score: 0.7216\n","Class 2 - Precision: 0.6047, Recall: 0.8913, F1-Score: 0.7206\n","Validation Loss: -15.8064, Accuracy: 0.7843, F1: 0.7570\n","Best model saved with validation loss: -15.8064\n","\n","\n","Epoch 9, Training Loss: -15.0642, Accuracy: 0.7735, F1: 0.7468\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0201\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9600, Recall: 0.7217, F1-Score: 0.8240\n","Class 1 - Precision: 0.5991, Recall: 0.8993, F1-Score: 0.7192\n","Class 2 - Precision: 0.5993, Recall: 0.8935, F1-Score: 0.7174\n","Validation Loss: -15.5591, Accuracy: 0.7800, F1: 0.7535\n","\n","\n","Epoch 10, Training Loss: -15.1424, Accuracy: 0.7748, F1: 0.7481\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0202\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9575, Recall: 0.7358, F1-Score: 0.8322\n","Class 1 - Precision: 0.6111, Recall: 0.8936, F1-Score: 0.7258\n","Class 2 - Precision: 0.6083, Recall: 0.8899, F1-Score: 0.7226\n","Validation Loss: -15.5859, Accuracy: 0.7878, F1: 0.7602\n","\n","\n","Epoch 11, Training Loss: -15.1992, Accuracy: 0.7752, F1: 0.7486\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0011\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0202\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9601, Recall: 0.7220, F1-Score: 0.8242\n","Class 1 - Precision: 0.5998, Recall: 0.8984, F1-Score: 0.7194\n","Class 2 - Precision: 0.5989, Recall: 0.8941, F1-Score: 0.7173\n","Validation Loss: -15.7289, Accuracy: 0.7801, F1: 0.7536\n","\n","\n","Epoch 12, Training Loss: -15.1656, Accuracy: 0.7764, F1: 0.7496\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0202\n","structure_head: 0.0186\n","Class 0 - Precision: 0.9601, Recall: 0.7275, F1-Score: 0.8278\n","Class 1 - Precision: 0.6047, Recall: 0.8980, F1-Score: 0.7227\n","Class 2 - Precision: 0.6039, Recall: 0.8956, F1-Score: 0.7214\n","Validation Loss: -15.8016, Accuracy: 0.7840, F1: 0.7573\n","\n","\n","Epoch 13, Training Loss: -15.2242, Accuracy: 0.7771, F1: 0.7504\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0011\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0202\n","structure_head: 0.0185\n","Class 0 - Precision: 0.9604, Recall: 0.7281, F1-Score: 0.8283\n","Class 1 - Precision: 0.6064, Recall: 0.8980, F1-Score: 0.7240\n","Class 2 - Precision: 0.6034, Recall: 0.8965, F1-Score: 0.7213\n","Validation Loss: -15.8375, Accuracy: 0.7845, F1: 0.7579\n","Best model saved with validation loss: -15.8375\n","\n","\n","Epoch 14, Training Loss: -15.2412, Accuracy: 0.7778, F1: 0.7511\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0010\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0202\n","structure_head: 0.0185\n","Class 0 - Precision: 0.9562, Recall: 0.7446, F1-Score: 0.8372\n","Class 1 - Precision: 0.6167, Recall: 0.8912, F1-Score: 0.7290\n","Class 2 - Precision: 0.6173, Recall: 0.8885, F1-Score: 0.7285\n","Validation Loss: -15.8566, Accuracy: 0.7930, F1: 0.7649\n","Best model saved with validation loss: -15.8566\n","\n","\n","Epoch 15, Training Loss: -15.2484, Accuracy: 0.7786, F1: 0.7520\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0011\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0202\n","structure_head: 0.0185\n","Class 0 - Precision: 0.9577, Recall: 0.7419, F1-Score: 0.8361\n","Class 1 - Precision: 0.6141, Recall: 0.8964, F1-Score: 0.7289\n","Class 2 - Precision: 0.6165, Recall: 0.8882, F1-Score: 0.7278\n","Validation Loss: -15.5039, Accuracy: 0.7921, F1: 0.7643\n","\n","\n","Epoch 16, Training Loss: -15.2943, Accuracy: 0.7797, F1: 0.7531\n","Average Gradient Norms per Layer:\n","embedding_layer: 0.0011\n","shared_transformer_blocks: 0.0014\n","struct_transformer_blocks: 0.0201\n","structure_head: 0.0184\n","Class 0 - Precision: 0.9629, Recall: 0.7213, F1-Score: 0.8248\n","Class 1 - Precision: 0.6034, Recall: 0.9030, F1-Score: 0.7234\n","Class 2 - Precision: 0.5988, Recall: 0.9018, F1-Score: 0.7197\n","Validation Loss: -16.0099, Accuracy: 0.7817, F1: 0.7560\n","Best model saved with validation loss: -16.0099\n","\n","\n"]}],"source":["train_losses, train_f1s, train_accuracies = [], [], []\n","val_losses, val_f1s, val_accuracies = [], [], []\n","\n","for epoch in range(50):\n","    model.train()  # Set model to training mode\n","    total_loss = 0.0\n","    correct_preds = 0\n","    total_preds = 0\n","    all_true_labels = []\n","    all_predicted_labels = []\n","    layer_grad_norms = {}  # Dictionary to accumulate grad norms by layer\n","    num_batches = len(train_dataloader)\n","\n","    for batch_X, batch_y_struct in train_dataloader:\n","        batch_X, batch_y_struct = batch_X.to(device), batch_y_struct.to(device)\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        pred_struct = model(batch_X)\n","\n","        # Loss computation\n","        loss = loss_fn_struct(pred_struct, batch_y_struct)\n","        loss.backward()\n","\n","        # Gradient clipping\n","        nn.utils.clip_grad_value_(model.parameters(), clip_value=0.1)\n","\n","        # Accumulate gradient norms by layer\n","        for name, param in model.named_parameters():\n","            if param.grad is not None:\n","                layer_name = name.split('.')[0]  # Use only the first part as layer name\n","                grad_norm = param.grad.norm().item()\n","                if layer_name not in layer_grad_norms:\n","                    layer_grad_norms[layer_name] = []\n","                layer_grad_norms[layer_name].append(grad_norm)\n","\n","        # Optimizer step\n","        optimizer.step()\n","        scheduler.step()\n","\n","        total_loss += loss.item()\n","\n","        # Convert predictions to class indices for metrics\n","        y_pred = torch.argmax(pred_struct, dim=-1)\n","        y_true = torch.argmax(batch_y_struct, dim=-1)\n","\n","        all_true_labels.append(y_true.cpu())\n","        all_predicted_labels.append(y_pred.cpu())\n","\n","        # Calculate correct predictions\n","        correct_preds += (y_pred == y_true).sum().item()\n","        total_preds += y_true.numel()\n","\n","    avg_loss = total_loss / num_batches\n","    all_true_labels = torch.cat(all_true_labels)\n","    all_predicted_labels = torch.cat(all_predicted_labels)\n","\n","    # Calculate training metrics\n","    train_metrics = calculate_class_metrics(all_true_labels, all_predicted_labels)\n","    avg_train_f1 = print_validation_metrics(train_metrics, printer=False)\n","    accuracy = correct_preds / total_preds\n","\n","    train_losses.append(avg_loss)\n","    train_accuracies.append(accuracy)\n","    train_f1s.append(avg_train_f1)\n","\n","    # Calculate average gradient norms per layer\n","    avg_layer_grad_norms = {layer: sum(norms) / len(norms) for layer, norms in layer_grad_norms.items()}\n","\n","    # Print epoch summary for training\n","    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, F1: {avg_train_f1:.4f}\")\n","    print(\"Average Gradient Norms per Layer:\")\n","    for layer, avg_norm in avg_layer_grad_norms.items():\n","        print(f\"{layer}: {avg_norm:.4f}\")\n","\n","    # Validation phase\n","    model.eval()  # Set model to evaluation mode\n","    val_loss = 0.0\n","    correct_preds = 0\n","    total_preds = 0\n","    all_y_true = []\n","    all_y_pred = []\n","    with torch.no_grad():\n","        for val_X, val_y_struct in val_dataloader:\n","            val_X, val_y_struct = val_X.to(device), val_y_struct.to(device)\n","            val_pred_struct = model(val_X)\n","\n","            # Loss computation\n","            val_loss += loss_fn_struct(val_pred_struct, val_y_struct).item()\n","\n","            # Convert predictions to class indices for metrics\n","            y_pred = torch.argmax(val_pred_struct, dim=-1)\n","            y_true = torch.argmax(val_y_struct, dim=-1)\n","\n","            all_y_true.append(y_true)\n","            all_y_pred.append(y_pred)\n","\n","            # Calculate correct predictions\n","            correct_preds += (y_pred == y_true).sum().item()\n","            total_preds += y_true.numel()\n","\n","    avg_val_loss = val_loss / len(val_dataloader)\n","    all_y_true = torch.cat(all_y_true)\n","    all_y_pred = torch.cat(all_y_pred)\n","\n","    # Calculate validation metrics\n","    val_metrics = calculate_class_metrics(all_y_true, all_y_pred)\n","    avg_val_f1 = print_validation_metrics(val_metrics)\n","    val_accuracy = correct_preds / total_preds\n","\n","    val_losses.append(avg_val_loss)\n","    val_accuracies.append(val_accuracy)\n","    val_f1s.append(avg_val_f1)\n","\n","    # Print validation summary\n","    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {avg_val_f1:.4f}\")\n","\n","    # Check for early stopping and save best model\n","    if avg_val_loss \u003c best_val_loss:\n","        best_val_loss = avg_val_loss\n","        torch.save(model.state_dict(), \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc.pth\")\n","        print(f\"Best model saved with validation loss: {avg_val_loss:.4f}\")\n","        patience_counter = 0\n","    else:\n","        patience_counter += 1\n","\n","    if patience_counter \u003e= patience:\n","        print(\"Early stopping triggered.\")\n","        break\n","\n","    print(\"\\n\")\n"]},{"cell_type":"code","execution_count":null,"id":"9410a4f5-0e05-4f32-83df-fea89d7f560a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":732,"status":"error","timestamp":1733285269817,"user":{"displayName":"Katherine Tang","userId":"10137539789629776108"},"user_tz":300},"id":"9410a4f5-0e05-4f32-83df-fea89d7f560a","outputId":"8e16a17a-600b-49e6-d824-82347f7f09c6"},"outputs":[{"ename":"NameError","evalue":"name 'train_losses' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-8c13356fc7cc\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 10\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create a dictionary for each list to be saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m data_to_save = {\n\u001b[0;32m---\u003e 10\u001b[0;31m     \u001b[0;34mf\"{model_name}_train_losses.csv\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;34mf\"{model_name}_train_f1s.csv\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_f1s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34mf\"{model_name}_train_accuracies.csv\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"]}],"source":["# Run this code to save each of the lists\n","import pandas as pd\n","\n","# Save lists to CSV files with filenames related to the model name\n","model_name = \"12-2_onehotenc\"\n","\n","# Create a dictionary for each list to be saved\n","data_to_save = {\n","    \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc_train_losses.csv\": train_losses,\n","    \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc_train_f1s.csv\": train_f1s,\n","    \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc_train_accuracies.csv\": train_accuracies,\n","    \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc_val_losses.csv\": val_losses,\n","    \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc_val_f1s.csv\": val_f1s,\n","    \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc_val_accuracies.csv\": val_accuracies,\n","}\n","\n","# Loop through each list and save it as a CSV\n","for filename, data_list in data_to_save.items():\n","    # Convert list to DataFrame\n","    df = pd.DataFrame(data_list, columns=[filename.split('_')[-1].split('.')[0]])  # Use the metric name as column\n","    # Save to CSV\n","    df.to_csv(filename, index=False)\n","\n","print(\"Metrics saved to CSV files.\")\n"]},{"cell_type":"code","execution_count":null,"id":"6ae34685-c6f7-4450-ab34-6b835d2cc8ab","metadata":{"id":"6ae34685-c6f7-4450-ab34-6b835d2cc8ab"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b357cec4-1c60-4e0e-b30f-2932cf828847","metadata":{"id":"b357cec4-1c60-4e0e-b30f-2932cf828847"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"2a20c6d2-8632-48b3-bc5b-d1050d25028f","metadata":{"id":"2a20c6d2-8632-48b3-bc5b-d1050d25028f"},"outputs":[],"source":["# Load the saved model\n","model_path = \"/content/drive/MyDrive/ECE661/ECE661_Final_Project_Data/12-2_onehotenc.pth\"\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.eval()\n","\n","# Function to decode structure\n","def decode_structure(encoded):\n","    structure_mapping = {0: '.', 1: '(', 2: ')', 3: '-'}  # '-' represents padding\n","    return ''.join([structure_mapping[code.item()] for code in encoded])\n","\n","def enforce_symmetry_and_minimum_distance(pred_structure, min_distance=3):\n","    stack = []\n","    for i, char in enumerate(pred_structure):\n","        if char == '(':\n","            stack.append(i)\n","        elif char == ')':\n","            if stack:\n","                opening_index = stack.pop()\n","                # Enforce minimum distance rule\n","                if i - opening_index - 1 \u003c min_distance or ''.join(pred_structure[opening_index + 1:i]).count('.') \u003c min_distance:\n","                    # Replace invalid pair with dots\n","                    pred_structure[opening_index] = '.'\n","                    pred_structure[i] = '.'\n","    # Replace unmatched '(' with '.'\n","    for i in stack:\n","        pred_structure[i] = '.'\n","    return pred_structure\n","\n","\n","\n","# Pick some sequences from the validation set\n","num_test_sequences = 50  # Number of sequences to test\n","val_sequences = X_val[:num_test_sequences]\n","val_structures = y_struct_val[:num_test_sequences]\n","\n","# Run predictions and compare with ground truth\n","print(\"Testing the model on some sequences from the validation set:\")\n","with torch.no_grad():\n","    for i, (sequence, true_structure) in enumerate(zip(val_sequences, val_structures)):\n","        sequence = sequence.unsqueeze(0).to(device)  # Add batch dimension\n","        true_structure = true_structure.to(device)\n","\n","        # Predict structure\n","        pred_structure_logits = model(sequence, true_structure.unsqueeze(0))\n","        pred_structure = torch.argmax(pred_structure_logits.view(-1, 3), dim=-1)\n","\n","        # Decode sequence and structures\n","        decoded_sequence = ''.join([list('ATCG-')[x.item()] for x in sequence[0]])  # Decode sequence\n","        decoded_true_structure = decode_structure(true_structure)\n","        decoded_pred_structure = decode_structure(pred_structure)\n","\n","        # Enforce symmetry and minimum distance rule\n","        decoded_pred_structure = enforce_symmetry_and_minimum_distance(list(decoded_pred_structure))\n","\n","        # Print results\n","        print(f\"\\nSequence {i + 1}: {decoded_sequence}\")\n","        print(f\"True Structure:    {decoded_true_structure}\")\n","        print(f\"Predicted Structure: {''.join(decoded_pred_structure)}\")\n"]},{"cell_type":"code","execution_count":null,"id":"8b8234b9-44fd-40d8-81d5-5e9dcd909e77","metadata":{"id":"8b8234b9-44fd-40d8-81d5-5e9dcd909e77"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}