{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83acf3e0-07d8-4d89-b480-db1c78c056ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of combined dataset after filtering: 1294216\n",
      "Training set size: 1292921\n",
      "Test set size: 1295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load all datasets\n",
    "with open('database1_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database1_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database2_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database2_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database3_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database3_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database4_1structsonly_34ave.pkl', 'rb') as file:\n",
    "    database4_1structsonly_34ave = pickle.load(file)\n",
    "\n",
    "with open('database5_1structsonly_50ave.pkl', 'rb') as file:\n",
    "    database5_1structsonly_50ave = pickle.load(file)\n",
    "\n",
    "with open('database6_allstructs_50ave.pkl', 'rb') as file:\n",
    "    database6_allstructs_50ave = pickle.load(file)\n",
    "\n",
    "with open('database7_allstructs_50ave.pkl', 'rb') as file:\n",
    "    database7_allstructs_50ave = pickle.load(file)\n",
    "\n",
    "with open('database9_allstructs_40ave.pkl', 'rb') as file:\n",
    "    database9_allstructs_40ave = pickle.load(file)\n",
    "\n",
    "with open('database10_allstructs_40ave.pkl', 'rb') as file:\n",
    "    database10_allstructs_40ave = pickle.load(file)\n",
    "\n",
    "with open('database11_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database11_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database13_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database13_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database14_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database14_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database15_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database15_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database16_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database16_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database17_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database17_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database18_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database18_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database19_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database19_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database20_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database20_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database21_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database21_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database22_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database22_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database23_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database23_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database24_allstructs_45only.pkl', 'rb') as file:\n",
    "    database24_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database25_allstructs_45only.pkl', 'rb') as file:\n",
    "    database25_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database26_allstructs_45only.pkl', 'rb') as file:\n",
    "    database26_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database27_allstructs_45only.pkl', 'rb') as file:\n",
    "    database27_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database28_allstructs_45only.pkl', 'rb') as file:\n",
    "    database28_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database29_allstructs_45only.pkl', 'rb') as file:\n",
    "    database29_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database30_allstructs_45only.pkl', 'rb') as file:\n",
    "    database30_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database31_allstructs_45only.pkl', 'rb') as file:\n",
    "    database31_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database32_allstructs_45only.pkl', 'rb') as file:\n",
    "    database32_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database33_allstructs_45only.pkl', 'rb') as file:\n",
    "    database33_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database34_allstructs_45only.pkl', 'rb') as file:\n",
    "    database34_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database35_allstructs_45only.pkl', 'rb') as file:\n",
    "    database35_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database36_allstructs_45only.pkl', 'rb') as file:\n",
    "    database36_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database37_allstructs_45only.pkl', 'rb') as file:\n",
    "    database37_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database38_allstructs_45only.pkl', 'rb') as file:\n",
    "    database38_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database39_allstructs_45only.pkl', 'rb') as file:\n",
    "    database39_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database40_allstructs_45only.pkl', 'rb') as file:\n",
    "    database40_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database41_allstructs_45only.pkl', 'rb') as file:\n",
    "    database41_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database42_allstructs_45only.pkl', 'rb') as file:\n",
    "    database42_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database43_allstructs_45only.pkl', 'rb') as file:\n",
    "    database43_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database44_allstructs_45only.pkl', 'rb') as file:\n",
    "    database44_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database45_allstructs_45only.pkl', 'rb') as file:\n",
    "    database45_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database46_allstructs_45only.pkl', 'rb') as file:\n",
    "    database46_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database47_allstructs_45only.pkl', 'rb') as file:\n",
    "    database47_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database48_allstructs_45only.pkl', 'rb') as file:\n",
    "    database48_allstructs_45only = pickle.load(file)\n",
    "    \n",
    "\n",
    "# Combine datasets into a single dictionary\n",
    "combined_data = {}\n",
    "datasets = [\n",
    "    database1_allstructs_34ave, database2_allstructs_34ave, database3_allstructs_34ave,\n",
    "    database4_1structsonly_34ave, database5_1structsonly_50ave, database6_allstructs_50ave,\n",
    "    database7_allstructs_50ave, database9_allstructs_40ave, database10_allstructs_40ave, \n",
    "    database11_allstructs_45ave, database13_allstructs_45ave, database14_allstructs_45ave,\n",
    "    database15_allstructs_45ave, database16_allstructs_45ave, database17_allstructs_45ave,\n",
    "    database18_allstructs_45ave, database19_allstructs_45ave, database20_allstructs_45ave,\n",
    "    database21_allstructs_45ave, database22_allstructs_45ave, database23_allstructs_45ave,\n",
    "    database24_allstructs_45only, database25_allstructs_45only, database26_allstructs_45only,\n",
    "    database27_allstructs_45only, database28_allstructs_45only, database29_allstructs_45only,\n",
    "    database30_allstructs_45only, database31_allstructs_45only, database32_allstructs_45only,\n",
    "    database33_allstructs_45only, database34_allstructs_45only, database35_allstructs_45only,\n",
    "    database36_allstructs_45only, database37_allstructs_45only, database38_allstructs_45only,\n",
    "    database39_allstructs_45only, database40_allstructs_45only, database41_allstructs_45only,\n",
    "    database42_allstructs_45only, database43_allstructs_45only, database44_allstructs_45only,\n",
    "    database45_allstructs_45only, database46_allstructs_45only, database47_allstructs_45only,\n",
    "    database48_allstructs_45only\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seq, (temp, structs) in dataset.items():\n",
    "        # Only include if melting temperature is defined and above 20\n",
    "        if temp is not None:\n",
    "            combined_data[seq] = (temp, structs)\n",
    "\n",
    "combined_data2 = {}\n",
    "for i, j in combined_data.items():\n",
    "    if len(i) == len(j[1][-1]):\n",
    "        combined_data2[i] = j\n",
    "\n",
    "combined_data = combined_data2\n",
    "\n",
    "# Verify combined data size after filtering\n",
    "print(f\"Total size of combined dataset after filtering: {len(combined_data)}\")\n",
    "\n",
    "# Prepare data for train-test split\n",
    "sequences = list(combined_data.keys())\n",
    "labels = list(combined_data.values())\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% test)\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    sequences, labels, test_size=0.001, random_state=42\n",
    ")\n",
    "\n",
    "# Create train and test sets as dictionaries\n",
    "train_set = {seq: label for seq, label in zip(train_sequences, train_labels)}\n",
    "test_set = {seq: label for seq, label in zip(test_sequences, test_labels)}\n",
    "\n",
    "# Display the split summary\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "994de9d2-83ea-4ca5-ba13-cdd20810a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in train_set.items():\n",
    "    if len(i) != len(j[1][-1]):\n",
    "        count +=1 \n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2423e75a-bf43-46fd-b32c-2d0084162646",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n",
    "top_structures = [train_set[seq][1] for seq in dna_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f745fd09-e181-473b-b036-bbd728f49f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777256\n"
     ]
    }
   ],
   "source": [
    "print(len(dna_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef21692e-1c22-4c59-9658-1ba8341a9fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TATTTATCAGATCAATGGGGTATGAGCACAGTTAGTGGCCCGGCG',\n",
       " 'GAGCACGTCCGGTGTAAGTGTCTTGCCGGCCAGTACCGAACACGT',\n",
       " 'CTCAGAAATACACTCCTGCCGTGCGGATCAGAGGCACCATATATG',\n",
       " 'CGCTAATTCACAGGTCAACGATATTTAATCGTTTGCGCTGCATTT',\n",
       " 'GAGCCTGGGCGAGGGAGTGGCACATGATTTATCGACCTTAAATTC',\n",
       " 'CGATCGGTACAGCATGGTCGGAGGGCAAGGACAAACAAGTTTCGG',\n",
       " 'CGCTTAGGGCAGTTTAATCTCTGTTGTCCTTATATCGACCATACC',\n",
       " 'GCTACGATACACCCGGGACATGCTTAGATGTCCTATGTGCAACTT',\n",
       " 'TTATTATCCGGTGGGAGTTTATATCTCACTTAATGAGGGGCTCTC',\n",
       " 'TAAGATGCGTGAACAAGAGGGGAATTGGAGCGAAACGGAGCGCTA',\n",
       " 'TGTCCGTAATTCCGCTCCTCTACCTCCCGCCAGGACATACCGAAC',\n",
       " 'CTTTTGAGGGCCAGATGAAGACTCGAGTCCACGCATGTTGGGCCC',\n",
       " 'TGGAGCACGGTTTCTATAGGTTTGAGTCATTCTGCCTTTCAACCG',\n",
       " 'TTGTTATAACTGAAGTATCGTGCCATGTAAACACGCATTTCGGTA',\n",
       " 'TACACCCAAAGCCGCTAATGGATGCAGCTCGCATTGCCTGTCCGA',\n",
       " 'ATTAGGGGCAAGACTAACTGCGGGAGTTAGGGTGAGATCGCGAAA',\n",
       " 'AGGGGCGAATCGATTGGGTTGGGAATTTGTTTCGCGCCAGAGAAC',\n",
       " 'ATTGAACTTTTGTACGCGAATTATCAATGACGGTGGCAGATTTTT',\n",
       " 'CAAATTGGTGTTCCGCGTCAGTGACACGGCCTAATTGTTCAACCC',\n",
       " 'TAGTGCGAGGGTCCACAAAGTCTTACTGTCGTACTGTCCTAGTGG',\n",
       " 'AGTCGCCGCGAATTTAACGTTACCGCGCAGTCGCCAATTAGTAGA',\n",
       " 'CAAAATAACCAGGCCTCACGCTCAATGGGGGCCGCAGAGTGGGCC',\n",
       " 'TTACGACCCAAACCTAACCTGGCGCGGTTGCACCTTAGTGGAAGG',\n",
       " 'TTACAAAATTTACGCGCTGTTGCTTATGGATCGGATTCTGTGAGC',\n",
       " 'TTATAGTTTTGCTGACAGCGGACTGATATCAATACGAATGGTATT',\n",
       " 'AGCTAATACAAATGCGTCCTAATATTCGATTGATGGAAGGTTACC',\n",
       " 'ACCAGCCGCGCGGATCAGGGAACGCACTGTACCATGGGAAACTCT',\n",
       " 'TCTAACGACGAAAGAACCAACTCGTCTACCTCCGTTTATCCGGTG',\n",
       " 'GTAGTCACCACTAACTCTGAGAGGCAGCGTGCGTATGATGTCCGC',\n",
       " 'TGGTAGGGAGGTCCCGACGTTGCGTTTTACCAGGCGTCGGCGCTA']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_sequences[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c93c17-7328-4b0f-909a-8eed3ffee0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.(((.....))).....((((.....(((.....)))))))....',\n",
       "  '...............((((.(...............).))))...',\n",
       "  '.(((.(.....).)))..........(((.....)))........',\n",
       "  '.(((.........)))..........(((.....)))........',\n",
       "  '.......((......)).........(((.....)))........',\n",
       "  '...........(((........))).(((.....)))........',\n",
       "  '......(((.(((.....))).))).(((.....)))........',\n",
       "  '.................((((.....(((.....)))))))....'],\n",
       " ['........(((((...........))))).....((.......))',\n",
       "  '...(((.....)))...((((.(...(((......))))))))..',\n",
       "  '......(.(((((...........))))))..((.....))....',\n",
       "  '...(((.....)))...((.....))(((......))).......',\n",
       "  '....((..(((((...........)))))...))..((....)).',\n",
       "  '.(((((...........))).))...(((......))).......',\n",
       "  '....((((.((((.....................))))...))))',\n",
       "  '....(((((((((...........)))))............))))',\n",
       "  '...(((.....)))..........(.(((......)))..)....',\n",
       "  '........(((((...........))))).......((....)).',\n",
       "  '...(((.....)))...((((.....(((......))).))))..',\n",
       "  '...(((...........)))......(((......))).......',\n",
       "  '........(((((...........)))))...((.....))....',\n",
       "  '...(((.....))).(((...)))..(((......))).......',\n",
       "  '...(((.....)))............(((......))).......'],\n",
       " ['...((.......))...(((.((.....))..)))..........',\n",
       "  '..........((....))..((((.........))))........',\n",
       "  '.................(((.((.....))..)))..((....))',\n",
       "  '.................(((.((.....))..)))..........',\n",
       "  '..(((..........)))..((((.........))))........'],\n",
       " ['....(((.((...((.((((((.....)))))).))..)).))).',\n",
       "  '(((.(............(((((.....)))))).)))........',\n",
       "  '........((......((((((.....))))))))..........',\n",
       "  '......(.....)...((((((.....)))))).((...))....',\n",
       "  '.((..........)).((((((.....)))))).((...))....',\n",
       "  '.((.............((((((.....))))))......))....',\n",
       "  '........(...)...((((((.....)))))).((...))....',\n",
       "  '..........((....((((((.....))))))))..........',\n",
       "  '....(((...(((...((((((.....))))))....))).))).',\n",
       "  '..((.......))...((((((.....)))))).((...))....',\n",
       "  '..........(((((.((((((.....)))))).)).))).....',\n",
       "  '..........(((..(((((((.....)))).)))..))).....',\n",
       "  '..........(((...((((((.....))))))....))).....',\n",
       "  '................((((((.....)))))).((...))....'],\n",
       " ['...(((.....)))....((...............))........',\n",
       "  '......(.((.........)).)...(((((.......)))))..',\n",
       "  '..((....))........(...)...(((((.......)))))..',\n",
       "  '......((.(((.(...............).))).))........',\n",
       "  '..(((.............)))....((....))............',\n",
       "  '......((.(((..(.(((...)))..)...))).))........',\n",
       "  '...(((.....)))....(...)...(((((.......)))))..',\n",
       "  '......((.(((.....((...)).......))).))........',\n",
       "  '..(((.............))).....(((((.......)))))..',\n",
       "  '......((.(((...................))).))........'],\n",
       " ['..............((.((...)).))...((......)).....',\n",
       "  '....((...((...))..))............(((....)))...',\n",
       "  '......(.....)...(((..........))).............',\n",
       "  '.........((...))(((..........))).............',\n",
       "  '...........((...........))......(((....)))...',\n",
       "  '(((((..........)))))............(((....)))...',\n",
       "  '................(((..........))).............',\n",
       "  '..............((.((...)).)).....(((....)))...'],\n",
       " ['.((.....))............((((.........))))......',\n",
       "  '.....((((((.............))))))...((.....))...',\n",
       "  '.........(((........)))..(((........)))......',\n",
       "  '.((.....))...............(((........)))......',\n",
       "  '.....((((((.............))))))...............'],\n",
       " ['.......((((...(((((((......))))))).))))......',\n",
       "  '((..((.......))((((((......)))))).....)).....',\n",
       "  '...(...).(((..(((((((......)))))))..)))......',\n",
       "  '....((.......))((((((......))))))...((...))..',\n",
       "  '...............((((((......))))))...((...))..',\n",
       "  '.........(((..(((((((......)))))))..)))......'],\n",
       " ['......(((....)))........((((.....)))).(.....)',\n",
       "  '..........((((((.......)))))).....(((.....)))',\n",
       "  '......(((....)))........((((.....))))........'],\n",
       " ['...........((...........))..((((........)))).',\n",
       "  '.....((......)).............((((........)))).',\n",
       "  '.............(((........))).((((........)))).']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_structures[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e9ad8-ec71-4953-a369-33e195ae0407",
   "metadata": {},
   "source": [
    "# Some Parameters Changed and Only Sequences 40-50 bp long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3ca561a-af4b-464a-83fa-78fcfd8b3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Number of sequences in dna_sequences:  10\n",
      "Sample weights stats:\n",
      "Min: 0.17018939554691315, Max: 0.3036707937717438, Mean: 0.2091214805841446\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.utils as nn_utils\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 45\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "num_shared_transformer_blocks = 12\n",
    "num_task_transformer_blocks = 6\n",
    "dropout_rate = 0.2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Encoding functions\n",
    "def encode_dna_sequence(seq):\n",
    "    mapping = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "    return [mapping[base] for base in seq]\n",
    "\n",
    "def encode_structure(structure):\n",
    "    structure_mapping = {'.': 0, '(': 1, ')': 2}\n",
    "    return [structure_mapping[char] for char in structure]\n",
    "\n",
    "# Assume train_set is already defined\n",
    "dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n",
    "print(\"Number of sequences in dna_sequences: \", len(dna_sequences))\n",
    "top_structures = [train_set[seq][1] for seq in dna_sequences]\n",
    "\n",
    "# Encode DNA sequences (no padding necessary)\n",
    "encoded_sequences = [encode_dna_sequence(seq) for seq in dna_sequences]\n",
    "\n",
    "# Encode structures (no padding necessary)\n",
    "encoded_structures = [encode_structure(structs[-1]) for structs in top_structures]\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(encoded_sequences, dtype=torch.long)\n",
    "y_struct = torch.tensor(encoded_structures, dtype=torch.long)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_struct_train, y_struct_val = train_test_split(X, y_struct, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "class_counts = torch.tensor(\n",
    "    [sum(struct.count(char) for struct in [\"\".join(top_struct) for top_struct in top_structures]) for char in \".()\"], \n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Ensure no division by zero\n",
    "total_count = class_counts.sum()\n",
    "if total_count == 0 or any(class_counts == 0):\n",
    "    raise ValueError(\"Class counts are invalid, resulting in division by zero.\")\n",
    "\n",
    "# Compute class weights (Inverse frequency weighting)\n",
    "class_weights = total_count / (class_counts + 1e-5)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.clamp(class_weights, min=0)  # Ensure non-negative weights\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Create weighted sampler for the training set\n",
    "sample_weights = []\n",
    "for y in y_struct_train:\n",
    "    valid_indices = y  # Here we are using y directly as it represents the class labels for each base\n",
    "    weight = [class_weights[class_idx].item() for class_idx in valid_indices]\n",
    "    sample_weights.append(sum(weight) / len(weight))  # Average weight for the sequence\n",
    "\n",
    "# Convert to tensor and validate\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "sample_weights = torch.nan_to_num(sample_weights, nan=1.0, posinf=1.0, neginf=1.0)  # Replace NaN/infs with default value\n",
    "sample_weights = torch.clamp(sample_weights, min=0)  # Ensure weights are non-negative\"\"\"\n",
    "\n",
    "class_weights = torch.load(\"class_weights_only45s.pt\").to(device)\n",
    "sample_weights = torch.load(\"sample_weights_only45s.pt\").to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Debugging: Print sample weights stats\n",
    "print(\"Sample weights stats:\")\n",
    "print(f\"Min: {sample_weights.min()}, Max: {sample_weights.max()}, Mean: {sample_weights.mean()}\")\n",
    "assert torch.all(sample_weights >= 0), \"Sample weights contain negative values!\"\n",
    "assert not torch.any(torch.isnan(sample_weights)), \"Sample weights contain NaN values!\"\n",
    "\n",
    "# Create sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_struct_train)\n",
    "val_dataset = TensorDataset(X_val, y_struct_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4f57ca6-0ce2-40d4-80ed-04fb55759afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn.utils as nn_utils\n",
    "\n",
    "# Model Definition\n",
    "class TransformerEncoderBlockWithPairingAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.2, sequence_length=45):\n",
    "        super(TransformerEncoderBlockWithPairingAttention, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.pairing_bias = nn.Parameter(torch.randn(sequence_length, sequence_length))\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        q, k, v = x, x, x\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (q.size(-1) ** 0.5)\n",
    "        seq_len = q.size(1)\n",
    "        pairing_bias_resized = self.pairing_bias[:seq_len, :seq_len]\n",
    "        pairing_bias_resized = pairing_bias_resized.unsqueeze(0).expand(x.size(0), -1, -1).to(x.device)\n",
    "        attn_scores = attn_scores + pairing_bias_resized\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        paired_attn_output = torch.matmul(attn_weights, v)\n",
    "        x = x + self.dropout1(attn_output + paired_attn_output)\n",
    "        x = self.layernorm1(x)\n",
    "        x = x + self.dropout2(self.ffn(x))\n",
    "        x = self.layernorm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StructurePredictor(nn.Module):\n",
    "    def __init__(self, sequence_length=45, embedding_dim=256, num_heads=8, ff_dim=512, num_shared_blocks=12, num_task_blocks=6):\n",
    "        super(StructurePredictor, self).__init__()\n",
    "        self.embedding = nn.Embedding(4, embedding_dim)  # No padding index since no padding is required\n",
    "        self.positional_encoding = self.create_sinusoidal_positional_encoding(sequence_length, embedding_dim)\n",
    "        self.shared_transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=sequence_length)\n",
    "            for _ in range(num_shared_blocks)\n",
    "        ])\n",
    "        self.struct_transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=sequence_length)\n",
    "            for _ in range(num_task_blocks)\n",
    "        ])\n",
    "        self.structure_head = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, 3)\n",
    "        )\n",
    "\n",
    "    def create_sinusoidal_positional_encoding(self, seq_len, d_model):\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pos_enc = torch.zeros(seq_len, d_model)\n",
    "        pos_enc[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pos_enc[:, 1::2] = torch.cos(pos * div_term)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device  # Get the device of input tensor\n",
    "        positional_encoding = self.positional_encoding.to(device)  # Move to same device\n",
    "    \n",
    "        x = self.embedding(x) + positional_encoding  # Add positional encoding\n",
    "        x = x.permute(1, 0, 2)  # Permute for transformer compatibility\n",
    "    \n",
    "        # Shared Transformer blocks\n",
    "        for block in self.shared_transformer_blocks:\n",
    "            x = block(x)\n",
    "    \n",
    "        # Output layers\n",
    "        output = self.structure_head(x.permute(1, 0, 2))  # Permute back to original shape\n",
    "        return output\n",
    "\n",
    "\n",
    "class RewardedThermodynamicallyBalancedCategoricalCrossEntropy(nn.Module):\n",
    "    def __init__(self, weights, pairing_penalty=0.2, thermo_penalty=0.3, specificity_reward=0.05):\n",
    "        super(RewardedThermodynamicallyBalancedCategoricalCrossEntropy, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.pairing_penalty = pairing_penalty\n",
    "        self.thermo_penalty = thermo_penalty\n",
    "        self.specificity_reward = specificity_reward\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Weighted categorical cross-entropy\n",
    "        y_true_one_hot = F.one_hot(y_true, num_classes=3).float()\n",
    "        log_probs = F.log_softmax(y_pred, dim=-1)\n",
    "        loss = -torch.sum(self.weights * y_true_one_hot * log_probs, dim=-1).mean()\n",
    "\n",
    "        # Pairing imbalance penalty\n",
    "        pred_labels = torch.argmax(y_pred, dim=-1)\n",
    "        open_count = (pred_labels == 1).sum()\n",
    "        close_count = (pred_labels == 2).sum()\n",
    "        imbalance_penalty = self.pairing_penalty * torch.abs(open_count - close_count).float()\n",
    "\n",
    "        # Thermodynamic penalty for mismatches\n",
    "        mismatch_penalty = torch.sum((pred_labels == 1) & (y_true == 2)) * self.thermo_penalty\n",
    "\n",
    "        # Specificity reward for correct pair predictions\n",
    "        correct_pairings = ((pred_labels == y_true) & ((y_true == 1) | (y_true == 2))).sum()\n",
    "        specificity_reward = self.specificity_reward * correct_pairings.float()\n",
    "\n",
    "        return loss + imbalance_penalty + mismatch_penalty - specificity_reward\n",
    "\n",
    "\n",
    "# Instantiate model and loss function\n",
    "model = StructurePredictor(sequence_length, embedding_dim, num_heads, ff_dim, num_shared_transformer_blocks, num_task_transformer_blocks).to(device)\n",
    "loss_fn_struct = RewardedThermodynamicallyBalancedCategoricalCrossEntropy(class_weights)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n",
    "\n",
    "# Training loop with early stopping and metrics\n",
    "best_val_loss = float('inf')\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "def calculate_class_metrics(y_true, y_pred, num_classes=3):\n",
    "    metrics = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        tp = ((y_pred == class_idx) & (y_true == class_idx)).sum().item()\n",
    "        fp = ((y_pred == class_idx) & (y_true != class_idx)).sum().item()\n",
    "        fn = ((y_pred != class_idx) & (y_true == class_idx)).sum().item()\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "        metrics[class_idx] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "    return metrics\n",
    "\n",
    "def print_validation_metrics(val_metrics, printer=True):\n",
    "    total_f1 = 0\n",
    "    num_classes = len(val_metrics)\n",
    "    \n",
    "    # Print metrics for each class\n",
    "    for cls, metrics in val_metrics.items():\n",
    "        if printer:\n",
    "            print(f\"Class {cls} - Precision: {metrics['precision']:.4f}, \"\n",
    "                  f\"Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1']:.4f}\")\n",
    "        total_f1 += metrics['f1']\n",
    "    \n",
    "    # Calculate the average F1 score\n",
    "    avg_f1 = total_f1 / num_classes if num_classes > 0 else 0.0\n",
    "    \n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2cad421-5c8e-4439-b0c1-a8ac50b5800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Save sample weights\n",
    "torch.save(sample_weights, \"sample_weights_evenevenmoredata.pt\")\n",
    "\n",
    "# Load sample weights\n",
    "torch.save(class_weights, \"class_weights_evenevenmoredata.pt\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c9865-6de3-4c08-be14-0b42aa449558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell if the gradients explode!\n",
    "\"\"\"\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n",
    "model_path = \"12-2_integerenc.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8eb2ca60-346a-4489-92cf-57934063aa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 20.1510\n",
      "Learning Rate: 8.136061215030879e-06\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0085\n",
      "shared_transformer_blocks: 0.0203\n",
      "structure_head: 0.0780\n",
      "Class 0 - Precision: 0.5128, Recall: 0.3846, F1-Score: 0.4396\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.2222, Recall: 0.4211, F1-Score: 0.2909\n",
      "Validation Loss: 5.3140, Accuracy: 0.3111, F1: 0.2435\n",
      "Best model saved with validation loss: 5.3140\n",
      "\n",
      "\n",
      "Epoch 2, Training Loss: 14.4830\n",
      "Learning Rate: 8.543859179826856e-06\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0083\n",
      "shared_transformer_blocks: 0.0217\n",
      "structure_head: 0.0789\n",
      "Class 0 - Precision: 0.5098, Recall: 0.5000, F1-Score: 0.5049\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.1724, Recall: 0.2632, F1-Score: 0.2083\n",
      "Validation Loss: 4.4608, Accuracy: 0.3444, F1: 0.2377\n",
      "Best model saved with validation loss: 4.4608\n",
      "\n",
      "\n",
      "Epoch 3, Training Loss: 3.8312\n",
      "Learning Rate: 9.222237946750927e-06\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0100\n",
      "shared_transformer_blocks: 0.0314\n",
      "structure_head: 0.1091\n",
      "Class 0 - Precision: 0.4898, Recall: 0.4615, F1-Score: 0.4752\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.2143, Recall: 0.3158, F1-Score: 0.2553\n",
      "Validation Loss: 3.6040, Accuracy: 0.3333, F1: 0.2435\n",
      "Best model saved with validation loss: 3.6040\n",
      "\n",
      "\n",
      "Epoch 4, Training Loss: 6.8024\n",
      "Learning Rate: 1.0169274577484803e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0075\n",
      "shared_transformer_blocks: 0.0206\n",
      "structure_head: 0.0740\n",
      "Class 0 - Precision: 0.4889, Recall: 0.4231, F1-Score: 0.4536\n",
      "Class 1 - Precision: 0.0909, Recall: 0.1053, F1-Score: 0.0976\n",
      "Class 2 - Precision: 0.3043, Recall: 0.3684, F1-Score: 0.3333\n",
      "Validation Loss: 0.6468, Accuracy: 0.3444, F1: 0.2948\n",
      "Best model saved with validation loss: 0.6468\n",
      "\n",
      "\n",
      "Epoch 5, Training Loss: 8.6483\n",
      "Learning Rate: 1.1382284593806468e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0062\n",
      "shared_transformer_blocks: 0.0160\n",
      "structure_head: 0.0569\n",
      "Class 0 - Precision: 0.4412, Recall: 0.2885, F1-Score: 0.3488\n",
      "Class 1 - Precision: 0.0741, Recall: 0.1053, F1-Score: 0.0870\n",
      "Class 2 - Precision: 0.3103, Recall: 0.4737, F1-Score: 0.3750\n",
      "Validation Loss: 1.0401, Accuracy: 0.2889, F1: 0.2703\n",
      "\n",
      "\n",
      "Epoch 6, Training Loss: 9.8357\n",
      "Learning Rate: 1.2857829587035395e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0074\n",
      "shared_transformer_blocks: 0.0195\n",
      "structure_head: 0.0709\n",
      "Class 0 - Precision: 0.4583, Recall: 0.2115, F1-Score: 0.2895\n",
      "Class 1 - Precision: 0.1143, Recall: 0.2105, F1-Score: 0.1481\n",
      "Class 2 - Precision: 0.3226, Recall: 0.5263, F1-Score: 0.4000\n",
      "Validation Loss: 1.5848, Accuracy: 0.2778, F1: 0.2792\n",
      "\n",
      "\n",
      "Epoch 7, Training Loss: 12.1192\n",
      "Learning Rate: 1.4591726964575502e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0079\n",
      "shared_transformer_blocks: 0.0215\n",
      "structure_head: 0.0823\n",
      "Class 0 - Precision: 0.5333, Recall: 0.1538, F1-Score: 0.2388\n",
      "Class 1 - Precision: 0.1463, Recall: 0.3158, F1-Score: 0.2000\n",
      "Class 2 - Precision: 0.3235, Recall: 0.5789, F1-Score: 0.4151\n",
      "Validation Loss: 2.3292, Accuracy: 0.2778, F1: 0.2846\n",
      "\n",
      "\n",
      "Epoch 8, Training Loss: 14.1051\n",
      "Learning Rate: 1.6579061805928314e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0054\n",
      "shared_transformer_blocks: 0.0151\n",
      "structure_head: 0.0561\n",
      "Class 0 - Precision: 0.5714, Recall: 0.1538, F1-Score: 0.2424\n",
      "Class 1 - Precision: 0.1795, Recall: 0.3684, F1-Score: 0.2414\n",
      "Class 2 - Precision: 0.3243, Recall: 0.6316, F1-Score: 0.4286\n",
      "Validation Loss: 0.9242, Accuracy: 0.3000, F1: 0.3041\n",
      "\n",
      "\n",
      "Epoch 9, Training Loss: 10.8984\n",
      "Learning Rate: 1.881420079456915e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0063\n",
      "shared_transformer_blocks: 0.0154\n",
      "structure_head: 0.0586\n",
      "Class 0 - Precision: 0.6154, Recall: 0.1538, F1-Score: 0.2462\n",
      "Class 1 - Precision: 0.1905, Recall: 0.4211, F1-Score: 0.2623\n",
      "Class 2 - Precision: 0.3429, Recall: 0.6316, F1-Score: 0.4444\n",
      "Validation Loss: 1.8696, Accuracy: 0.3111, F1: 0.3176\n",
      "\n",
      "\n",
      "Epoch 10, Training Loss: 13.9266\n",
      "Learning Rate: 2.1290808186194625e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0078\n",
      "shared_transformer_blocks: 0.0255\n",
      "structure_head: 0.0854\n",
      "Class 0 - Precision: 0.6000, Recall: 0.1731, F1-Score: 0.2687\n",
      "Class 1 - Precision: 0.1860, Recall: 0.4211, F1-Score: 0.2581\n",
      "Class 2 - Precision: 0.3125, Recall: 0.5263, F1-Score: 0.3922\n",
      "Validation Loss: 3.0660, Accuracy: 0.3000, F1: 0.3063\n",
      "\n",
      "\n",
      "Epoch 11, Training Loss: 23.8223\n",
      "Learning Rate: 2.4001863768078577e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0082\n",
      "shared_transformer_blocks: 0.0286\n",
      "structure_head: 0.0950\n",
      "Class 0 - Precision: 0.6818, Recall: 0.2885, F1-Score: 0.4054\n",
      "Class 1 - Precision: 0.2162, Recall: 0.4211, F1-Score: 0.2857\n",
      "Class 2 - Precision: 0.3226, Recall: 0.5263, F1-Score: 0.4000\n",
      "Validation Loss: 1.7641, Accuracy: 0.3667, F1: 0.3637\n",
      "\n",
      "\n",
      "Epoch 12, Training Loss: 16.6288\n",
      "Learning Rate: 2.6939682758627515e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0070\n",
      "shared_transformer_blocks: 0.0220\n",
      "structure_head: 0.0722\n",
      "Class 0 - Precision: 0.7105, Recall: 0.5192, F1-Score: 0.6000\n",
      "Class 1 - Precision: 0.3077, Recall: 0.4211, F1-Score: 0.3556\n",
      "Class 2 - Precision: 0.3462, Recall: 0.4737, F1-Score: 0.4000\n",
      "Validation Loss: 0.3148, Accuracy: 0.4889, F1: 0.4519\n",
      "Best model saved with validation loss: 0.3148\n",
      "\n",
      "\n",
      "Epoch 13, Training Loss: 7.2803\n",
      "Learning Rate: 3.0095937590729016e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0057\n",
      "shared_transformer_blocks: 0.0137\n",
      "structure_head: 0.0524\n",
      "Class 0 - Precision: 0.6863, Recall: 0.6731, F1-Score: 0.6796\n",
      "Class 1 - Precision: 0.3846, Recall: 0.2632, F1-Score: 0.3125\n",
      "Class 2 - Precision: 0.3462, Recall: 0.4737, F1-Score: 0.4000\n",
      "Validation Loss: 2.1678, Accuracy: 0.5444, F1: 0.4640\n",
      "\n",
      "\n",
      "Epoch 14, Training Loss: 2.6052\n",
      "Learning Rate: 3.3461681517145544e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0056\n",
      "shared_transformer_blocks: 0.0148\n",
      "structure_head: 0.0521\n",
      "Class 0 - Precision: 0.6364, Recall: 0.8077, F1-Score: 0.7119\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.3182, Recall: 0.3684, F1-Score: 0.3415\n",
      "Validation Loss: 3.9241, Accuracy: 0.5444, F1: 0.3511\n",
      "\n",
      "\n",
      "Epoch 15, Training Loss: 2.6693\n",
      "Learning Rate: 3.702737397104147e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0052\n",
      "shared_transformer_blocks: 0.0138\n",
      "structure_head: 0.0453\n",
      "Class 0 - Precision: 0.6479, Recall: 0.8846, F1-Score: 0.7480\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.3158, Recall: 0.3158, F1-Score: 0.3158\n",
      "Validation Loss: 3.7815, Accuracy: 0.5778, F1: 0.3546\n",
      "\n",
      "\n",
      "Epoch 16, Training Loss: 4.3463\n",
      "Learning Rate: 4.078290760975629e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0048\n",
      "shared_transformer_blocks: 0.0123\n",
      "structure_head: 0.0436\n",
      "Class 0 - Precision: 0.6479, Recall: 0.8846, F1-Score: 0.7480\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.3158, Recall: 0.3158, F1-Score: 0.3158\n",
      "Validation Loss: 3.7913, Accuracy: 0.5778, F1: 0.3546\n",
      "\n",
      "\n",
      "Epoch 17, Training Loss: 8.2868\n",
      "Learning Rate: 4.471763696516559e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0083\n",
      "shared_transformer_blocks: 0.0306\n",
      "structure_head: 0.1059\n",
      "Class 0 - Precision: 0.6479, Recall: 0.8846, F1-Score: 0.7480\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.3158, Recall: 0.3158, F1-Score: 0.3158\n",
      "Validation Loss: 3.7903, Accuracy: 0.5778, F1: 0.3546\n",
      "\n",
      "\n",
      "Epoch 18, Training Loss: 9.3377\n",
      "Learning Rate: 4.882040861941696e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0082\n",
      "shared_transformer_blocks: 0.0300\n",
      "structure_head: 0.1081\n",
      "Class 0 - Precision: 0.6324, Recall: 0.8269, F1-Score: 0.7167\n",
      "Class 1 - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "Class 2 - Precision: 0.3000, Recall: 0.3158, F1-Score: 0.3077\n",
      "Validation Loss: 3.5792, Accuracy: 0.5444, F1: 0.3415\n",
      "\n",
      "\n",
      "Epoch 19, Training Loss: 3.6767\n",
      "Learning Rate: 5.307959282050475e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0081\n",
      "shared_transformer_blocks: 0.0261\n",
      "structure_head: 0.0941\n",
      "Class 0 - Precision: 0.6667, Recall: 0.7308, F1-Score: 0.6972\n",
      "Class 1 - Precision: 0.4167, Recall: 0.2632, F1-Score: 0.3226\n",
      "Class 2 - Precision: 0.2857, Recall: 0.3158, F1-Score: 0.3000\n",
      "Validation Loss: 1.5134, Accuracy: 0.5444, F1: 0.4399\n",
      "\n",
      "\n",
      "Epoch 20, Training Loss: 2.8687\n",
      "Learning Rate: 5.748311644806559e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0071\n",
      "shared_transformer_blocks: 0.0194\n",
      "structure_head: 0.0689\n",
      "Class 0 - Precision: 0.7073, Recall: 0.5577, F1-Score: 0.6237\n",
      "Class 1 - Precision: 0.3182, Recall: 0.3684, F1-Score: 0.3415\n",
      "Class 2 - Precision: 0.3333, Recall: 0.4737, F1-Score: 0.3913\n",
      "Validation Loss: 1.0508, Accuracy: 0.5000, F1: 0.4521\n",
      "\n",
      "\n",
      "Epoch 21, Training Loss: 4.7649\n",
      "Learning Rate: 6.201849723594987e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0049\n",
      "shared_transformer_blocks: 0.0138\n",
      "structure_head: 0.0490\n",
      "Class 0 - Precision: 0.7692, Recall: 0.3846, F1-Score: 0.5128\n",
      "Class 1 - Precision: 0.3125, Recall: 0.5263, F1-Score: 0.3922\n",
      "Class 2 - Precision: 0.3438, Recall: 0.5789, F1-Score: 0.4314\n",
      "Validation Loss: 0.3961, Accuracy: 0.4556, F1: 0.4454\n",
      "\n",
      "\n",
      "Epoch 22, Training Loss: 2.6417\n",
      "Learning Rate: 6.66728791545612e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0049\n",
      "shared_transformer_blocks: 0.0129\n",
      "structure_head: 0.0498\n",
      "Class 0 - Precision: 0.6923, Recall: 0.1731, F1-Score: 0.2769\n",
      "Class 1 - Precision: 0.2821, Recall: 0.5789, F1-Score: 0.3793\n",
      "Class 2 - Precision: 0.3421, Recall: 0.6842, F1-Score: 0.4561\n",
      "Validation Loss: 0.4452, Accuracy: 0.3667, F1: 0.3708\n",
      "\n",
      "\n",
      "Epoch 23, Training Loss: 6.9063\n",
      "Learning Rate: 7.143306885266912e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0089\n",
      "shared_transformer_blocks: 0.0301\n",
      "structure_head: 0.1075\n",
      "Class 0 - Precision: 0.7273, Recall: 0.1538, F1-Score: 0.2540\n",
      "Class 1 - Precision: 0.2955, Recall: 0.6842, F1-Score: 0.4127\n",
      "Class 2 - Precision: 0.3143, Recall: 0.5789, F1-Score: 0.4074\n",
      "Validation Loss: 2.6453, Accuracy: 0.3556, F1: 0.3580\n",
      "\n",
      "\n",
      "Epoch 24, Training Loss: 8.6871\n",
      "Learning Rate: 7.62855730553964e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0070\n",
      "shared_transformer_blocks: 0.0200\n",
      "structure_head: 0.0732\n",
      "Class 0 - Precision: 0.6667, Recall: 0.1923, F1-Score: 0.2985\n",
      "Class 1 - Precision: 0.3077, Recall: 0.6316, F1-Score: 0.4138\n",
      "Class 2 - Precision: 0.3333, Recall: 0.6316, F1-Score: 0.4364\n",
      "Validation Loss: 0.8443, Accuracy: 0.3778, F1: 0.3829\n",
      "\n",
      "\n",
      "Epoch 25, Training Loss: 12.5744\n",
      "Learning Rate: 8.121663681237296e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0068\n",
      "shared_transformer_blocks: 0.0175\n",
      "structure_head: 0.0680\n",
      "Class 0 - Precision: 0.6800, Recall: 0.3269, F1-Score: 0.4416\n",
      "Class 1 - Precision: 0.3438, Recall: 0.5789, F1-Score: 0.4314\n",
      "Class 2 - Precision: 0.3333, Recall: 0.5789, F1-Score: 0.4231\n",
      "Validation Loss: 0.2441, Accuracy: 0.4333, F1: 0.4320\n",
      "Best model saved with validation loss: 0.2441\n",
      "\n",
      "\n",
      "Epoch 26, Training Loss: 3.5104\n",
      "Learning Rate: 8.621228248763702e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0066\n",
      "shared_transformer_blocks: 0.0230\n",
      "structure_head: 0.0859\n",
      "Class 0 - Precision: 0.6279, Recall: 0.5192, F1-Score: 0.5684\n",
      "Class 1 - Precision: 0.3600, Recall: 0.4737, F1-Score: 0.4091\n",
      "Class 2 - Precision: 0.2727, Recall: 0.3158, F1-Score: 0.2927\n",
      "Validation Loss: 0.7019, Accuracy: 0.4667, F1: 0.4234\n",
      "\n",
      "\n",
      "Epoch 27, Training Loss: 1.7063\n",
      "Learning Rate: 9.12583493807627e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0046\n",
      "shared_transformer_blocks: 0.0113\n",
      "structure_head: 0.0379\n",
      "Class 0 - Precision: 0.6290, Recall: 0.7500, F1-Score: 0.6842\n",
      "Class 1 - Precision: 0.3077, Recall: 0.2105, F1-Score: 0.2500\n",
      "Class 2 - Precision: 0.3333, Recall: 0.2632, F1-Score: 0.2941\n",
      "Validation Loss: 0.5176, Accuracy: 0.5333, F1: 0.4094\n",
      "\n",
      "\n",
      "Epoch 28, Training Loss: 1.7771\n",
      "Learning Rate: 9.634053386690403e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0036\n",
      "shared_transformer_blocks: 0.0102\n",
      "structure_head: 0.0345\n",
      "Class 0 - Precision: 0.5867, Recall: 0.8462, F1-Score: 0.6929\n",
      "Class 1 - Precision: 0.2000, Recall: 0.0526, F1-Score: 0.0833\n",
      "Class 2 - Precision: 0.4000, Recall: 0.2105, F1-Score: 0.2759\n",
      "Validation Loss: 1.0443, Accuracy: 0.5444, F1: 0.3507\n",
      "\n",
      "\n",
      "Epoch 29, Training Loss: 1.6595\n",
      "Learning Rate: 0.00010144442994197362\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0087\n",
      "shared_transformer_blocks: 0.0312\n",
      "structure_head: 0.1214\n",
      "Class 0 - Precision: 0.5867, Recall: 0.8462, F1-Score: 0.6929\n",
      "Class 1 - Precision: 0.2000, Recall: 0.0526, F1-Score: 0.0833\n",
      "Class 2 - Precision: 0.4000, Recall: 0.2105, F1-Score: 0.2759\n",
      "Validation Loss: 1.0432, Accuracy: 0.5444, F1: 0.3507\n",
      "\n",
      "\n",
      "Epoch 30, Training Loss: 2.7062\n",
      "Learning Rate: 0.00010655557005802638\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0071\n",
      "shared_transformer_blocks: 0.0211\n",
      "structure_head: 0.0781\n",
      "Class 0 - Precision: 0.5781, Recall: 0.7115, F1-Score: 0.6379\n",
      "Class 1 - Precision: 0.2857, Recall: 0.2105, F1-Score: 0.2424\n",
      "Class 2 - Precision: 0.3333, Recall: 0.2105, F1-Score: 0.2581\n",
      "Validation Loss: 0.5777, Accuracy: 0.5000, F1: 0.3795\n",
      "\n",
      "\n",
      "Epoch 31, Training Loss: 4.2842\n",
      "Learning Rate: 0.000111659466133096\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0062\n",
      "shared_transformer_blocks: 0.0150\n",
      "structure_head: 0.0525\n",
      "Class 0 - Precision: 0.6000, Recall: 0.5192, F1-Score: 0.5567\n",
      "Class 1 - Precision: 0.3333, Recall: 0.4211, F1-Score: 0.3721\n",
      "Class 2 - Precision: 0.3333, Recall: 0.3684, F1-Score: 0.3500\n",
      "Validation Loss: 0.4135, Accuracy: 0.4667, F1: 0.4263\n",
      "\n",
      "\n",
      "Epoch 32, Training Loss: -1.0686\n",
      "Learning Rate: 0.0001167416506192373\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0048\n",
      "shared_transformer_blocks: 0.0128\n",
      "structure_head: 0.0466\n",
      "Class 0 - Precision: 0.6333, Recall: 0.3654, F1-Score: 0.4634\n",
      "Class 1 - Precision: 0.3103, Recall: 0.4737, F1-Score: 0.3750\n",
      "Class 2 - Precision: 0.2903, Recall: 0.4737, F1-Score: 0.3600\n",
      "Validation Loss: 0.6620, Accuracy: 0.4111, F1: 0.3995\n",
      "\n",
      "\n",
      "Epoch 33, Training Loss: 1.8987\n",
      "Learning Rate: 0.00012178771751236296\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0062\n",
      "shared_transformer_blocks: 0.0164\n",
      "structure_head: 0.0584\n",
      "Class 0 - Precision: 0.7333, Recall: 0.2115, F1-Score: 0.3284\n",
      "Class 1 - Precision: 0.3030, Recall: 0.5263, F1-Score: 0.3846\n",
      "Class 2 - Precision: 0.2857, Recall: 0.6316, F1-Score: 0.3934\n",
      "Validation Loss: 2.1654, Accuracy: 0.3667, F1: 0.3688\n",
      "\n",
      "\n",
      "Epoch 34, Training Loss: 4.1515\n",
      "Learning Rate: 0.00012678336318762705\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0055\n",
      "shared_transformer_blocks: 0.0170\n",
      "structure_head: 0.0628\n",
      "Class 0 - Precision: 0.7692, Recall: 0.1923, F1-Score: 0.3077\n",
      "Class 1 - Precision: 0.2941, Recall: 0.5263, F1-Score: 0.3774\n",
      "Class 2 - Precision: 0.3023, Recall: 0.6842, F1-Score: 0.4194\n",
      "Validation Loss: 2.1225, Accuracy: 0.3667, F1: 0.3681\n",
      "\n",
      "\n",
      "Epoch 35, Training Loss: 3.4483\n",
      "Learning Rate: 0.0001317144269446036\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0047\n",
      "shared_transformer_blocks: 0.0144\n",
      "structure_head: 0.0542\n",
      "Class 0 - Precision: 0.6471, Recall: 0.2115, F1-Score: 0.3188\n",
      "Class 1 - Precision: 0.2941, Recall: 0.5263, F1-Score: 0.3774\n",
      "Class 2 - Precision: 0.2821, Recall: 0.5789, F1-Score: 0.3793\n",
      "Validation Loss: 1.4316, Accuracy: 0.3556, F1: 0.3585\n",
      "\n",
      "\n",
      "Epoch 36, Training Loss: 0.7611\n",
      "Learning Rate: 0.00013656693114733092\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0097\n",
      "shared_transformer_blocks: 0.0245\n",
      "structure_head: 0.0946\n",
      "Class 0 - Precision: 0.6250, Recall: 0.4808, F1-Score: 0.5435\n",
      "Class 1 - Precision: 0.3226, Recall: 0.5263, F1-Score: 0.4000\n",
      "Class 2 - Precision: 0.2632, Recall: 0.2632, F1-Score: 0.2632\n",
      "Validation Loss: 2.8471, Accuracy: 0.4444, F1: 0.4022\n",
      "\n",
      "\n",
      "Epoch 37, Training Loss: 4.4271\n",
      "Learning Rate: 0.00014132712084543878\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0091\n",
      "shared_transformer_blocks: 0.0274\n",
      "structure_head: 0.1049\n",
      "Class 0 - Precision: 0.6486, Recall: 0.4615, F1-Score: 0.5393\n",
      "Class 1 - Precision: 0.3125, Recall: 0.5263, F1-Score: 0.3922\n",
      "Class 2 - Precision: 0.3333, Recall: 0.3684, F1-Score: 0.3500\n",
      "Validation Loss: 2.5465, Accuracy: 0.4556, F1: 0.4272\n",
      "\n",
      "\n",
      "Epoch 38, Training Loss: 10.2437\n",
      "Learning Rate: 0.00014598150276405012\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0078\n",
      "shared_transformer_blocks: 0.0141\n",
      "structure_head: 0.0520\n",
      "Class 0 - Precision: 0.6471, Recall: 0.4231, F1-Score: 0.5116\n",
      "Class 1 - Precision: 0.3125, Recall: 0.5263, F1-Score: 0.3922\n",
      "Class 2 - Precision: 0.2917, Recall: 0.3684, F1-Score: 0.3256\n",
      "Validation Loss: 1.9415, Accuracy: 0.4333, F1: 0.4098\n",
      "\n",
      "\n",
      "Epoch 39, Training Loss: 6.7267\n",
      "Learning Rate: 0.00015051688355193442\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0067\n",
      "shared_transformer_blocks: 0.0150\n",
      "structure_head: 0.0510\n",
      "Class 0 - Precision: 0.6818, Recall: 0.2885, F1-Score: 0.4054\n",
      "Class 1 - Precision: 0.3226, Recall: 0.5263, F1-Score: 0.4000\n",
      "Class 2 - Precision: 0.2973, Recall: 0.5789, F1-Score: 0.3929\n",
      "Validation Loss: 1.3333, Accuracy: 0.4000, F1: 0.3994\n",
      "\n",
      "\n",
      "Epoch 40, Training Loss: 3.5294\n",
      "Learning Rate: 0.00015492040717949527\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0086\n",
      "shared_transformer_blocks: 0.0217\n",
      "structure_head: 0.0818\n",
      "Class 0 - Precision: 0.6667, Recall: 0.3462, F1-Score: 0.4557\n",
      "Class 1 - Precision: 0.3214, Recall: 0.4737, F1-Score: 0.3830\n",
      "Class 2 - Precision: 0.3429, Recall: 0.6316, F1-Score: 0.4444\n",
      "Validation Loss: 1.5322, Accuracy: 0.4333, F1: 0.4277\n",
      "\n",
      "\n",
      "Epoch 41, Training Loss: -0.8730\n",
      "Learning Rate: 0.00015917959138058306\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0063\n",
      "shared_transformer_blocks: 0.0140\n",
      "structure_head: 0.0452\n",
      "Class 0 - Precision: 0.6154, Recall: 0.4615, F1-Score: 0.5275\n",
      "Class 1 - Precision: 0.3750, Recall: 0.4737, F1-Score: 0.4186\n",
      "Class 2 - Precision: 0.3704, Recall: 0.5263, F1-Score: 0.4348\n",
      "Validation Loss: 0.5333, Accuracy: 0.4778, F1: 0.4603\n",
      "\n",
      "\n",
      "Epoch 42, Training Loss: 4.0652\n",
      "Learning Rate: 0.00016328236303483443\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0088\n",
      "shared_transformer_blocks: 0.0230\n",
      "structure_head: 0.0757\n",
      "Class 0 - Precision: 0.6429, Recall: 0.3462, F1-Score: 0.4500\n",
      "Class 1 - Precision: 0.3438, Recall: 0.5789, F1-Score: 0.4314\n",
      "Class 2 - Precision: 0.4000, Recall: 0.6316, F1-Score: 0.4898\n",
      "Validation Loss: 0.4196, Accuracy: 0.4556, F1: 0.4571\n",
      "\n",
      "\n",
      "Epoch 43, Training Loss: -0.1550\n",
      "Learning Rate: 0.00016721709239024373\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0078\n",
      "shared_transformer_blocks: 0.0136\n",
      "structure_head: 0.0438\n",
      "Class 0 - Precision: 0.7143, Recall: 0.2885, F1-Score: 0.4110\n",
      "Class 1 - Precision: 0.3714, Recall: 0.6842, F1-Score: 0.4815\n",
      "Class 2 - Precision: 0.4118, Recall: 0.7368, F1-Score: 0.5283\n",
      "Validation Loss: 0.0170, Accuracy: 0.4667, F1: 0.4736\n",
      "Best model saved with validation loss: 0.0170\n",
      "\n",
      "\n",
      "Epoch 44, Training Loss: 6.7096\n",
      "Learning Rate: 0.00017097262602895852\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0086\n",
      "shared_transformer_blocks: 0.0191\n",
      "structure_head: 0.0675\n",
      "Class 0 - Precision: 0.7083, Recall: 0.3269, F1-Score: 0.4474\n",
      "Class 1 - Precision: 0.3214, Recall: 0.4737, F1-Score: 0.3830\n",
      "Class 2 - Precision: 0.3947, Recall: 0.7895, F1-Score: 0.5263\n",
      "Validation Loss: 1.9762, Accuracy: 0.4556, F1: 0.4522\n",
      "\n",
      "\n",
      "Epoch 45, Training Loss: -0.3775\n",
      "Learning Rate: 0.00017453831848285444\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0071\n",
      "shared_transformer_blocks: 0.0118\n",
      "structure_head: 0.0402\n",
      "Class 0 - Precision: 0.6897, Recall: 0.3846, F1-Score: 0.4938\n",
      "Class 1 - Precision: 0.3182, Recall: 0.3684, F1-Score: 0.3415\n",
      "Class 2 - Precision: 0.3846, Recall: 0.7895, F1-Score: 0.5172\n",
      "Validation Loss: 3.1884, Accuracy: 0.4667, F1: 0.4508\n",
      "\n",
      "\n",
      "Epoch 46, Training Loss: 4.9869\n",
      "Learning Rate: 0.00017790406240927103\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0090\n",
      "shared_transformer_blocks: 0.0138\n",
      "structure_head: 0.0522\n",
      "Class 0 - Precision: 0.6552, Recall: 0.3654, F1-Score: 0.4691\n",
      "Class 1 - Precision: 0.2857, Recall: 0.3158, F1-Score: 0.3000\n",
      "Class 2 - Precision: 0.3250, Recall: 0.6842, F1-Score: 0.4407\n",
      "Validation Loss: 3.7537, Accuracy: 0.4222, F1: 0.4033\n",
      "\n",
      "\n",
      "Epoch 47, Training Loss: 13.1317\n",
      "Learning Rate: 0.0001810603172413725\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0071\n",
      "shared_transformer_blocks: 0.0161\n",
      "structure_head: 0.0584\n",
      "Class 0 - Precision: 0.6341, Recall: 0.5000, F1-Score: 0.5591\n",
      "Class 1 - Precision: 0.2727, Recall: 0.3158, F1-Score: 0.2927\n",
      "Class 2 - Precision: 0.3704, Recall: 0.5263, F1-Score: 0.4348\n",
      "Validation Loss: 1.1175, Accuracy: 0.4667, F1: 0.4289\n",
      "\n",
      "\n",
      "Epoch 48, Training Loss: 2.9333\n",
      "Learning Rate: 0.00018399813623192146\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0096\n",
      "shared_transformer_blocks: 0.0195\n",
      "structure_head: 0.0624\n",
      "Class 0 - Precision: 0.6429, Recall: 0.5192, F1-Score: 0.5745\n",
      "Class 1 - Precision: 0.3750, Recall: 0.6316, F1-Score: 0.4706\n",
      "Class 2 - Precision: 0.3125, Recall: 0.2632, F1-Score: 0.2857\n",
      "Validation Loss: 3.8540, Accuracy: 0.4889, F1: 0.4436\n",
      "\n",
      "\n",
      "Epoch 49, Training Loss: 8.7876\n",
      "Learning Rate: 0.00018670919181380542\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0092\n",
      "shared_transformer_blocks: 0.0164\n",
      "structure_head: 0.0581\n",
      "Class 0 - Precision: 0.6444, Recall: 0.5577, F1-Score: 0.5979\n",
      "Class 1 - Precision: 0.3636, Recall: 0.6316, F1-Score: 0.4615\n",
      "Class 2 - Precision: 0.4167, Recall: 0.2632, F1-Score: 0.3226\n",
      "Validation Loss: 4.8587, Accuracy: 0.5111, F1: 0.4607\n",
      "\n",
      "\n",
      "Epoch 50, Training Loss: 12.3284\n",
      "Learning Rate: 0.00018918579920543086\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0081\n",
      "shared_transformer_blocks: 0.0197\n",
      "structure_head: 0.0664\n",
      "Class 0 - Precision: 0.6154, Recall: 0.4615, F1-Score: 0.5275\n",
      "Class 1 - Precision: 0.2692, Recall: 0.3684, F1-Score: 0.3111\n",
      "Class 2 - Precision: 0.3200, Recall: 0.4211, F1-Score: 0.3636\n",
      "Validation Loss: 0.6551, Accuracy: 0.4333, F1: 0.4007\n",
      "\n",
      "\n",
      "Epoch 51, Training Loss: -1.0216\n",
      "Learning Rate: 0.00019142093819407167\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0055\n",
      "shared_transformer_blocks: 0.0122\n",
      "structure_head: 0.0462\n",
      "Class 0 - Precision: 0.6333, Recall: 0.3654, F1-Score: 0.4634\n",
      "Class 1 - Precision: 0.2381, Recall: 0.2632, F1-Score: 0.2500\n",
      "Class 2 - Precision: 0.3077, Recall: 0.6316, F1-Score: 0.4138\n",
      "Validation Loss: 3.6635, Accuracy: 0.4000, F1: 0.3757\n",
      "\n",
      "\n",
      "Epoch 52, Training Loss: 11.5367\n",
      "Learning Rate: 0.0001934082730354245\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0090\n",
      "shared_transformer_blocks: 0.0218\n",
      "structure_head: 0.0812\n",
      "Class 0 - Precision: 0.6316, Recall: 0.4615, F1-Score: 0.5333\n",
      "Class 1 - Precision: 0.2381, Recall: 0.2632, F1-Score: 0.2500\n",
      "Class 2 - Precision: 0.3226, Recall: 0.5263, F1-Score: 0.4000\n",
      "Validation Loss: 2.1582, Accuracy: 0.4333, F1: 0.3944\n",
      "\n",
      "\n",
      "Epoch 53, Training Loss: 5.4486\n",
      "Learning Rate: 0.00019514217041296462\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0081\n",
      "shared_transformer_blocks: 0.0173\n",
      "structure_head: 0.0552\n",
      "Class 0 - Precision: 0.6176, Recall: 0.4038, F1-Score: 0.4884\n",
      "Class 1 - Precision: 0.3333, Recall: 0.6316, F1-Score: 0.4364\n",
      "Class 2 - Precision: 0.3500, Recall: 0.3684, F1-Score: 0.3590\n",
      "Validation Loss: 3.7372, Accuracy: 0.4444, F1: 0.4279\n",
      "\n",
      "\n",
      "Epoch 54, Training Loss: 8.9424\n",
      "Learning Rate: 0.00019661771540619355\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0072\n",
      "shared_transformer_blocks: 0.0167\n",
      "structure_head: 0.0533\n",
      "Class 0 - Precision: 0.5897, Recall: 0.4423, F1-Score: 0.5055\n",
      "Class 1 - Precision: 0.3714, Recall: 0.6842, F1-Score: 0.4815\n",
      "Class 2 - Precision: 0.3125, Recall: 0.2632, F1-Score: 0.2857\n",
      "Validation Loss: 4.0918, Accuracy: 0.4556, F1: 0.4242\n",
      "\n",
      "\n",
      "Epoch 55, Training Loss: 13.6855\n",
      "Learning Rate: 0.0001978307254225152\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0066\n",
      "shared_transformer_blocks: 0.0163\n",
      "structure_head: 0.0658\n",
      "Class 0 - Precision: 0.5532, Recall: 0.5000, F1-Score: 0.5253\n",
      "Class 1 - Precision: 0.2917, Recall: 0.3684, F1-Score: 0.3256\n",
      "Class 2 - Precision: 0.4211, Recall: 0.4211, F1-Score: 0.4211\n",
      "Validation Loss: 0.8519, Accuracy: 0.4556, F1: 0.4240\n",
      "\n",
      "\n",
      "Epoch 56, Training Loss: 5.6244\n",
      "Learning Rate: 0.0001987777620532491\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0050\n",
      "shared_transformer_blocks: 0.0101\n",
      "structure_head: 0.0340\n",
      "Class 0 - Precision: 0.5424, Recall: 0.6154, F1-Score: 0.5766\n",
      "Class 1 - Precision: 0.3333, Recall: 0.2632, F1-Score: 0.2941\n",
      "Class 2 - Precision: 0.3125, Recall: 0.2632, F1-Score: 0.2857\n",
      "Validation Loss: 0.0355, Accuracy: 0.4667, F1: 0.3855\n",
      "\n",
      "\n",
      "Epoch 57, Training Loss: 8.9302\n",
      "Learning Rate: 0.00019945614082017316\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0064\n",
      "shared_transformer_blocks: 0.0133\n",
      "structure_head: 0.0472\n",
      "Class 0 - Precision: 0.5574, Recall: 0.6538, F1-Score: 0.6018\n",
      "Class 1 - Precision: 0.3571, Recall: 0.2632, F1-Score: 0.3030\n",
      "Class 2 - Precision: 0.3333, Recall: 0.2632, F1-Score: 0.2941\n",
      "Validation Loss: 0.0523, Accuracy: 0.4889, F1: 0.3996\n",
      "\n",
      "\n",
      "Epoch 58, Training Loss: 0.6215\n",
      "Learning Rate: 0.00019986393878496916\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0123\n",
      "shared_transformer_blocks: 0.0272\n",
      "structure_head: 0.0979\n",
      "Class 0 - Precision: 0.6471, Recall: 0.4231, F1-Score: 0.5116\n",
      "Class 1 - Precision: 0.3103, Recall: 0.4737, F1-Score: 0.3750\n",
      "Class 2 - Precision: 0.3333, Recall: 0.4737, F1-Score: 0.3913\n",
      "Validation Loss: 0.6998, Accuracy: 0.4444, F1: 0.4260\n",
      "\n",
      "\n",
      "Epoch 59, Training Loss: 0.5754\n",
      "Learning Rate: 0.0002\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0082\n",
      "shared_transformer_blocks: 0.0183\n",
      "structure_head: 0.0622\n",
      "Class 0 - Precision: 0.6061, Recall: 0.3846, F1-Score: 0.4706\n",
      "Class 1 - Precision: 0.3421, Recall: 0.6842, F1-Score: 0.4561\n",
      "Class 2 - Precision: 0.2632, Recall: 0.2632, F1-Score: 0.2632\n",
      "Validation Loss: 4.7056, Accuracy: 0.4222, F1: 0.3966\n",
      "\n",
      "\n",
      "Epoch 60, Training Loss: 12.3111\n",
      "Learning Rate: 0.0001999748235949567\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0132\n",
      "shared_transformer_blocks: 0.0298\n",
      "structure_head: 0.0938\n",
      "Class 0 - Precision: 0.5238, Recall: 0.6346, F1-Score: 0.5739\n",
      "Class 1 - Precision: 0.2353, Recall: 0.2105, F1-Score: 0.2222\n",
      "Class 2 - Precision: 0.3000, Recall: 0.1579, F1-Score: 0.2069\n",
      "Validation Loss: 1.7611, Accuracy: 0.4444, F1: 0.3343\n",
      "\n",
      "\n",
      "Epoch 61, Training Loss: 4.1839\n",
      "Learning Rate: 0.00019989930705690485\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0178\n",
      "shared_transformer_blocks: 0.0408\n",
      "structure_head: 0.1282\n",
      "Class 0 - Precision: 0.5778, Recall: 0.5000, F1-Score: 0.5361\n",
      "Class 1 - Precision: 0.3462, Recall: 0.4737, F1-Score: 0.4000\n",
      "Class 2 - Precision: 0.3158, Recall: 0.3158, F1-Score: 0.3158\n",
      "Validation Loss: 1.5969, Accuracy: 0.4556, F1: 0.4173\n",
      "\n",
      "\n",
      "Epoch 62, Training Loss: 6.7275\n",
      "Learning Rate: 0.0001997734884106956\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0090\n",
      "shared_transformer_blocks: 0.0137\n",
      "structure_head: 0.0463\n",
      "Class 0 - Precision: 0.6364, Recall: 0.4038, F1-Score: 0.4941\n",
      "Class 1 - Precision: 0.3333, Recall: 0.4737, F1-Score: 0.3913\n",
      "Class 2 - Precision: 0.3333, Recall: 0.5263, F1-Score: 0.4082\n",
      "Validation Loss: 0.5656, Accuracy: 0.4444, F1: 0.4312\n",
      "\n",
      "\n",
      "Epoch 63, Training Loss: 3.7709\n",
      "Learning Rate: 0.00019959743100980633\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0126\n",
      "shared_transformer_blocks: 0.0277\n",
      "structure_head: 0.0881\n",
      "Class 0 - Precision: 0.5625, Recall: 0.5192, F1-Score: 0.5400\n",
      "Class 1 - Precision: 0.3043, Recall: 0.3684, F1-Score: 0.3333\n",
      "Class 2 - Precision: 0.3158, Recall: 0.3158, F1-Score: 0.3158\n",
      "Validation Loss: 1.0778, Accuracy: 0.4444, F1: 0.3964\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, train_accuracies = [], [], []\n",
    "val_losses, val_f1s, val_accuracies = [], [], []\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    layer_grad_norms = {}  # Dictionary to accumulate grad norms by layer\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_X, batch_y_struct in train_dataloader:\n",
    "        batch_X, batch_y_struct = batch_X.to(device), batch_y_struct.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred_struct = model(batch_X)\n",
    "\n",
    "        # Loss computation\n",
    "        loss = loss_fn_struct(pred_struct.view(-1, 3), batch_y_struct.view(-1))\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate gradient norms by layer name\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                layer_name = name.split('.')[0]  # Use only the first part as layer name\n",
    "                grad_norm = param.grad.norm().item()\n",
    "                if layer_name not in layer_grad_norms:\n",
    "                    layer_grad_norms[layer_name] = []\n",
    "                layer_grad_norms[layer_name].append(grad_norm)\n",
    "\n",
    "        # Gradient clipping\n",
    "        nn_utils.clip_grad_value_(model.parameters(), clip_value=0.1)\n",
    "\n",
    "        # Optimizer and scheduler step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        y_true = batch_y_struct.view(-1)\n",
    "        y_pred = torch.argmax(pred_struct.view(-1, 3), dim=-1)\n",
    "        all_true_labels.append(y_true.cpu())\n",
    "        all_predicted_labels.append(y_pred.cpu())\n",
    "\n",
    "        # Calculate correct predictions\n",
    "        correct_preds += (y_pred == y_true).sum().item()\n",
    "        total_preds += y_true.numel()\n",
    "\n",
    "    # Calculate training metrics\n",
    "    avg_loss = total_loss / num_batches\n",
    "    all_true_labels = torch.cat(all_true_labels)\n",
    "    all_predicted_labels = torch.cat(all_predicted_labels)\n",
    "    train_metrics = calculate_class_metrics(all_true_labels, all_predicted_labels)\n",
    "    avg_train_f1 = print_validation_metrics(train_metrics, printer=False)\n",
    "    accuracy = correct_preds / total_preds\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    train_f1s.append(avg_train_f1)\n",
    "\n",
    "    # Calculate average gradient norms per layer\n",
    "    avg_layer_grad_norms = {layer: sum(norms) / len(norms) for layer, norms in layer_grad_norms.items()}\n",
    "\n",
    "    # Print epoch summary with average layer gradient norms\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    print(\"Average Gradient Norms per Layer:\")\n",
    "    for layer, avg_norm in avg_layer_grad_norms.items():\n",
    "        print(f\"{layer}: {avg_norm:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y_struct in val_dataloader:\n",
    "            val_X, val_y_struct = val_X.to(device), val_y_struct.to(device)\n",
    "            val_pred_struct = model(val_X)\n",
    "            val_loss += loss_fn_struct(val_pred_struct.view(-1, 3), val_y_struct.view(-1)).item()\n",
    "\n",
    "            # Collect true and predicted labels\n",
    "            y_true = val_y_struct.view(-1)\n",
    "            y_pred = torch.argmax(val_pred_struct.view(-1, 3), dim=-1)\n",
    "            all_y_true.append(y_true.cpu())\n",
    "            all_y_pred.append(y_pred.cpu())\n",
    "\n",
    "            # Calculate correct predictions\n",
    "            correct_preds += (y_pred == y_true).sum().item()\n",
    "            total_preds += y_true.numel()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    all_y_true = torch.cat(all_y_true)\n",
    "    all_y_pred = torch.cat(all_y_pred)\n",
    "    val_metrics = calculate_class_metrics(all_y_true, all_y_pred)\n",
    "    avg_val_f1 = print_validation_metrics(val_metrics)\n",
    "    val_accuracy = correct_preds / total_preds\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1s.append(avg_val_f1)\n",
    "\n",
    "    # Print validation summary\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {avg_val_f1:.4f}\")\n",
    "\n",
    "    # Check for early stopping and save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"12-2_integerenc.pth\")\n",
    "        print(f\"Best model saved with validation loss: {avg_val_loss:.4f}\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95506223-06ce-4790-b203-3716533b0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to save each of the lists\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Save lists to CSV files with filenames related to the model name\n",
    "model_name = \"12-2_integerenc\"\n",
    "\n",
    "# Create a dictionary for each list to be saved\n",
    "data_to_save = {\n",
    "    f\"{model_name}_train_losses.csv\": train_losses,\n",
    "    f\"{model_name}_train_f1s.csv\": train_f1s,\n",
    "    f\"{model_name}_train_accuracies.csv\": train_accuracies,\n",
    "    f\"{model_name}_val_losses.csv\": val_losses,\n",
    "    f\"{model_name}_val_f1s.csv\": val_f1s,\n",
    "    f\"{model_name}_val_accuracies.csv\": val_accuracies,\n",
    "}\n",
    "\n",
    "# Loop through each list and save it as a CSV\n",
    "for filename, data_list in data_to_save.items():\n",
    "    # Convert list to DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=[filename.split('_')[-1].split('.')[0]])  # Use the metric name as column\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "print(\"Metrics saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db47ef-18ea-4b74-b0ad-1bd7d2e10fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d90d28-7d25-48f2-96b5-7f9ebc5a15ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83bc70f-6404-4432-8519-f5b8ae844ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model_path = \"12-2-integerenc.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Function to decode structure\n",
    "def decode_structure(encoded):\n",
    "    structure_mapping = {0: '.', 1: '(', 2: ')', 3: '-'}  # '-' represents padding\n",
    "    return ''.join([structure_mapping[code.item()] for code in encoded])\n",
    "\n",
    "def enforce_symmetry_and_minimum_distance(pred_structure, min_distance=3):\n",
    "    stack = []\n",
    "    for i, char in enumerate(pred_structure):\n",
    "        if char == '(':\n",
    "            stack.append(i)\n",
    "        elif char == ')':\n",
    "            if stack:\n",
    "                opening_index = stack.pop()\n",
    "                # Enforce minimum distance rule\n",
    "                if i - opening_index - 1 < min_distance or ''.join(pred_structure[opening_index + 1:i]).count('.') < min_distance:\n",
    "                    # Replace invalid pair with dots\n",
    "                    pred_structure[opening_index] = '.'\n",
    "                    pred_structure[i] = '.'\n",
    "    # Replace unmatched '(' with '.'\n",
    "    for i in stack:\n",
    "        pred_structure[i] = '.'\n",
    "    return pred_structure\n",
    "\n",
    "\n",
    "\n",
    "# Pick some sequences from the validation set\n",
    "num_test_sequences = 50  # Number of sequences to test\n",
    "val_sequences = X_val[:num_test_sequences]\n",
    "val_structures = y_struct_val[:num_test_sequences]\n",
    "\n",
    "# Run predictions and compare with ground truth\n",
    "print(\"Testing the model on some sequences from the validation set:\")\n",
    "with torch.no_grad():\n",
    "    for i, (sequence, true_structure) in enumerate(zip(val_sequences, val_structures)):\n",
    "        sequence = sequence.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        true_structure = true_structure.to(device)\n",
    "        \n",
    "        # Predict structure\n",
    "        pred_structure_logits = model(sequence, true_structure.unsqueeze(0))\n",
    "        pred_structure = torch.argmax(pred_structure_logits.view(-1, 3), dim=-1)\n",
    "        \n",
    "        # Decode sequence and structures\n",
    "        decoded_sequence = ''.join([list('ATCG-')[x.item()] for x in sequence[0]])  # Decode sequence\n",
    "        decoded_true_structure = decode_structure(true_structure)\n",
    "        decoded_pred_structure = decode_structure(pred_structure)\n",
    "\n",
    "        # Enforce symmetry and minimum distance rule\n",
    "        decoded_pred_structure = enforce_symmetry_and_minimum_distance(list(decoded_pred_structure))\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\nSequence {i + 1}: {decoded_sequence}\")\n",
    "        print(f\"True Structure:    {decoded_true_structure}\")\n",
    "        print(f\"Predicted Structure: {''.join(decoded_pred_structure)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad42b62-2112-4dbc-babf-7ad0ce1a71bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd878a-7427-4e67-ac28-73ca3c8d160b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
