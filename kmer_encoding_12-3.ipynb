{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83acf3e0-07d8-4d89-b480-db1c78c056ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of combined dataset after filtering: 1294216\n",
      "Training set size: 1292921\n",
      "Test set size: 1295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load all datasets\n",
    "with open('database1_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database1_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database2_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database2_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database3_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database3_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database4_1structsonly_34ave.pkl', 'rb') as file:\n",
    "    database4_1structsonly_34ave = pickle.load(file)\n",
    "\n",
    "with open('database5_1structsonly_50ave.pkl', 'rb') as file:\n",
    "    database5_1structsonly_50ave = pickle.load(file)\n",
    "\n",
    "with open('database6_allstructs_50ave.pkl', 'rb') as file:\n",
    "    database6_allstructs_50ave = pickle.load(file)\n",
    "\n",
    "with open('database7_allstructs_50ave.pkl', 'rb') as file:\n",
    "    database7_allstructs_50ave = pickle.load(file)\n",
    "\n",
    "with open('database9_allstructs_40ave.pkl', 'rb') as file:\n",
    "    database9_allstructs_40ave = pickle.load(file)\n",
    "\n",
    "with open('database10_allstructs_40ave.pkl', 'rb') as file:\n",
    "    database10_allstructs_40ave = pickle.load(file)\n",
    "\n",
    "with open('database11_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database11_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database13_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database13_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database14_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database14_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database15_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database15_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database16_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database16_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database17_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database17_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database18_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database18_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database19_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database19_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database20_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database20_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database21_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database21_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database22_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database22_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database23_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database23_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database24_allstructs_45only.pkl', 'rb') as file:\n",
    "    database24_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database25_allstructs_45only.pkl', 'rb') as file:\n",
    "    database25_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database26_allstructs_45only.pkl', 'rb') as file:\n",
    "    database26_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database27_allstructs_45only.pkl', 'rb') as file:\n",
    "    database27_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database28_allstructs_45only.pkl', 'rb') as file:\n",
    "    database28_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database29_allstructs_45only.pkl', 'rb') as file:\n",
    "    database29_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database30_allstructs_45only.pkl', 'rb') as file:\n",
    "    database30_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database31_allstructs_45only.pkl', 'rb') as file:\n",
    "    database31_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database32_allstructs_45only.pkl', 'rb') as file:\n",
    "    database32_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database33_allstructs_45only.pkl', 'rb') as file:\n",
    "    database33_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database34_allstructs_45only.pkl', 'rb') as file:\n",
    "    database34_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database35_allstructs_45only.pkl', 'rb') as file:\n",
    "    database35_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database36_allstructs_45only.pkl', 'rb') as file:\n",
    "    database36_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database37_allstructs_45only.pkl', 'rb') as file:\n",
    "    database37_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database38_allstructs_45only.pkl', 'rb') as file:\n",
    "    database38_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database39_allstructs_45only.pkl', 'rb') as file:\n",
    "    database39_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database40_allstructs_45only.pkl', 'rb') as file:\n",
    "    database40_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database41_allstructs_45only.pkl', 'rb') as file:\n",
    "    database41_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database42_allstructs_45only.pkl', 'rb') as file:\n",
    "    database42_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database43_allstructs_45only.pkl', 'rb') as file:\n",
    "    database43_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database44_allstructs_45only.pkl', 'rb') as file:\n",
    "    database44_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database45_allstructs_45only.pkl', 'rb') as file:\n",
    "    database45_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database46_allstructs_45only.pkl', 'rb') as file:\n",
    "    database46_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database47_allstructs_45only.pkl', 'rb') as file:\n",
    "    database47_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database48_allstructs_45only.pkl', 'rb') as file:\n",
    "    database48_allstructs_45only = pickle.load(file)\n",
    "    \n",
    "\n",
    "# Combine datasets into a single dictionary\n",
    "combined_data = {}\n",
    "datasets = [\n",
    "    database1_allstructs_34ave, database2_allstructs_34ave, database3_allstructs_34ave,\n",
    "    database4_1structsonly_34ave, database5_1structsonly_50ave, database6_allstructs_50ave,\n",
    "    database7_allstructs_50ave, database9_allstructs_40ave, database10_allstructs_40ave, \n",
    "    database11_allstructs_45ave, database13_allstructs_45ave, database14_allstructs_45ave,\n",
    "    database15_allstructs_45ave, database16_allstructs_45ave, database17_allstructs_45ave,\n",
    "    database18_allstructs_45ave, database19_allstructs_45ave, database20_allstructs_45ave,\n",
    "    database21_allstructs_45ave, database22_allstructs_45ave, database23_allstructs_45ave,\n",
    "    database24_allstructs_45only, database25_allstructs_45only, database26_allstructs_45only,\n",
    "    database27_allstructs_45only, database28_allstructs_45only, database29_allstructs_45only,\n",
    "    database30_allstructs_45only, database31_allstructs_45only, database32_allstructs_45only,\n",
    "    database33_allstructs_45only, database34_allstructs_45only, database35_allstructs_45only,\n",
    "    database36_allstructs_45only, database37_allstructs_45only, database38_allstructs_45only,\n",
    "    database39_allstructs_45only, database40_allstructs_45only, database41_allstructs_45only,\n",
    "    database42_allstructs_45only, database43_allstructs_45only, database44_allstructs_45only,\n",
    "    database45_allstructs_45only, database46_allstructs_45only, database47_allstructs_45only,\n",
    "    database48_allstructs_45only\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seq, (temp, structs) in dataset.items():\n",
    "        # Only include if melting temperature is defined and above 20\n",
    "        if temp is not None:\n",
    "            combined_data[seq] = (temp, structs)\n",
    "\n",
    "combined_data2 = {}\n",
    "for i, j in combined_data.items():\n",
    "    if len(i) == len(j[1][-1]):\n",
    "        combined_data2[i] = j\n",
    "\n",
    "combined_data = combined_data2\n",
    "\n",
    "# Verify combined data size after filtering\n",
    "print(f\"Total size of combined dataset after filtering: {len(combined_data)}\")\n",
    "\n",
    "# Prepare data for train-test split\n",
    "sequences = list(combined_data.keys())\n",
    "labels = list(combined_data.values())\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% test)\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    sequences, labels, test_size=0.001, random_state=42\n",
    ")\n",
    "\n",
    "# Create train and test sets as dictionaries\n",
    "train_set = {seq: label for seq, label in zip(train_sequences, train_labels)}\n",
    "test_set = {seq: label for seq, label in zip(test_sequences, test_labels)}\n",
    "\n",
    "# Display the split summary\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "994de9d2-83ea-4ca5-ba13-cdd20810a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, j in train_set.items():\n",
    "    if len(i) != len(j[1][-1]):\n",
    "        count +=1 \n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2423e75a-bf43-46fd-b32c-2d0084162646",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n",
    "top_structures = [train_set[seq][1] for seq in dna_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f745fd09-e181-473b-b036-bbd728f49f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777256\n"
     ]
    }
   ],
   "source": [
    "print(len(dna_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef21692e-1c22-4c59-9658-1ba8341a9fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TATTTATCAGATCAATGGGGTATGAGCACAGTTAGTGGCCCGGCG',\n",
       " 'GAGCACGTCCGGTGTAAGTGTCTTGCCGGCCAGTACCGAACACGT',\n",
       " 'CTCAGAAATACACTCCTGCCGTGCGGATCAGAGGCACCATATATG',\n",
       " 'CGCTAATTCACAGGTCAACGATATTTAATCGTTTGCGCTGCATTT',\n",
       " 'GAGCCTGGGCGAGGGAGTGGCACATGATTTATCGACCTTAAATTC',\n",
       " 'CGATCGGTACAGCATGGTCGGAGGGCAAGGACAAACAAGTTTCGG',\n",
       " 'CGCTTAGGGCAGTTTAATCTCTGTTGTCCTTATATCGACCATACC',\n",
       " 'GCTACGATACACCCGGGACATGCTTAGATGTCCTATGTGCAACTT',\n",
       " 'TTATTATCCGGTGGGAGTTTATATCTCACTTAATGAGGGGCTCTC',\n",
       " 'TAAGATGCGTGAACAAGAGGGGAATTGGAGCGAAACGGAGCGCTA',\n",
       " 'TGTCCGTAATTCCGCTCCTCTACCTCCCGCCAGGACATACCGAAC',\n",
       " 'CTTTTGAGGGCCAGATGAAGACTCGAGTCCACGCATGTTGGGCCC',\n",
       " 'TGGAGCACGGTTTCTATAGGTTTGAGTCATTCTGCCTTTCAACCG',\n",
       " 'TTGTTATAACTGAAGTATCGTGCCATGTAAACACGCATTTCGGTA',\n",
       " 'TACACCCAAAGCCGCTAATGGATGCAGCTCGCATTGCCTGTCCGA',\n",
       " 'ATTAGGGGCAAGACTAACTGCGGGAGTTAGGGTGAGATCGCGAAA',\n",
       " 'AGGGGCGAATCGATTGGGTTGGGAATTTGTTTCGCGCCAGAGAAC',\n",
       " 'ATTGAACTTTTGTACGCGAATTATCAATGACGGTGGCAGATTTTT',\n",
       " 'CAAATTGGTGTTCCGCGTCAGTGACACGGCCTAATTGTTCAACCC',\n",
       " 'TAGTGCGAGGGTCCACAAAGTCTTACTGTCGTACTGTCCTAGTGG',\n",
       " 'AGTCGCCGCGAATTTAACGTTACCGCGCAGTCGCCAATTAGTAGA',\n",
       " 'CAAAATAACCAGGCCTCACGCTCAATGGGGGCCGCAGAGTGGGCC',\n",
       " 'TTACGACCCAAACCTAACCTGGCGCGGTTGCACCTTAGTGGAAGG',\n",
       " 'TTACAAAATTTACGCGCTGTTGCTTATGGATCGGATTCTGTGAGC',\n",
       " 'TTATAGTTTTGCTGACAGCGGACTGATATCAATACGAATGGTATT',\n",
       " 'AGCTAATACAAATGCGTCCTAATATTCGATTGATGGAAGGTTACC',\n",
       " 'ACCAGCCGCGCGGATCAGGGAACGCACTGTACCATGGGAAACTCT',\n",
       " 'TCTAACGACGAAAGAACCAACTCGTCTACCTCCGTTTATCCGGTG',\n",
       " 'GTAGTCACCACTAACTCTGAGAGGCAGCGTGCGTATGATGTCCGC',\n",
       " 'TGGTAGGGAGGTCCCGACGTTGCGTTTTACCAGGCGTCGGCGCTA']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_sequences[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c93c17-7328-4b0f-909a-8eed3ffee0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.(((.....))).....((((.....(((.....)))))))....',\n",
       "  '...............((((.(...............).))))...',\n",
       "  '.(((.(.....).)))..........(((.....)))........',\n",
       "  '.(((.........)))..........(((.....)))........',\n",
       "  '.......((......)).........(((.....)))........',\n",
       "  '...........(((........))).(((.....)))........',\n",
       "  '......(((.(((.....))).))).(((.....)))........',\n",
       "  '.................((((.....(((.....)))))))....'],\n",
       " ['........(((((...........))))).....((.......))',\n",
       "  '...(((.....)))...((((.(...(((......))))))))..',\n",
       "  '......(.(((((...........))))))..((.....))....',\n",
       "  '...(((.....)))...((.....))(((......))).......',\n",
       "  '....((..(((((...........)))))...))..((....)).',\n",
       "  '.(((((...........))).))...(((......))).......',\n",
       "  '....((((.((((.....................))))...))))',\n",
       "  '....(((((((((...........)))))............))))',\n",
       "  '...(((.....)))..........(.(((......)))..)....',\n",
       "  '........(((((...........))))).......((....)).',\n",
       "  '...(((.....)))...((((.....(((......))).))))..',\n",
       "  '...(((...........)))......(((......))).......',\n",
       "  '........(((((...........)))))...((.....))....',\n",
       "  '...(((.....))).(((...)))..(((......))).......',\n",
       "  '...(((.....)))............(((......))).......'],\n",
       " ['...((.......))...(((.((.....))..)))..........',\n",
       "  '..........((....))..((((.........))))........',\n",
       "  '.................(((.((.....))..)))..((....))',\n",
       "  '.................(((.((.....))..)))..........',\n",
       "  '..(((..........)))..((((.........))))........'],\n",
       " ['....(((.((...((.((((((.....)))))).))..)).))).',\n",
       "  '(((.(............(((((.....)))))).)))........',\n",
       "  '........((......((((((.....))))))))..........',\n",
       "  '......(.....)...((((((.....)))))).((...))....',\n",
       "  '.((..........)).((((((.....)))))).((...))....',\n",
       "  '.((.............((((((.....))))))......))....',\n",
       "  '........(...)...((((((.....)))))).((...))....',\n",
       "  '..........((....((((((.....))))))))..........',\n",
       "  '....(((...(((...((((((.....))))))....))).))).',\n",
       "  '..((.......))...((((((.....)))))).((...))....',\n",
       "  '..........(((((.((((((.....)))))).)).))).....',\n",
       "  '..........(((..(((((((.....)))).)))..))).....',\n",
       "  '..........(((...((((((.....))))))....))).....',\n",
       "  '................((((((.....)))))).((...))....'],\n",
       " ['...(((.....)))....((...............))........',\n",
       "  '......(.((.........)).)...(((((.......)))))..',\n",
       "  '..((....))........(...)...(((((.......)))))..',\n",
       "  '......((.(((.(...............).))).))........',\n",
       "  '..(((.............)))....((....))............',\n",
       "  '......((.(((..(.(((...)))..)...))).))........',\n",
       "  '...(((.....)))....(...)...(((((.......)))))..',\n",
       "  '......((.(((.....((...)).......))).))........',\n",
       "  '..(((.............))).....(((((.......)))))..',\n",
       "  '......((.(((...................))).))........'],\n",
       " ['..............((.((...)).))...((......)).....',\n",
       "  '....((...((...))..))............(((....)))...',\n",
       "  '......(.....)...(((..........))).............',\n",
       "  '.........((...))(((..........))).............',\n",
       "  '...........((...........))......(((....)))...',\n",
       "  '(((((..........)))))............(((....)))...',\n",
       "  '................(((..........))).............',\n",
       "  '..............((.((...)).)).....(((....)))...'],\n",
       " ['.((.....))............((((.........))))......',\n",
       "  '.....((((((.............))))))...((.....))...',\n",
       "  '.........(((........)))..(((........)))......',\n",
       "  '.((.....))...............(((........)))......',\n",
       "  '.....((((((.............))))))...............'],\n",
       " ['.......((((...(((((((......))))))).))))......',\n",
       "  '((..((.......))((((((......)))))).....)).....',\n",
       "  '...(...).(((..(((((((......)))))))..)))......',\n",
       "  '....((.......))((((((......))))))...((...))..',\n",
       "  '...............((((((......))))))...((...))..',\n",
       "  '.........(((..(((((((......)))))))..)))......'],\n",
       " ['......(((....)))........((((.....)))).(.....)',\n",
       "  '..........((((((.......)))))).....(((.....)))',\n",
       "  '......(((....)))........((((.....))))........'],\n",
       " ['...........((...........))..((((........)))).',\n",
       "  '.....((......)).............((((........)))).',\n",
       "  '.............(((........))).((((........)))).']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_structures[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e9ad8-ec71-4953-a369-33e195ae0407",
   "metadata": {},
   "source": [
    "# Some Parameters Changed and Only Sequences 40-50 bp long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ca561a-af4b-464a-83fa-78fcfd8b3516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Number of sequences in dna_sequences:  777256\n",
      "Sample weights stats:\n",
      "Min: 0.1343396008014679, Max: 0.3759748339653015, Mean: 0.22687213122844696\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 45 - 3 + 1  # Adjusted for k=3\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "num_shared_transformer_blocks = 12\n",
    "num_task_transformer_blocks = 6\n",
    "dropout_rate = 0.2\n",
    "kmer_size = 3  # Set the k-mer size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Encoding functions\n",
    "def generate_kmers(sequence, k):\n",
    "    \"\"\"Generate k-mers from a DNA sequence.\"\"\"\n",
    "    return [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "\n",
    "def encode_kmers(kmers, k):\n",
    "    \"\"\"Encode k-mers using a simple integer mapping.\"\"\"\n",
    "    bases = ['A', 'T', 'C', 'G']\n",
    "    kmer_mapping = {\"\".join(kmer): idx for idx, kmer in enumerate(itertools.product(bases, repeat=k))}\n",
    "    return [kmer_mapping[kmer] for kmer in kmers]\n",
    "\n",
    "def encode_structure(structure):\n",
    "    \"\"\"Encode dot-bracket notation.\"\"\"\n",
    "    structure_mapping = {'.': 0, '(': 1, ')': 2}\n",
    "    return [structure_mapping[char] for char in structure]\n",
    "\n",
    "# Prepare DNA sequences and structures\n",
    "dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n",
    "print(\"Number of sequences in dna_sequences: \", len(dna_sequences))\n",
    "top_structures = [train_set[seq][1] for seq in dna_sequences]\n",
    "\n",
    "# Encode DNA sequences with k-mers\n",
    "encoded_sequences = []\n",
    "for seq in dna_sequences:\n",
    "    kmers = generate_kmers(seq, kmer_size)\n",
    "    encoded_kmers = encode_kmers(kmers, kmer_size)\n",
    "    encoded_sequences.append(encoded_kmers)\n",
    "\n",
    "# Ensure all sequences have consistent length\n",
    "assert all(len(seq) == sequence_length for seq in encoded_sequences), \"Inconsistent k-mer sequence lengths.\"\n",
    "\n",
    "# Encode structures\n",
    "encoded_structures = []\n",
    "for structs in top_structures:\n",
    "    structure = structs[-1]\n",
    "    encoded = encode_structure(structure)\n",
    "    if len(encoded) != 45:  # Ensure structure length matches the original sequence length\n",
    "        raise ValueError(f\"Structure length {len(encoded)} does not match original sequence length (45).\")\n",
    "    encoded_structures.append(encoded)\n",
    "\n",
    "\n",
    "# Convert to tensors and split into training and validation sets\n",
    "X = torch.tensor(encoded_sequences, dtype=torch.long)\n",
    "y_struct = torch.tensor(encoded_structures, dtype=torch.long)\n",
    "\n",
    "X_train, X_val, y_struct_train, y_struct_val = train_test_split(X, y_struct, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "# Calculate class counts based on encoded structures\n",
    "class_counts = torch.tensor(\n",
    "    [sum(struct.count(char) for struct in [\"\".join(top_struct) for top_struct in top_structures]) for char in \".()\"], \n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Ensure no division by zero\n",
    "total_count = class_counts.sum()\n",
    "if total_count == 0 or any(class_counts == 0):\n",
    "    raise ValueError(\"Class counts are invalid, resulting in division by zero.\")\n",
    "\n",
    "# Compute class weights (Inverse frequency weighting)\n",
    "class_weights = total_count / (class_counts + 1e-5)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.clamp(class_weights, min=0)  # Ensure non-negative weights\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Create weighted sampler for the training set\n",
    "sample_weights = []\n",
    "for y in y_struct_train:\n",
    "    valid_indices = y  # Here we are using y directly as it represents the class labels for each base\n",
    "    weight = [class_weights[class_idx].item() for class_idx in valid_indices]\n",
    "    sample_weights.append(sum(weight) / len(weight))  # Average weight for the sequence\n",
    "\n",
    "# Convert to tensor and validate\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "sample_weights = torch.nan_to_num(sample_weights, nan=1.0, posinf=1.0, neginf=1.0)  # Replace NaN/infs with default value\n",
    "sample_weights = torch.clamp(sample_weights, min=0)  # Ensure weights are non-negative\"\"\"\n",
    "\n",
    "# Load precomputed weights\n",
    "class_weights = torch.load(\"class_weights_only45s.pt\").to(device)\n",
    "sample_weights = torch.load(\"sample_weights_only45s.pt\").to(device)\n",
    "\n",
    "# Debugging: Print sample weights stats\n",
    "print(\"Sample weights stats:\")\n",
    "print(f\"Min: {sample_weights.min()}, Max: {sample_weights.max()}, Mean: {sample_weights.mean()}\")\n",
    "assert torch.all(sample_weights >= 0), \"Sample weights contain negative values!\"\n",
    "assert not torch.any(torch.isnan(sample_weights)), \"Sample weights contain NaN values!\"\n",
    "\n",
    "# Create sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_struct_train)\n",
    "val_dataset = TensorDataset(X_val, y_struct_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f57ca6-0ce2-40d4-80ed-04fb55759afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn.utils as nn_utils\n",
    "\n",
    "class TransformerEncoderBlockWithPairingAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.2, sequence_length=80):\n",
    "        super(TransformerEncoderBlockWithPairingAttention, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.pairing_bias = nn.Parameter(torch.randn(sequence_length, sequence_length))\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        q, k, v = x, x, x\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (q.size(-1) ** 0.5)\n",
    "        seq_len = q.size(1)\n",
    "        pairing_bias_resized = self.pairing_bias[:seq_len, :seq_len]\n",
    "        pairing_bias_resized = pairing_bias_resized.unsqueeze(0).expand(x.size(0), -1, -1).to(x.device)\n",
    "        attn_scores = attn_scores + pairing_bias_resized\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        paired_attn_output = torch.matmul(attn_weights, v)\n",
    "        x = x + self.dropout1(attn_output + paired_attn_output)\n",
    "        x = self.layernorm1(x)\n",
    "        x = x + self.dropout2(self.ffn(x))\n",
    "        x = self.layernorm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StructurePredictor(nn.Module):\n",
    "    def __init__(self, input_length, output_length, embedding_dim, num_heads, ff_dim, num_shared_blocks, num_task_blocks, vocab_size):\n",
    "        super(StructurePredictor, self).__init__()\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # Embedding and positional encoding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_encoding = self.create_sinusoidal_positional_encoding(input_length, embedding_dim)\n",
    "\n",
    "        # Shared Transformer blocks\n",
    "        self.shared_transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=input_length)\n",
    "            for _ in range(num_shared_blocks)\n",
    "        ])\n",
    "\n",
    "        # Task-specific Transformer blocks\n",
    "        self.task_transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=output_length)\n",
    "            for _ in range(num_task_blocks)\n",
    "        ])\n",
    "\n",
    "        # Linear layer to match output length\n",
    "        self.length_adapter = nn.Linear(input_length, output_length)\n",
    "\n",
    "        # Structure prediction head\n",
    "        self.structure_head = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, 3)  # Output for structure prediction: '.', '(', ')'\n",
    "        )\n",
    "\n",
    "    def create_sinusoidal_positional_encoding(self, seq_len, d_model):\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pos_enc = torch.zeros(seq_len, d_model)\n",
    "        pos_enc[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pos_enc[:, 1::2] = torch.cos(pos * div_term)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device  # Get the device of the input tensor\n",
    "\n",
    "        # Add positional encoding\n",
    "        positional_encoding = self.positional_encoding[:self.input_length, :].to(device)\n",
    "        x = self.embedding(x) + positional_encoding\n",
    "        x = x.permute(1, 0, 2)  # Permute for transformer compatibility\n",
    "\n",
    "        # Shared Transformer blocks\n",
    "        for block in self.shared_transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2)  # Permute back to original shape\n",
    "\n",
    "        # Adjust sequence length\n",
    "        x = self.length_adapter(x.permute(0, 2, 1)).permute(0, 2, 1)  # Convert (batch_size, input_length, dim) to (batch_size, output_length, dim)\n",
    "\n",
    "        # Task-specific Transformer blocks\n",
    "        x = x.permute(1, 0, 2)  # Permute for transformer compatibility\n",
    "        for block in self.task_transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = x.permute(1, 0, 2)  # Permute back to original shape\n",
    "\n",
    "        # Predict structure\n",
    "        output = self.structure_head(x)  # Shape: (batch_size, output_length, 3)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RewardedThermodynamicallyBalancedCategoricalCrossEntropy(nn.Module):\n",
    "    def __init__(self, weights, pairing_penalty=0.2, thermo_penalty=0.3, specificity_reward=0.05):\n",
    "        super(RewardedThermodynamicallyBalancedCategoricalCrossEntropy, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.pairing_penalty = pairing_penalty\n",
    "        self.thermo_penalty = thermo_penalty\n",
    "        self.specificity_reward = specificity_reward\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        if y_pred.size(-1) != 3:\n",
    "            raise ValueError(\"y_pred must have a final dimension of 3 classes.\")\n",
    "        if y_true.dim() != 2 or y_pred.dim() != 3:\n",
    "            raise ValueError(\"y_true and y_pred must have shapes (batch_size, sequence_length) and (batch_size, sequence_length, 3), respectively.\")\n",
    "\n",
    "        # Weighted categorical cross-entropy\n",
    "        y_true_one_hot = F.one_hot(y_true, num_classes=3).float()\n",
    "        log_probs = F.log_softmax(y_pred, dim=-1)\n",
    "        loss = -torch.sum(self.weights * y_true_one_hot * log_probs, dim=-1).mean()\n",
    "\n",
    "        # Pairing imbalance penalty\n",
    "        pred_labels = torch.argmax(y_pred, dim=-1)\n",
    "        open_count = (pred_labels == 1).sum()\n",
    "        close_count = (pred_labels == 2).sum()\n",
    "        imbalance_penalty = self.pairing_penalty * torch.abs(open_count - close_count).float()\n",
    "\n",
    "        # Thermodynamic penalty for mismatches\n",
    "        mismatch_penalty = torch.sum((pred_labels == 1) & (y_true == 2)) * self.thermo_penalty\n",
    "\n",
    "        # Specificity reward for correct pair predictions\n",
    "        correct_pairings = ((pred_labels == y_true) & ((y_true == 1) | (y_true == 2))).sum()\n",
    "        specificity_reward = self.specificity_reward * correct_pairings.float()\n",
    "\n",
    "        return loss + imbalance_penalty + mismatch_penalty - specificity_reward\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "input_length = 43  # Input sequence length\n",
    "output_length = 45  # Output structure length\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "num_shared_blocks = 12\n",
    "num_task_blocks = 6\n",
    "vocab_size = 4 ** kmer_size  # For A, T, C, G k-mers\n",
    "\n",
    "# Instantiate model\n",
    "model = StructurePredictor(\n",
    "    input_length=input_length,\n",
    "    output_length=output_length,\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_shared_blocks=num_shared_blocks,\n",
    "    num_task_blocks=num_task_blocks,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "loss_fn_struct = RewardedThermodynamicallyBalancedCategoricalCrossEntropy(\n",
    "    weights=class_weights\n",
    ")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n",
    "\n",
    "# Training loop with early stopping and metrics\n",
    "best_val_loss = float('inf')\n",
    "patience = 100\n",
    "patience_counter = 0\n",
    "\n",
    "def calculate_class_metrics(y_true, y_pred, num_classes=3):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1-score for each class.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        tp = ((y_pred == class_idx) & (y_true == class_idx)).sum().item()\n",
    "        fp = ((y_pred == class_idx) & (y_true != class_idx)).sum().item()\n",
    "        fn = ((y_pred != class_idx) & (y_true == class_idx)).sum().item()\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "        metrics[class_idx] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "    return metrics\n",
    "\n",
    "def print_validation_metrics(val_metrics, printer=True):\n",
    "    \"\"\"\n",
    "    Print validation metrics and compute the average F1-score.\n",
    "    \"\"\"\n",
    "    total_f1 = 0\n",
    "    num_classes = len(val_metrics)\n",
    "    \n",
    "    # Print metrics for each class\n",
    "    for cls, metrics in val_metrics.items():\n",
    "        if printer:\n",
    "            print(f\"Class {cls} - Precision: {metrics['precision']:.4f}, \"\n",
    "                  f\"Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1']:.4f}\")\n",
    "        total_f1 += metrics['f1']\n",
    "    \n",
    "    # Calculate the average F1 score\n",
    "    avg_f1 = total_f1 / num_classes if num_classes > 0 else 0.0\n",
    "    \n",
    "    return avg_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2cad421-5c8e-4439-b0c1-a8ac50b5800c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Save sample weights\\ntorch.save(sample_weights, \"sample_weights_evenevenmoredata.pt\")\\n\\n# Load sample weights\\ntorch.save(class_weights, \"class_weights_evenevenmoredata.pt\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Save sample weights\n",
    "torch.save(sample_weights, \"sample_weights_evenevenmoredata.pt\")\n",
    "\n",
    "# Load sample weights\n",
    "torch.save(class_weights, \"class_weights_evenevenmoredata.pt\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1c9865-6de3-4c08-be14-0b42aa449558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\\nmodel_path = \"12-2_integerenc.pth\"\\nmodel.load_state_dict(torch.load(model_path, map_location=device))'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this cell if the gradients explode!\n",
    "\"\"\"\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n",
    "model_path = \"12-2_integerenc.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb2ca60-346a-4489-92cf-57934063aa03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 15.6124\n",
      "Learning Rate: 8.131564889193507e-06\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0004\n",
      "shared_transformer_blocks: 0.0018\n",
      "task_transformer_blocks: 0.0039\n",
      "length_adapter: 0.0430\n",
      "structure_head: 0.0234\n",
      "Class 0 - Precision: 0.8775, Recall: 0.0879, F1-Score: 0.1597\n",
      "Class 1 - Precision: 0.2465, Recall: 0.7111, F1-Score: 0.3661\n",
      "Class 2 - Precision: 0.2508, Recall: 0.6801, F1-Score: 0.3665\n",
      "Validation Loss: 13.9558, Accuracy: 0.3008, F1: 0.2974\n",
      "Best model saved with validation loss: 13.9558\n",
      "\n",
      "\n",
      "Epoch 2, Training Loss: 12.5033\n",
      "Learning Rate: 8.52589894593923e-06\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0002\n",
      "shared_transformer_blocks: 0.0007\n",
      "task_transformer_blocks: 0.0026\n",
      "length_adapter: 0.0347\n",
      "structure_head: 0.0225\n",
      "Class 0 - Precision: 0.8708, Recall: 0.0975, F1-Score: 0.1754\n",
      "Class 1 - Precision: 0.2472, Recall: 0.7058, F1-Score: 0.3661\n",
      "Class 2 - Precision: 0.2513, Recall: 0.6768, F1-Score: 0.3665\n",
      "Validation Loss: 13.1237, Accuracy: 0.3001, F1: 0.3027\n",
      "Best model saved with validation loss: 13.1237\n",
      "\n",
      "\n",
      "Epoch 3, Training Loss: 12.7512\n",
      "Learning Rate: 9.181921326143828e-06\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0006\n",
      "shared_transformer_blocks: 0.0010\n",
      "task_transformer_blocks: 0.0025\n",
      "length_adapter: 0.0425\n",
      "structure_head: 0.0223\n",
      "Class 0 - Precision: 0.8802, Recall: 0.1334, F1-Score: 0.2318\n",
      "Class 1 - Precision: 0.2558, Recall: 0.6719, F1-Score: 0.3706\n",
      "Class 2 - Precision: 0.2520, Recall: 0.6965, F1-Score: 0.3701\n",
      "Validation Loss: 12.2241, Accuracy: 0.3121, F1: 0.3242\n",
      "Best model saved with validation loss: 12.2241\n",
      "\n",
      "\n",
      "Epoch 4, Training Loss: 14.1210\n",
      "Learning Rate: 1.009783391497899e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0017\n",
      "shared_transformer_blocks: 0.0022\n",
      "task_transformer_blocks: 0.0032\n",
      "length_adapter: 0.0500\n",
      "structure_head: 0.0226\n",
      "Class 0 - Precision: 0.8942, Recall: 0.1644, F1-Score: 0.2778\n",
      "Class 1 - Precision: 0.2558, Recall: 0.7117, F1-Score: 0.3763\n",
      "Class 2 - Precision: 0.2643, Recall: 0.6551, F1-Score: 0.3767\n",
      "Validation Loss: 23.1759, Accuracy: 0.3354, F1: 0.3436\n",
      "\n",
      "\n",
      "Epoch 5, Training Loss: 17.2375\n",
      "Learning Rate: 1.1271126255397556e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0033\n",
      "shared_transformer_blocks: 0.0047\n",
      "task_transformer_blocks: 0.0049\n",
      "length_adapter: 0.0517\n",
      "structure_head: 0.0239\n",
      "Class 0 - Precision: 0.8763, Recall: 0.2373, F1-Score: 0.3734\n",
      "Class 1 - Precision: 0.2773, Recall: 0.7095, F1-Score: 0.3987\n",
      "Class 2 - Precision: 0.2836, Recall: 0.6679, F1-Score: 0.3981\n",
      "Validation Loss: 20.5489, Accuracy: 0.3931, F1: 0.3901\n",
      "\n",
      "\n",
      "Epoch 6, Training Loss: 6.3735\n",
      "Learning Rate: 1.2698582429133791e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0050\n",
      "shared_transformer_blocks: 0.0077\n",
      "task_transformer_blocks: 0.0072\n",
      "length_adapter: 0.0521\n",
      "structure_head: 0.0256\n",
      "Class 0 - Precision: 0.8548, Recall: 0.3097, F1-Score: 0.4547\n",
      "Class 1 - Precision: 0.3139, Recall: 0.6870, F1-Score: 0.4309\n",
      "Class 2 - Precision: 0.3040, Recall: 0.7173, F1-Score: 0.4270\n",
      "Validation Loss: 9.9648, Accuracy: 0.4519, F1: 0.4375\n",
      "Best model saved with validation loss: 9.9648\n",
      "\n",
      "\n",
      "Epoch 7, Training Loss: -2.5144\n",
      "Learning Rate: 1.4376289871326675e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0064\n",
      "shared_transformer_blocks: 0.0104\n",
      "task_transformer_blocks: 0.0092\n",
      "length_adapter: 0.0529\n",
      "structure_head: 0.0267\n",
      "Class 0 - Precision: 0.8544, Recall: 0.3996, F1-Score: 0.5445\n",
      "Class 1 - Precision: 0.3581, Recall: 0.7129, F1-Score: 0.4767\n",
      "Class 2 - Precision: 0.3435, Recall: 0.7338, F1-Score: 0.4680\n",
      "Validation Loss: 0.6711, Accuracy: 0.5155, F1: 0.4964\n",
      "Best model saved with validation loss: 0.6711\n",
      "\n",
      "\n",
      "Epoch 8, Training Loss: -6.7404\n",
      "Learning Rate: 1.6299650094606864e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0070\n",
      "shared_transformer_blocks: 0.0113\n",
      "task_transformer_blocks: 0.0100\n",
      "length_adapter: 0.0508\n",
      "structure_head: 0.0268\n",
      "Class 0 - Precision: 0.8684, Recall: 0.4882, F1-Score: 0.6251\n",
      "Class 1 - Precision: 0.4007, Recall: 0.7367, F1-Score: 0.5191\n",
      "Class 2 - Precision: 0.3942, Recall: 0.7533, F1-Score: 0.5175\n",
      "Validation Loss: -4.2058, Accuracy: 0.5807, F1: 0.5539\n",
      "Best model saved with validation loss: -4.2058\n",
      "\n",
      "\n",
      "Epoch 9, Training Loss: -8.6362\n",
      "Learning Rate: 1.8463391293252333e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0073\n",
      "shared_transformer_blocks: 0.0116\n",
      "task_transformer_blocks: 0.0100\n",
      "length_adapter: 0.0465\n",
      "structure_head: 0.0264\n",
      "Class 0 - Precision: 0.8931, Recall: 0.5305, F1-Score: 0.6656\n",
      "Class 1 - Precision: 0.4369, Recall: 0.7740, F1-Score: 0.5586\n",
      "Class 2 - Precision: 0.4279, Recall: 0.7920, F1-Score: 0.5556\n",
      "Validation Loss: -7.1278, Accuracy: 0.6216, F1: 0.5933\n",
      "Best model saved with validation loss: -7.1278\n",
      "\n",
      "\n",
      "Epoch 10, Training Loss: -9.7932\n",
      "Learning Rate: 2.0861582792866323e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0075\n",
      "shared_transformer_blocks: 0.0119\n",
      "task_transformer_blocks: 0.0096\n",
      "length_adapter: 0.0415\n",
      "structure_head: 0.0262\n",
      "Class 0 - Precision: 0.8864, Recall: 0.6127, F1-Score: 0.7246\n",
      "Class 1 - Precision: 0.4760, Recall: 0.7530, F1-Score: 0.5833\n",
      "Class 2 - Precision: 0.4665, Recall: 0.7707, F1-Score: 0.5812\n",
      "Validation Loss: -8.2825, Accuracy: 0.6526, F1: 0.6297\n",
      "Best model saved with validation loss: -8.2825\n",
      "\n",
      "\n",
      "Epoch 11, Training Loss: -10.5433\n",
      "Learning Rate: 2.348765130597157e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0076\n",
      "shared_transformer_blocks: 0.0121\n",
      "task_transformer_blocks: 0.0091\n",
      "length_adapter: 0.0368\n",
      "structure_head: 0.0256\n",
      "Class 0 - Precision: 0.9019, Recall: 0.6224, F1-Score: 0.7365\n",
      "Class 1 - Precision: 0.4967, Recall: 0.7833, F1-Score: 0.6079\n",
      "Class 2 - Precision: 0.4807, Recall: 0.7985, F1-Score: 0.6001\n",
      "Validation Loss: -9.2713, Accuracy: 0.6709, F1: 0.6482\n",
      "Best model saved with validation loss: -9.2713\n",
      "\n",
      "\n",
      "Epoch 12, Training Loss: -11.2170\n",
      "Learning Rate: 2.63343989489651e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0078\n",
      "shared_transformer_blocks: 0.0124\n",
      "task_transformer_blocks: 0.0086\n",
      "length_adapter: 0.0330\n",
      "structure_head: 0.0252\n",
      "Class 0 - Precision: 0.9058, Recall: 0.6432, F1-Score: 0.7523\n",
      "Class 1 - Precision: 0.5089, Recall: 0.7933, F1-Score: 0.6200\n",
      "Class 2 - Precision: 0.5013, Recall: 0.8018, F1-Score: 0.6169\n",
      "Validation Loss: -10.6216, Accuracy: 0.6867, F1: 0.6631\n",
      "Best model saved with validation loss: -10.6216\n",
      "\n",
      "\n",
      "Epoch 13, Training Loss: -11.7874\n",
      "Learning Rate: 2.939402297105084e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0080\n",
      "shared_transformer_blocks: 0.0126\n",
      "task_transformer_blocks: 0.0081\n",
      "length_adapter: 0.0303\n",
      "structure_head: 0.0246\n",
      "Class 0 - Precision: 0.9092, Recall: 0.6709, F1-Score: 0.7721\n",
      "Class 1 - Precision: 0.5332, Recall: 0.7930, F1-Score: 0.6377\n",
      "Class 2 - Precision: 0.5182, Recall: 0.8084, F1-Score: 0.6315\n",
      "Validation Loss: -10.5712, Accuracy: 0.7003, F1: 0.6804\n",
      "\n",
      "\n",
      "Epoch 14, Training Loss: -12.2799\n",
      "Learning Rate: 3.265813714107378e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0082\n",
      "shared_transformer_blocks: 0.0128\n",
      "task_transformer_blocks: 0.0076\n",
      "length_adapter: 0.0281\n",
      "structure_head: 0.0242\n",
      "Class 0 - Precision: 0.9157, Recall: 0.6761, F1-Score: 0.7778\n",
      "Class 1 - Precision: 0.5400, Recall: 0.8095, F1-Score: 0.6478\n",
      "Class 2 - Precision: 0.5282, Recall: 0.8172, F1-Score: 0.6417\n",
      "Validation Loss: -11.6421, Accuracy: 0.7109, F1: 0.6891\n",
      "Best model saved with validation loss: -11.6421\n",
      "\n",
      "\n",
      "Epoch 15, Training Loss: -12.7507\n",
      "Learning Rate: 3.6117794733636166e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0083\n",
      "shared_transformer_blocks: 0.0130\n",
      "task_transformer_blocks: 0.0072\n",
      "length_adapter: 0.0264\n",
      "structure_head: 0.0237\n",
      "Class 0 - Precision: 0.9147, Recall: 0.7119, F1-Score: 0.8006\n",
      "Class 1 - Precision: 0.5579, Recall: 0.8078, F1-Score: 0.6600\n",
      "Class 2 - Precision: 0.5624, Recall: 0.8089, F1-Score: 0.6635\n",
      "Validation Loss: -12.5763, Accuracy: 0.7228, F1: 0.7081\n",
      "Best model saved with validation loss: -12.5763\n",
      "\n",
      "\n",
      "Epoch 16, Training Loss: -13.1081\n",
      "Learning Rate: 3.976351305149184e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0086\n",
      "shared_transformer_blocks: 0.0132\n",
      "task_transformer_blocks: 0.0069\n",
      "length_adapter: 0.0250\n",
      "structure_head: 0.0232\n",
      "Class 0 - Precision: 0.9190, Recall: 0.7086, F1-Score: 0.8002\n",
      "Class 1 - Precision: 0.5629, Recall: 0.8151, F1-Score: 0.6659\n",
      "Class 2 - Precision: 0.5585, Recall: 0.8191, F1-Score: 0.6641\n",
      "Validation Loss: -12.6972, Accuracy: 0.7299, F1: 0.7101\n",
      "Best model saved with validation loss: -12.6972\n",
      "\n",
      "\n",
      "Epoch 17, Training Loss: -13.4829\n",
      "Learning Rate: 4.358529941700506e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0087\n",
      "shared_transformer_blocks: 0.0133\n",
      "task_transformer_blocks: 0.0066\n",
      "length_adapter: 0.0238\n",
      "structure_head: 0.0227\n",
      "Class 0 - Precision: 0.9197, Recall: 0.7322, F1-Score: 0.8153\n",
      "Class 1 - Precision: 0.5871, Recall: 0.8132, F1-Score: 0.6819\n",
      "Class 2 - Precision: 0.5754, Recall: 0.8225, F1-Score: 0.6771\n",
      "Validation Loss: -12.6992, Accuracy: 0.7395, F1: 0.7248\n",
      "Best model saved with validation loss: -12.6992\n",
      "\n",
      "\n",
      "Epoch 18, Training Loss: -13.7633\n",
      "Learning Rate: 4.757267856143199e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0089\n",
      "shared_transformer_blocks: 0.0134\n",
      "task_transformer_blocks: 0.0063\n",
      "length_adapter: 0.0228\n",
      "structure_head: 0.0222\n",
      "Class 0 - Precision: 0.9263, Recall: 0.7192, F1-Score: 0.8097\n",
      "Class 1 - Precision: 0.5782, Recall: 0.8297, F1-Score: 0.6815\n",
      "Class 2 - Precision: 0.5718, Recall: 0.8340, F1-Score: 0.6784\n",
      "Validation Loss: -13.4945, Accuracy: 0.7446, F1: 0.7232\n",
      "Best model saved with validation loss: -13.4945\n",
      "\n",
      "\n",
      "Epoch 19, Training Loss: -14.0668\n",
      "Learning Rate: 5.171472133695375e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0090\n",
      "shared_transformer_blocks: 0.0136\n",
      "task_transformer_blocks: 0.0060\n",
      "length_adapter: 0.0220\n",
      "structure_head: 0.0217\n",
      "Class 0 - Precision: 0.9265, Recall: 0.7440, F1-Score: 0.8253\n",
      "Class 1 - Precision: 0.5989, Recall: 0.8295, F1-Score: 0.6956\n",
      "Class 2 - Precision: 0.5938, Recall: 0.8325, F1-Score: 0.6932\n",
      "Validation Loss: -13.8498, Accuracy: 0.7531, F1: 0.7380\n",
      "Best model saved with validation loss: -13.8498\n",
      "\n",
      "\n",
      "Epoch 20, Training Loss: -14.3523\n",
      "Learning Rate: 5.6000074672762066e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0092\n",
      "shared_transformer_blocks: 0.0137\n",
      "task_transformer_blocks: 0.0058\n",
      "length_adapter: 0.0213\n",
      "structure_head: 0.0212\n",
      "Class 0 - Precision: 0.9293, Recall: 0.7380, F1-Score: 0.8227\n",
      "Class 1 - Precision: 0.5969, Recall: 0.8311, F1-Score: 0.6948\n",
      "Class 2 - Precision: 0.5870, Recall: 0.8396, F1-Score: 0.6910\n",
      "Validation Loss: -13.9572, Accuracy: 0.7578, F1: 0.7361\n",
      "Best model saved with validation loss: -13.9572\n",
      "\n",
      "\n",
      "Epoch 21, Training Loss: -14.5767\n",
      "Learning Rate: 6.0416992693090665e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0093\n",
      "shared_transformer_blocks: 0.0138\n",
      "task_transformer_blocks: 0.0056\n",
      "length_adapter: 0.0207\n",
      "structure_head: 0.0206\n",
      "Class 0 - Precision: 0.9342, Recall: 0.7428, F1-Score: 0.8276\n",
      "Class 1 - Precision: 0.6037, Recall: 0.8421, F1-Score: 0.7033\n",
      "Class 2 - Precision: 0.5971, Recall: 0.8502, F1-Score: 0.7015\n",
      "Validation Loss: -14.3264, Accuracy: 0.7633, F1: 0.7441\n",
      "Best model saved with validation loss: -14.3264\n",
      "\n",
      "\n",
      "Epoch 22, Training Loss: -14.8645\n",
      "Learning Rate: 6.495336891189954e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0095\n",
      "shared_transformer_blocks: 0.0139\n",
      "task_transformer_blocks: 0.0055\n",
      "length_adapter: 0.0203\n",
      "structure_head: 0.0200\n",
      "Class 0 - Precision: 0.9279, Recall: 0.7798, F1-Score: 0.8474\n",
      "Class 1 - Precision: 0.6299, Recall: 0.8303, F1-Score: 0.7163\n",
      "Class 2 - Precision: 0.6313, Recall: 0.8330, F1-Score: 0.7183\n",
      "Validation Loss: -14.4271, Accuracy: 0.7724, F1: 0.7607\n",
      "Best model saved with validation loss: -14.4271\n",
      "\n",
      "\n",
      "Epoch 23, Training Loss: -15.0835\n",
      "Learning Rate: 6.95967694159685e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0096\n",
      "shared_transformer_blocks: 0.0140\n",
      "task_transformer_blocks: 0.0053\n",
      "length_adapter: 0.0200\n",
      "structure_head: 0.0195\n",
      "Class 0 - Precision: 0.9351, Recall: 0.7612, F1-Score: 0.8392\n",
      "Class 1 - Precision: 0.6189, Recall: 0.8441, F1-Score: 0.7142\n",
      "Class 2 - Precision: 0.6158, Recall: 0.8494, F1-Score: 0.7140\n",
      "Validation Loss: -14.6869, Accuracy: 0.7752, F1: 0.7558\n",
      "Best model saved with validation loss: -14.6869\n",
      "\n",
      "\n",
      "Epoch 24, Training Loss: -15.2824\n",
      "Learning Rate: 7.433446694544762e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0098\n",
      "shared_transformer_blocks: 0.0141\n",
      "task_transformer_blocks: 0.0052\n",
      "length_adapter: 0.0197\n",
      "structure_head: 0.0188\n",
      "Class 0 - Precision: 0.9368, Recall: 0.7703, F1-Score: 0.8454\n",
      "Class 1 - Precision: 0.6291, Recall: 0.8494, F1-Score: 0.7228\n",
      "Class 2 - Precision: 0.6266, Recall: 0.8522, F1-Score: 0.7222\n",
      "Validation Loss: -15.0649, Accuracy: 0.7801, F1: 0.7635\n",
      "Best model saved with validation loss: -15.0649\n",
      "\n",
      "\n",
      "Epoch 25, Training Loss: -15.4719\n",
      "Learning Rate: 7.91534757784515e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0099\n",
      "shared_transformer_blocks: 0.0142\n",
      "task_transformer_blocks: 0.0051\n",
      "length_adapter: 0.0196\n",
      "structure_head: 0.0182\n",
      "Class 0 - Precision: 0.9399, Recall: 0.7565, F1-Score: 0.8383\n",
      "Class 1 - Precision: 0.6157, Recall: 0.8552, F1-Score: 0.7160\n",
      "Class 2 - Precision: 0.6170, Recall: 0.8580, F1-Score: 0.7178\n",
      "Validation Loss: -15.2088, Accuracy: 0.7823, F1: 0.7573\n",
      "Best model saved with validation loss: -15.2088\n",
      "\n",
      "\n",
      "Epoch 26, Training Loss: -15.6714\n",
      "Learning Rate: 8.404058732408145e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0101\n",
      "shared_transformer_blocks: 0.0143\n",
      "task_transformer_blocks: 0.0050\n",
      "length_adapter: 0.0195\n",
      "structure_head: 0.0176\n",
      "Class 0 - Precision: 0.9399, Recall: 0.7761, F1-Score: 0.8502\n",
      "Class 1 - Precision: 0.6384, Recall: 0.8556, F1-Score: 0.7312\n",
      "Class 2 - Precision: 0.6328, Recall: 0.8580, F1-Score: 0.7284\n",
      "Validation Loss: -14.9271, Accuracy: 0.7880, F1: 0.7699\n",
      "\n",
      "\n",
      "Epoch 27, Training Loss: -15.8350\n",
      "Learning Rate: 8.898240632631713e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0102\n",
      "shared_transformer_blocks: 0.0144\n",
      "task_transformer_blocks: 0.0049\n",
      "length_adapter: 0.0194\n",
      "structure_head: 0.0169\n",
      "Class 0 - Precision: 0.9492, Recall: 0.7381, F1-Score: 0.8304\n",
      "Class 1 - Precision: 0.6079, Recall: 0.8762, F1-Score: 0.7178\n",
      "Class 2 - Precision: 0.6044, Recall: 0.8748, F1-Score: 0.7149\n",
      "Validation Loss: -15.2571, Accuracy: 0.7874, F1: 0.7544\n",
      "Best model saved with validation loss: -15.2571\n",
      "\n",
      "\n",
      "Epoch 28, Training Loss: -16.0139\n",
      "Learning Rate: 9.396538757954509e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0103\n",
      "shared_transformer_blocks: 0.0145\n",
      "task_transformer_blocks: 0.0048\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0162\n",
      "Class 0 - Precision: 0.9399, Recall: 0.7864, F1-Score: 0.8563\n",
      "Class 1 - Precision: 0.6443, Recall: 0.8538, F1-Score: 0.7344\n",
      "Class 2 - Precision: 0.6453, Recall: 0.8566, F1-Score: 0.7361\n",
      "Validation Loss: -15.6032, Accuracy: 0.7954, F1: 0.7756\n",
      "Best model saved with validation loss: -15.6032\n",
      "\n",
      "\n",
      "Epoch 29, Training Loss: -16.1887\n",
      "Learning Rate: 9.897587305508968e-05\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0104\n",
      "shared_transformer_blocks: 0.0146\n",
      "task_transformer_blocks: 0.0047\n",
      "length_adapter: 0.0191\n",
      "structure_head: 0.0156\n",
      "Class 0 - Precision: 0.9400, Recall: 0.7974, F1-Score: 0.8629\n",
      "Class 1 - Precision: 0.6559, Recall: 0.8590, F1-Score: 0.7438\n",
      "Class 2 - Precision: 0.6601, Recall: 0.8560, F1-Score: 0.7454\n",
      "Validation Loss: -15.5404, Accuracy: 0.7990, F1: 0.7840\n",
      "\n",
      "\n",
      "Epoch 30, Training Loss: -16.2952\n",
      "Learning Rate: 0.00010400012933698426\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0105\n",
      "shared_transformer_blocks: 0.0146\n",
      "task_transformer_blocks: 0.0047\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0151\n",
      "Class 0 - Precision: 0.9451, Recall: 0.7793, F1-Score: 0.8542\n",
      "Class 1 - Precision: 0.6434, Recall: 0.8644, F1-Score: 0.7377\n",
      "Class 2 - Precision: 0.6412, Recall: 0.8705, F1-Score: 0.7385\n",
      "Validation Loss: -15.9576, Accuracy: 0.7997, F1: 0.7768\n",
      "Best model saved with validation loss: -15.9576\n",
      "\n",
      "\n",
      "Epoch 31, Training Loss: -16.4173\n",
      "Learning Rate: 0.00010902438526437461\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0106\n",
      "shared_transformer_blocks: 0.0147\n",
      "task_transformer_blocks: 0.0046\n",
      "length_adapter: 0.0190\n",
      "structure_head: 0.0146\n",
      "Class 0 - Precision: 0.9442, Recall: 0.7954, F1-Score: 0.8635\n",
      "Class 1 - Precision: 0.6589, Recall: 0.8653, F1-Score: 0.7481\n",
      "Class 2 - Precision: 0.6583, Recall: 0.8665, F1-Score: 0.7482\n",
      "Validation Loss: -16.0115, Accuracy: 0.8044, F1: 0.7866\n",
      "Best model saved with validation loss: -16.0115\n",
      "\n",
      "\n",
      "Epoch 32, Training Loss: -16.5463\n",
      "Learning Rate: 0.00011403486967737796\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0107\n",
      "shared_transformer_blocks: 0.0148\n",
      "task_transformer_blocks: 0.0045\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0141\n",
      "Class 0 - Precision: 0.9458, Recall: 0.7919, F1-Score: 0.8620\n",
      "Class 1 - Precision: 0.6552, Recall: 0.8683, F1-Score: 0.7468\n",
      "Class 2 - Precision: 0.6555, Recall: 0.8687, F1-Score: 0.7472\n",
      "Validation Loss: -16.0134, Accuracy: 0.8064, F1: 0.7853\n",
      "Best model saved with validation loss: -16.0134\n",
      "\n",
      "\n",
      "Epoch 33, Training Loss: -16.6532\n",
      "Learning Rate: 0.00011901784916294019\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0108\n",
      "shared_transformer_blocks: 0.0149\n",
      "task_transformer_blocks: 0.0045\n",
      "length_adapter: 0.0191\n",
      "structure_head: 0.0136\n",
      "Class 0 - Precision: 0.9453, Recall: 0.8003, F1-Score: 0.8668\n",
      "Class 1 - Precision: 0.6665, Recall: 0.8657, F1-Score: 0.7531\n",
      "Class 2 - Precision: 0.6621, Recall: 0.8701, F1-Score: 0.7520\n",
      "Validation Loss: -16.0999, Accuracy: 0.8090, F1: 0.7906\n",
      "Best model saved with validation loss: -16.0999\n",
      "\n",
      "\n",
      "Epoch 34, Training Loss: -16.7026\n",
      "Learning Rate: 0.0001239596656972306\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0108\n",
      "shared_transformer_blocks: 0.0149\n",
      "task_transformer_blocks: 0.0044\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0134\n",
      "Class 0 - Precision: 0.9473, Recall: 0.7972, F1-Score: 0.8658\n",
      "Class 1 - Precision: 0.6610, Recall: 0.8707, F1-Score: 0.7515\n",
      "Class 2 - Precision: 0.6626, Recall: 0.8719, F1-Score: 0.7530\n",
      "Validation Loss: -16.1978, Accuracy: 0.8096, F1: 0.7901\n",
      "Best model saved with validation loss: -16.1978\n",
      "\n",
      "\n",
      "Epoch 35, Training Loss: -16.7980\n",
      "Learning Rate: 0.00012884677408140028\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0109\n",
      "shared_transformer_blocks: 0.0150\n",
      "task_transformer_blocks: 0.0044\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0130\n",
      "Class 0 - Precision: 0.9478, Recall: 0.8025, F1-Score: 0.8691\n",
      "Class 1 - Precision: 0.6711, Recall: 0.8724, F1-Score: 0.7586\n",
      "Class 2 - Precision: 0.6663, Recall: 0.8746, F1-Score: 0.7563\n",
      "Validation Loss: -16.2553, Accuracy: 0.8124, F1: 0.7947\n",
      "Best model saved with validation loss: -16.2553\n",
      "\n",
      "\n",
      "Epoch 36, Training Loss: -16.8624\n",
      "Learning Rate: 0.0001336657790680942\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0110\n",
      "shared_transformer_blocks: 0.0150\n",
      "task_transformer_blocks: 0.0043\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0127\n",
      "Class 0 - Precision: 0.9478, Recall: 0.8012, F1-Score: 0.8684\n",
      "Class 1 - Precision: 0.6675, Recall: 0.8717, F1-Score: 0.7560\n",
      "Class 2 - Precision: 0.6666, Recall: 0.8746, F1-Score: 0.7566\n",
      "Validation Loss: -16.3918, Accuracy: 0.8138, F1: 0.7937\n",
      "Best model saved with validation loss: -16.3918\n",
      "\n",
      "\n",
      "Epoch 37, Training Loss: -16.9812\n",
      "Learning Rate: 0.00013840347207695622\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0110\n",
      "shared_transformer_blocks: 0.0151\n",
      "task_transformer_blocks: 0.0043\n",
      "length_adapter: 0.0192\n",
      "structure_head: 0.0124\n",
      "Class 0 - Precision: 0.9542, Recall: 0.7790, F1-Score: 0.8577\n",
      "Class 1 - Precision: 0.6525, Recall: 0.8846, F1-Score: 0.7510\n",
      "Class 2 - Precision: 0.6445, Recall: 0.8882, F1-Score: 0.7470\n",
      "Validation Loss: -16.4157, Accuracy: 0.8128, F1: 0.7852\n",
      "Best model saved with validation loss: -16.4157\n",
      "\n",
      "\n",
      "Epoch 38, Training Loss: -17.0309\n",
      "Learning Rate: 0.00014304686739849165\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0111\n",
      "shared_transformer_blocks: 0.0152\n",
      "task_transformer_blocks: 0.0042\n",
      "length_adapter: 0.0194\n",
      "structure_head: 0.0121\n",
      "Class 0 - Precision: 0.9464, Recall: 0.8177, F1-Score: 0.8774\n",
      "Class 1 - Precision: 0.6809, Recall: 0.8725, F1-Score: 0.7649\n",
      "Class 2 - Precision: 0.6874, Recall: 0.8673, F1-Score: 0.7669\n",
      "Validation Loss: -16.1888, Accuracy: 0.8179, F1: 0.8031\n",
      "\n",
      "\n",
      "Epoch 39, Training Loss: -17.0384\n",
      "Learning Rate: 0.0001475832377870555\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0112\n",
      "shared_transformer_blocks: 0.0153\n",
      "task_transformer_blocks: 0.0042\n",
      "length_adapter: 0.0195\n",
      "structure_head: 0.0118\n",
      "Class 0 - Precision: 0.9539, Recall: 0.7885, F1-Score: 0.8633\n",
      "Class 1 - Precision: 0.6527, Recall: 0.8873, F1-Score: 0.7521\n",
      "Class 2 - Precision: 0.6619, Recall: 0.8827, F1-Score: 0.7565\n",
      "Validation Loss: -16.2649, Accuracy: 0.8154, F1: 0.7906\n",
      "\n",
      "\n",
      "Epoch 40, Training Loss: -17.1244\n",
      "Learning Rate: 0.00015200014934540793\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0112\n",
      "shared_transformer_blocks: 0.0153\n",
      "task_transformer_blocks: 0.0042\n",
      "length_adapter: 0.0195\n",
      "structure_head: 0.0116\n",
      "Class 0 - Precision: 0.9492, Recall: 0.8061, F1-Score: 0.8718\n",
      "Class 1 - Precision: 0.6749, Recall: 0.8724, F1-Score: 0.7611\n",
      "Class 2 - Precision: 0.6709, Recall: 0.8787, F1-Score: 0.7608\n",
      "Validation Loss: -16.6277, Accuracy: 0.8185, F1: 0.7979\n",
      "Best model saved with validation loss: -16.6277\n",
      "\n",
      "\n",
      "Epoch 41, Training Loss: -17.1410\n",
      "Learning Rate: 0.0001562854956052208\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0112\n",
      "shared_transformer_blocks: 0.0154\n",
      "task_transformer_blocks: 0.0042\n",
      "length_adapter: 0.0197\n",
      "structure_head: 0.0113\n",
      "Class 0 - Precision: 0.9480, Recall: 0.8152, F1-Score: 0.8766\n",
      "Class 1 - Precision: 0.6815, Recall: 0.8739, F1-Score: 0.7658\n",
      "Class 2 - Precision: 0.6825, Recall: 0.8719, F1-Score: 0.7657\n",
      "Validation Loss: -16.4486, Accuracy: 0.8197, F1: 0.8027\n",
      "\n",
      "\n",
      "Epoch 42, Training Loss: -17.1831\n",
      "Learning Rate: 0.00016042753071012265\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0112\n",
      "shared_transformer_blocks: 0.0155\n",
      "task_transformer_blocks: 0.0041\n",
      "length_adapter: 0.0197\n",
      "structure_head: 0.0111\n",
      "Class 0 - Precision: 0.9509, Recall: 0.8066, F1-Score: 0.8728\n",
      "Class 1 - Precision: 0.6774, Recall: 0.8776, F1-Score: 0.7646\n",
      "Class 2 - Precision: 0.6726, Recall: 0.8818, F1-Score: 0.7632\n",
      "Validation Loss: -16.6491, Accuracy: 0.8202, F1: 0.8002\n",
      "Best model saved with validation loss: -16.6491\n",
      "\n",
      "\n",
      "Epoch 43, Training Loss: -17.2063\n",
      "Learning Rate: 0.0001644149016103299\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0111\n",
      "shared_transformer_blocks: 0.0155\n",
      "task_transformer_blocks: 0.0041\n",
      "length_adapter: 0.0198\n",
      "structure_head: 0.0109\n",
      "Class 0 - Precision: 0.9484, Recall: 0.8170, F1-Score: 0.8778\n",
      "Class 1 - Precision: 0.6812, Recall: 0.8721, F1-Score: 0.7649\n",
      "Class 2 - Precision: 0.6871, Recall: 0.8750, F1-Score: 0.7697\n",
      "Validation Loss: -16.8567, Accuracy: 0.8217, F1: 0.8041\n",
      "Best model saved with validation loss: -16.8567\n",
      "\n",
      "\n",
      "Epoch 44, Training Loss: -17.2473\n",
      "Learning Rate: 0.00016823667918062054\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0111\n",
      "shared_transformer_blocks: 0.0156\n",
      "task_transformer_blocks: 0.0041\n",
      "length_adapter: 0.0198\n",
      "structure_head: 0.0107\n",
      "Class 0 - Precision: 0.9533, Recall: 0.8020, F1-Score: 0.8711\n",
      "Class 1 - Precision: 0.6738, Recall: 0.8839, F1-Score: 0.7647\n",
      "Class 2 - Precision: 0.6681, Recall: 0.8833, F1-Score: 0.7608\n",
      "Validation Loss: -16.5059, Accuracy: 0.8209, F1: 0.7989\n",
      "\n",
      "\n",
      "Epoch 45, Training Loss: -17.2824\n",
      "Learning Rate: 0.0001718823881763579\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0110\n",
      "shared_transformer_blocks: 0.0156\n",
      "task_transformer_blocks: 0.0040\n",
      "length_adapter: 0.0202\n",
      "structure_head: 0.0104\n",
      "Class 0 - Precision: 0.9519, Recall: 0.8077, F1-Score: 0.8739\n",
      "Class 1 - Precision: 0.6777, Recall: 0.8802, F1-Score: 0.7658\n",
      "Class 2 - Precision: 0.6757, Recall: 0.8828, F1-Score: 0.7654\n",
      "Validation Loss: -16.8494, Accuracy: 0.8219, F1: 0.8017\n",
      "\n",
      "\n",
      "Epoch 46, Training Loss: -17.2561\n",
      "Learning Rate: 0.0001753420359454575\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0109\n",
      "shared_transformer_blocks: 0.0157\n",
      "task_transformer_blocks: 0.0040\n",
      "length_adapter: 0.0203\n",
      "structure_head: 0.0102\n",
      "Class 0 - Precision: 0.9480, Recall: 0.8217, F1-Score: 0.8803\n",
      "Class 1 - Precision: 0.6916, Recall: 0.8724, F1-Score: 0.7716\n",
      "Class 2 - Precision: 0.6877, Recall: 0.8742, F1-Score: 0.7698\n",
      "Validation Loss: -16.5044, Accuracy: 0.8238, F1: 0.8072\n",
      "\n",
      "\n",
      "Epoch 47, Training Loss: -17.3391\n",
      "Learning Rate: 0.00017860613981759873\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0109\n",
      "shared_transformer_blocks: 0.0158\n",
      "task_transformer_blocks: 0.0040\n",
      "length_adapter: 0.0205\n",
      "structure_head: 0.0100\n",
      "Class 0 - Precision: 0.9514, Recall: 0.8148, F1-Score: 0.8778\n",
      "Class 1 - Precision: 0.6812, Recall: 0.8819, F1-Score: 0.7687\n",
      "Class 2 - Precision: 0.6874, Recall: 0.8795, F1-Score: 0.7717\n",
      "Validation Loss: -16.8211, Accuracy: 0.8242, F1: 0.8061\n",
      "\n",
      "\n",
      "Epoch 48, Training Loss: -17.3709\n",
      "Learning Rate: 0.0001816657530956096\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0109\n",
      "shared_transformer_blocks: 0.0158\n",
      "task_transformer_blocks: 0.0040\n",
      "length_adapter: 0.0206\n",
      "structure_head: 0.0098\n",
      "Class 0 - Precision: 0.9512, Recall: 0.8101, F1-Score: 0.8750\n",
      "Class 1 - Precision: 0.6778, Recall: 0.8806, F1-Score: 0.7660\n",
      "Class 2 - Precision: 0.6801, Recall: 0.8797, F1-Score: 0.7671\n",
      "Validation Loss: -16.8084, Accuracy: 0.8238, F1: 0.8027\n",
      "\n",
      "\n",
      "Epoch 49, Training Loss: -17.3900\n",
      "Learning Rate: 0.00018451248957778395\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0108\n",
      "shared_transformer_blocks: 0.0159\n",
      "task_transformer_blocks: 0.0039\n",
      "length_adapter: 0.0206\n",
      "structure_head: 0.0096\n",
      "Class 0 - Precision: 0.9536, Recall: 0.8093, F1-Score: 0.8756\n",
      "Class 1 - Precision: 0.6820, Recall: 0.8846, F1-Score: 0.7702\n",
      "Class 2 - Precision: 0.6776, Recall: 0.8860, F1-Score: 0.7679\n",
      "Validation Loss: -16.8728, Accuracy: 0.8249, F1: 0.8046\n",
      "Best model saved with validation loss: -16.8728\n",
      "\n",
      "\n",
      "Epoch 50, Training Loss: -17.3875\n",
      "Learning Rate: 0.00018713854654391676\n",
      "Average Gradient Norms per Layer:\n",
      "embedding: 0.0108\n",
      "shared_transformer_blocks: 0.0159\n",
      "task_transformer_blocks: 0.0039\n",
      "length_adapter: 0.0208\n",
      "structure_head: 0.0095\n",
      "Class 0 - Precision: 0.9491, Recall: 0.8340, F1-Score: 0.8879\n",
      "Class 1 - Precision: 0.7060, Recall: 0.8749, F1-Score: 0.7814\n",
      "Class 2 - Precision: 0.7044, Recall: 0.8771, F1-Score: 0.7813\n",
      "Validation Loss: -17.0069, Accuracy: 0.8277, F1: 0.8169\n",
      "Best model saved with validation loss: -17.0069\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, train_accuracies = [], [], []\n",
    "val_losses, val_f1s, val_accuracies = [], [], []\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    layer_grad_norms = {}  # Dictionary to accumulate grad norms by layer\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_X, batch_y_struct in train_dataloader:\n",
    "        batch_X, batch_y_struct = batch_X.to(device), batch_y_struct.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: batch_X (43) -> structure logits (45)\n",
    "        # Forward pass\n",
    "        pred_struct = model(batch_X)  # Shape: (batch_size, sequence_length, 3)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn_struct(pred_struct, batch_y_struct)  # Shapes match\n",
    "\n",
    "\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate gradient norms by layer name\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                layer_name = name.split('.')[0]  # Use only the first part as layer name\n",
    "                grad_norm = param.grad.norm().item()\n",
    "                if layer_name not in layer_grad_norms:\n",
    "                    layer_grad_norms[layer_name] = []\n",
    "                layer_grad_norms[layer_name].append(grad_norm)\n",
    "\n",
    "        # Gradient clipping\n",
    "        nn_utils.clip_grad_value_(model.parameters(), clip_value=0.1)\n",
    "\n",
    "        # Optimizer and scheduler step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate predictions and mask for valid labels\n",
    "        y_true = batch_y_struct.view(-1)  # 45-element structure target\n",
    "        y_pred = torch.argmax(pred_struct.view(-1, 3), dim=-1)  # Predicted logits\n",
    "        mask = (y_true != vocab_size - 1)  # Valid labels in structure encoding\n",
    "        all_true_labels.append(y_true[mask].cpu())\n",
    "        all_predicted_labels.append(y_pred[mask].cpu())\n",
    "\n",
    "        # Calculate correct predictions\n",
    "        correct_preds += (y_pred[mask] == y_true[mask]).sum().item()\n",
    "        total_preds += mask.sum().item()\n",
    "\n",
    "    # Calculate training metrics\n",
    "    avg_loss = total_loss / num_batches\n",
    "    all_true_labels = torch.cat(all_true_labels)\n",
    "    all_predicted_labels = torch.cat(all_predicted_labels)\n",
    "    train_metrics = calculate_class_metrics(all_true_labels, all_predicted_labels)\n",
    "    avg_train_f1 = print_validation_metrics(train_metrics, printer=False)\n",
    "    accuracy = correct_preds / total_preds\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    train_f1s.append(avg_train_f1)\n",
    "\n",
    "    # Calculate average gradient norms per layer\n",
    "    avg_layer_grad_norms = {layer: sum(norms) / len(norms) for layer, norms in layer_grad_norms.items()}\n",
    "\n",
    "    # Print epoch summary with average layer gradient norms\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    print(\"Average Gradient Norms per Layer:\")\n",
    "    for layer, avg_norm in avg_layer_grad_norms.items():\n",
    "        print(f\"{layer}: {avg_norm:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y_struct in val_dataloader:\n",
    "            val_X, val_y_struct = val_X.to(device), val_y_struct.to(device)\n",
    "            val_pred_struct = model(val_X)\n",
    "            val_loss += loss_fn_struct(val_pred_struct, val_y_struct).item()\n",
    "\n",
    "            # Collect true and predicted labels\n",
    "            y_true = val_y_struct.view(-1)\n",
    "            y_pred = torch.argmax(val_pred_struct.view(-1, 3), dim=-1)\n",
    "            mask = (y_true != vocab_size - 1)\n",
    "            all_y_true.append(y_true[mask])\n",
    "            all_y_pred.append(y_pred[mask])\n",
    "\n",
    "            # Calculate correct predictions\n",
    "            correct_preds += (y_pred[mask] == y_true[mask]).sum().item()\n",
    "            total_preds += mask.sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    all_y_true = torch.cat(all_y_true)\n",
    "    all_y_pred = torch.cat(all_y_pred)\n",
    "    val_metrics = calculate_class_metrics(all_y_true, all_y_pred)\n",
    "    avg_val_f1 = print_validation_metrics(val_metrics)\n",
    "    val_accuracy = correct_preds / total_preds\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1s.append(avg_val_f1)\n",
    "\n",
    "    # Print validation summary\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {avg_val_f1:.4f}\")\n",
    "\n",
    "    # Check for early stopping and save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"12-2_kmerenc.pth\")\n",
    "        print(f\"Best model saved with validation loss: {avg_val_loss:.4f}\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0458b4ec-2b44-442b-93da-611683cf7f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Run this code to save each of the lists\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Save lists to CSV files with filenames related to the model name\n",
    "model_name = \"12-2_kmerenc\"\n",
    "\n",
    "# Create a dictionary for each list to be saved\n",
    "data_to_save = {\n",
    "    f\"{model_name}_train_losses.csv\": train_losses,\n",
    "    f\"{model_name}_train_f1s.csv\": train_f1s,\n",
    "    f\"{model_name}_train_accuracies.csv\": train_accuracies,\n",
    "    f\"{model_name}_val_losses.csv\": val_losses,\n",
    "    f\"{model_name}_val_f1s.csv\": val_f1s,\n",
    "    f\"{model_name}_val_accuracies.csv\": val_accuracies,\n",
    "}\n",
    "\n",
    "# Loop through each list and save it as a CSV\n",
    "for filename, data_list in data_to_save.items():\n",
    "    # Convert list to DataFrame\n",
    "    df = pd.DataFrame(data_list, columns=[filename.split('_')[-1].split('.')[0]])  # Use the metric name as column\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "print(\"Metrics saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fdc62a-36f0-4051-912a-ff90627138a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ad7d2-cf07-45d4-a785-310152261e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd339ae1-25d8-47d2-a51e-bd7782b80e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb84ead4-47c1-4f20-949c-9b466520442a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in dna_sequences:  797\n"
     ]
    }
   ],
   "source": [
    "model_path = \"12-2_kmerenc.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Prepare DNA sequences and structures\n",
    "dna_sequences2 = [seq for seq in test_set.keys() if len(seq) == 45]\n",
    "print(\"Number of sequences in dna_sequences: \", len(dna_sequences2))\n",
    "top_structures2 = [test_set[seq][1] for seq in dna_sequences2]\n",
    "\n",
    "# Encode DNA sequences with k-mers\n",
    "encoded_sequences2 = []\n",
    "for seq in dna_sequences2:\n",
    "    kmers = generate_kmers(seq, kmer_size)\n",
    "    encoded_kmers = encode_kmers(kmers, kmer_size)\n",
    "    encoded_sequences2.append(encoded_kmers)\n",
    "\n",
    "# Ensure all sequences have consistent length\n",
    "#assert all(len(seq) == sequence_length for seq in encoded_sequences2), \"Inconsistent k-mer sequence lengths.\"\n",
    "\n",
    "# Encode structures\n",
    "encoded_structures2 = []\n",
    "for structs in top_structures2:\n",
    "    structure = structs[-1]\n",
    "    encoded = encode_structure(structure)\n",
    "    if len(encoded) != 45:  # Ensure structure length matches the original sequence length\n",
    "        raise ValueError(f\"Structure length {len(encoded)} does not match original sequence length (45).\")\n",
    "    encoded_structures2.append(encoded)\n",
    "\n",
    "\n",
    "# Convert to tensors and split into training and validation sets\n",
    "X2 = torch.tensor(encoded_sequences2, dtype=torch.long)\n",
    "y_struct2 = torch.tensor(encoded_structures2, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d231006-de61-4511-af86-81c15940d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model on some sequences from the test set:\n",
      "\n",
      "Sequence 1: TGT GTC TCA CAT ATG TGA GAA AAA AAG AGC GCG CGT GTC TCC CCC CCC CCA CAA AAG AGT GTC TCC CCA CAT ATC TCA CAA AAG AGA GAC ACG CGC GCA CAG AGG GGG GGA GAT ATT TTG TGC GCT CTA\n",
      "True Structure:    ..........(((((..............)))))...........\n",
      "Predicted Structure: .........(((((((((..(((......))))).))))))))).\n",
      "\n",
      "Sequence 2: TTG TGT GTG TGT GTG TGC GCA CAC ACG CGA GAT ATT TTG TGA GAT ATA TAG AGC GCG CGT GTC TCC CCG CGT GTG TGC GCT CTG TGT GTA TAG AGG GGT GTG TGC GCG CGG GGA GAA AAA AAG AGG GGT\n",
      "True Structure:    ......(((((............))))).................\n",
      "Predicted Structure: ......(((((............))))).................\n",
      "\n",
      "Sequence 3: AAA AAG AGG GGC GCT CTC TCG CGC GCT CTT TTG TGA GAA AAA AAA AAG AGA GAG AGA GAT ATG TGG GGA GAT ATA TAT ATT TTC TCT CTT TTT TTG TGT GTC TCT CTA TAC ACC CCG CGC GCA CAC ACG\n",
      "True Structure:    .(((.....)))..(((((.........)))))............\n",
      "Predicted Structure: .(((.....)))...(((((((....)))))))............\n",
      "\n",
      "Sequence 4: TGC GCG CGC GCG CGT GTG TGT GTC TCA CAC ACC CCG CGA GAT ATA TAT ATT TTC TCA CAG AGC GCT CTT TTC TCA CAG AGC GCG CGA GAG AGC GCC CCG CGC GCT CTG TGT GTT TTT TTT TTA TAA AAG\n",
      "True Structure:    ....((......))...........(((((...))))).......\n",
      "Predicted Structure: ....((......))...........(((((...))))).......\n",
      "\n",
      "Sequence 5: GCG CGT GTA TAT ATC TCA CAG AGC GCG CGC GCC CCC CCT CTT TTT TTG TGT GTA TAT ATA TAT ATC TCC CCG CGT GTC TCG CGC GCT CTT TTG TGG GGA GAA AAG AGA GAG AGG GGA GAT ATG TGC GCG\n",
      "True Structure:    ((((....)))).........((((.............))))...\n",
      "Predicted Structure: ((((....)))).........((((..(((.....))))))))))\n",
      "\n",
      "Sequence 6: AGA GAA AAC ACT CTA TAT ATC TCT CTC TCC CCG CGC GCC CCG CGC GCG CGG GGC GCA CAT ATA TAG AGA GAT ATT TTG TGT GTT TTC TCC CCG CGC GCC CCT CTA TAA AAA AAT ATA TAT ATC TCA CAC\n",
      "True Structure:    .((((.((((..((....))..)))).))))..............\n",
      "Predicted Structure: (((((...)(.....(((....))))))))))))...........\n",
      "\n",
      "Sequence 7: TAT ATG TGG GGG GGC GCG CGT GTA TAA AAG AGA GAG AGC GCT CTA TAC ACG CGA GAT ATC TCT CTA TAG AGA GAG AGG GGA GAG AGT GTG TGG GGG GGT GTA TAA AAA AAG AGG GGT GTC TCT CTA TAG\n",
      "True Structure:    ......((((.....))))..(((((..............)))))\n",
      "Predicted Structure: ......((((.....))))..(((((..............)))))\n",
      "\n",
      "Sequence 8: CTG TGC GCT CTG TGG GGC GCT CTG TGA GAA AAC ACG CGC GCA CAC ACA CAT ATT TTA TAC ACG CGT GTA TAA AAG AGA GAC ACT CTC TCA CAG AGG GGC GCT CTA TAT ATG TGC GCT CTA TAG AGG GGG\n",
      "True Structure:    .......(((((((.......))).....))))............\n",
      "Predicted Structure: ....((((((((((.......))).....))))))...)......\n",
      "\n",
      "Sequence 9: AGC GCA CAT ATC TCG CGT GTG TGC GCA CAT ATA TAC ACG CGC GCC CCG CGA GAA AAA AAG AGT GTA TAA AAT ATG TGA GAA AAA AAC ACC CCC CCC CCT CTT TTA TAC ACA CAG AGA GAA AAT ATA TAA\n",
      "True Structure:    ....(((.((....)))))..((((.........)))).......\n",
      "Predicted Structure: .(((.....)..)))......((((.........)))).......\n",
      "\n",
      "Sequence 10: GAG AGC GCC CCC CCA CAA AAT ATT TTC TCA CAC ACA CAC ACT CTT TTG TGC GCT CTA TAC ACG CGC GCA CAC ACA CAT ATC TCC CCG CGC GCC CCG CGT GTT TTG TGG GGG GGG GGC GCT CTC TCC CCA\n",
      "True Structure:    ((((((....((....))..(((.........)))..))))))..\n",
      "Predicted Structure: ((((((((........(((...))).........)))))))))..\n",
      "\n",
      "Sequence 11: TTT TTA TAG AGA GAG AGG GGG GGG GGT GTG TGG GGA GAC ACT CTT TTA TAC ACC CCA CAC ACC CCT CTG TGC GCC CCG CGC GCC CCT CTC TCC CCG CGG GGG GGT GTG TGT GTG TGA GAG AGT GTT TTA\n",
      "True Structure:    ........(((((.....)))))..(((....)))..........\n",
      "Predicted Structure: ........(((((.....)))))..(((....)))..........\n",
      "\n",
      "Sequence 12: GTC TCG CGG GGG GGA GAT ATC TCT CTA TAA AAT ATG TGC GCA CAC ACT CTC TCG CGG GGC GCA CAT ATA TAG AGC GCC CCC CCC CCG CGG GGC GCC CCA CAT ATC TCG CGC GCT CTC TCG CGG GGA GAC\n",
      "True Structure:    ...........((((.....))))....(((((....)).)))..\n",
      "Predicted Structure: ...(((..(((((((.....)))))).)))).((.......))..\n",
      "\n",
      "Sequence 13: ACT CTG TGT GTG TGA GAT ATA TAG AGA GAC ACT CTG TGT GTG TGC GCC CCT CTC TCC CCT CTT TTA TAC ACG CGG GGA GAT ATA TAA AAG AGT GTC TCG CGG GGT GTG TGG GGT GTG TGC GCC CCT CTC\n",
      "True Structure:    ((.((.....)).)).....((((....))))..((.....))..\n",
      "Predicted Structure: .((.....))..........((((....))))..(((...)))..\n",
      "\n",
      "Sequence 14: AAG AGC GCC CCA CAA AAT ATC TCC CCT CTA TAG AGT GTG TGC GCC CCG CGG GGC GCC CCG CGG GGA GAG AGC GCC CCT CTC TCG CGT GTT TTA TAT ATG TGA GAC ACC CCA CAT ATT TTT TTC TCC CCG\n",
      "True Structure:    ..(((............)))((((.................))))\n",
      "Predicted Structure: ..((..........)).(((((...)).....((....)).))))\n",
      "\n",
      "Sequence 15: CCT CTT TTG TGC GCG CGA GAC ACC CCG CGT GTG TGG GGG GGC GCA CAG AGA GAG AGG GGC GCC CCT CTG TGC GCG CGA GAC ACC CCC CCA CAG AGC GCG CGC GCA CAT ATA TAT ATT TTC TCT CTT TTG\n",
      "True Structure:    ....(((..(((((((....)))))))......))).........\n",
      "Predicted Structure: .....((..(((((((((....))))..)))).))).........\n",
      "\n",
      "Sequence 16: CCG CGA GAC ACC CCA CAA AAC ACG CGT GTT TTA TAT ATC TCT CTA TAA AAA AAG AGA GAG AGG GGC GCC CCA CAC ACG CGG GGG GGG GGT GTG TGT GTC TCA CAC ACC CCC CCG CGT GTG TGC GCG CGC\n",
      "True Structure:    .((.....))............((((((((......)))))).))\n",
      "Predicted Structure: .((.....))..............((((((((...))))))).).\n",
      "\n",
      "Sequence 17: GGA GAC ACG CGG GGA GAC ACC CCC CCT CTA TAC ACA CAC ACG CGG GGG GGT GTC TCC CCT CTT TTG TGA GAT ATA TAA AAC ACG CGA GAC ACA CAA AAG AGC GCT CTA TAT ATC TCG CGA GAC ACT CTC\n",
      "True Structure:    ....((((((.....)))))).......(((.......)))....\n",
      "Predicted Structure: ....((((((.....)))))).......(((.......)))....\n",
      "\n",
      "Sequence 18: CAA AAG AGT GTC TCA CAA AAC ACC CCC CCT CTA TAC ACT CTG TGC GCC CCA CAT ATA TAC ACT CTG TGT GTA TAG AGC GCC CCA CAT ATA TAG AGA GAT ATC TCC CCT CTA TAC ACC CCG CGG GGG GGG\n",
      "True Structure:    ..........((((.........))))........((.....)).\n",
      "Predicted Structure: ..........((((.........))))........((....))).\n",
      "\n",
      "Sequence 19: TTC TCG CGT GTC TCA CAA AAT ATT TTA TAC ACA CAC ACA CAA AAC ACT CTC TCT CTC TCA CAC ACA CAA AAT ATA TAG AGT GTC TCT CTA TAT ATG TGA GAT ATC TCT CTC TCG CGG GGT GTA TAT ATT\n",
      "True Structure:    ...((.....))..........((........))...........\n",
      "Predicted Structure: ...((.....))..........((........))...........\n",
      "\n",
      "Sequence 20: CAC ACG CGC GCG CGT GTT TTT TTG TGC GCT CTA TAT ATT TTG TGA GAG AGA GAC ACA CAG AGA GAT ATC TCA CAC ACG CGA GAG AGC GCT CTA TAA AAT ATA TAA AAA AAT ATT TTG TGG GGA GAT ATA\n",
      "True Structure:    .........(((..(((......)))..)))..............\n",
      "Predicted Structure: .........(((..(((......))).))))..............\n",
      "\n",
      "Sequence 21: CCG CGT GTT TTC TCC CCA CAC ACA CAC ACG CGT GTT TTG TGA GAT ATT TTA TAT ATT TTG TGA GAT ATG TGG GGC GCT CTT TTC TCA CAG AGA GAC ACC CCG CGG GGG GGC GCG CGC GCT CTA TAT ATG\n",
      "True Structure:    .(((.....)))..........(((((............))))).\n",
      "Predicted Structure: .(((.....))).........(((((...........))))))).\n",
      "\n",
      "Sequence 22: GTA TAG AGC GCG CGA GAT ATA TAA AAC ACC CCC CCG CGG GGT GTG TGA GAT ATC TCA CAT ATG TGT GTG TGC GCT CTG TGG GGG GGC GCC CCG CGC GCC CCC CCC CCG CGG GGT GTG TGC GCC CCG CGG\n",
      "True Structure:    ...(((....((((((........)))))).))).(((....)))\n",
      "Predicted Structure: ..((((....(((((....(....)))))(((....)))))))))\n",
      "\n",
      "Sequence 23: CTC TCC CCG CGA GAT ATA TAT ATT TTA TAA AAA AAT ATA TAG AGG GGG GGT GTG TGA GAA AAG AGT GTC TCG CGT GTA TAT ATA TAC ACC CCA CAC ACA CAT ATG TGT GTT TTA TAG AGG GGG GGC GCA\n",
      "True Structure:    ................(((..........))).............\n",
      "Predicted Structure: ...((((((...))).(((....)))....))))......))...\n",
      "\n",
      "Sequence 24: GTC TCC CCT CTG TGT GTG TGG GGG GGC GCG CGA GAG AGG GGC GCG CGT GTC TCG CGG GGA GAG AGC GCC CCA CAA AAT ATT TTC TCG CGT GTC TCT CTG TGG GGA GAG AGA GAA AAC ACC CCT CTC TCT\n",
      "True Structure:    ..((....))...(((......))).........((....))...\n",
      "Predicted Structure: ..((....))...(((......)))..........(((...))).\n",
      "\n",
      "Sequence 25: GCG CGC GCG CGT GTC TCT CTT TTG TGG GGC GCA CAT ATT TTT TTC TCC CCA CAG AGA GAT ATG TGG GGC GCG CGT GTA TAC ACA CAC ACT CTA TAG AGC GCC CCT CTG TGA GAG AGC GCC CCG CGT GTA\n",
      "True Structure:    .(((.(((.((.....)))))..))).......((....))....\n",
      "Predicted Structure: .((((((((((.....)))))))))).......((....))....\n",
      "\n",
      "Sequence 26: GCA CAT ATA TAC ACA CAG AGA GAG AGG GGG GGC GCT CTC TCA CAA AAC ACT CTA TAC ACT CTT TTG TGC GCT CTT TTT TTA TAG AGG GGG GGG GGC GCC CCC CCT CTC TCG CGA GAA AAG AGG GGT GTC\n",
      "True Structure:    .......(((((((.................))))))).......\n",
      "Predicted Structure: .......((((((((..(((.......))))))))))).......\n",
      "\n",
      "Sequence 27: AAG AGT GTC TCC CCT CTC TCG CGG GGG GGA GAC ACG CGT GTG TGT GTG TGG GGC GCC CCC CCC CCA CAA AAG AGC GCT CTG TGC GCG CGC GCC CCC CCC CCT CTA TAA AAA AAG AGC GCT CTC TCT CTT\n",
      "True Structure:    ..((((...))))...........((((..........))))...\n",
      "Predicted Structure: .......(((...)(..(((......)..)))).....))))...\n",
      "\n",
      "Sequence 28: GTC TCG CGC GCT CTA TAA AAC ACT CTA TAG AGT GTA TAG AGG GGT GTG TGG GGC GCC CCC CCC CCG CGC GCA CAG AGT GTT TTG TGA GAA AAT ATC TCG CGC GCT CTC TCC CCT CTC TCT CTA TAT ATG\n",
      "True Structure:    ....(((.....)))...((...))....................\n",
      "Predicted Structure: ....(((.....))).(((....))..).................\n",
      "\n",
      "Sequence 29: CCA CAT ATC TCT CTG TGG GGA GAT ATG TGC GCG CGG GGG GGC GCC CCC CCG CGT GTC TCC CCA CAA AAC ACA CAA AAT ATA TAT ATC TCG CGT GTC TCC CCC CCC CCG CGG GGA GAG AGG GGC GCG CGA\n",
      "True Structure:    ((....))...((((..((...........))..)))).......\n",
      "Predicted Structure: ........((((((...))))).......(((((.....))))))\n",
      "\n",
      "Sequence 30: CTC TCG CGG GGT GTC TCA CAT ATA TAT ATG TGG GGA GAG AGA GAA AAT ATA TAG AGG GGC GCT CTG TGT GTG TGT GTC TCA CAG AGA GAC ACC CCT CTA TAC ACG CGT GTC TCT CTC TCA CAA AAA AAT\n",
      "True Structure:    ............((((.(((((((...))).))))..))))....\n",
      "Predicted Structure: ............((((.(((((((...))).))))..))))....\n",
      "\n",
      "Sequence 31: TCT CTT TTC TCA CAA AAC ACC CCT CTG TGT GTC TCG CGG GGG GGT GTG TGA GAT ATA TAA AAT ATC TCC CCA CAA AAA AAA AAC ACG CGC GCT CTG TGC GCA CAC ACG CGC GCA CAT ATC TCG CGC GCT\n",
      "True Structure:    ....((.((....)).))...........((.....)).......\n",
      "Predicted Structure: ......(((.....)))............((.....)).......\n",
      "\n",
      "Sequence 32: ACG CGA GAA AAC ACG CGT GTG TGG GGG GGC GCA CAA AAT ATG TGT GTG TGA GAG AGG GGC GCA CAT ATA TAG AGC GCG CGT GTG TGA GAA AAT ATA TAC ACC CCC CCG CGC GCC CCC CCG CGC GCG CGA\n",
      "True Structure:    .....(((((((.(((.....)))...((....))..))))))).\n",
      "Predicted Structure: .....(((((((.((((.....)).))).....))..))))))).\n",
      "\n",
      "Sequence 33: AAG AGC GCT CTG TGA GAT ATC TCC CCG CGG GGT GTG TGT GTC TCA CAA AAA AAT ATT TTC TCG CGC GCC CCA CAC ACT CTG TGC GCT CTA TAA AAT ATC TCA CAT ATT TTT TTA TAT ATA TAA AAG AGT\n",
      "True Structure:    ..........((((.......))))....................\n",
      "Predicted Structure: .....(((..(....)..........).))..))...........\n",
      "\n",
      "Sequence 34: ACT CTT TTA TAC ACA CAT ATT TTA TAA AAC ACA CAA AAA AAA AAC ACC CCT CTC TCC CCC CCT CTG TGG GGC GCT CTC TCA CAC ACT CTA TAA AAA AAA AAT ATT TTA TAA AAG AGG GGC GCC CCC CCA\n",
      "True Structure:    .......................(((..............)))..\n",
      "Predicted Structure: .......................((((............))))..\n",
      "\n",
      "Sequence 35: GCC CCC CCC CCA CAC ACA CAG AGA GAA AAA AAC ACA CAA AAC ACA CAC ACT CTG TGC GCG CGC GCC CCG CGA GAG AGG GGG GGG GGA GAT ATG TGT GTA TAG AGT GTT TTA TAA AAT ATC TCG CGG GGT\n",
      "True Structure:    ......(((........)))..((((..............)))).\n",
      "Predicted Structure: ......(((........)))..((((..............)))).\n",
      "\n",
      "Sequence 36: GCA CAC ACT CTC TCG CGG GGA GAT ATA TAG AGT GTT TTG TGG GGT GTC TCG CGT GTT TTA TAG AGG GGA GAG AGC GCA CAT ATA TAG AGA GAG AGC GCT CTA TAA AAG AGG GGT GTT TTC TCG CGT GTC\n",
      "True Structure:    ..(((.....)))...........(((.....)))..........\n",
      "Predicted Structure: ..(((((...)))....)).....(((.....)))..........\n",
      "\n",
      "Sequence 37: CCT CTT TTT TTC TCT CTT TTG TGT GTA TAA AAC ACC CCT CTG TGG GGT GTC TCC CCC CCG CGA GAA AAA AAA AAA AAA AAT ATC TCA CAC ACC CCA CAT ATT TTG TGT GTT TTT TTC TCT CTA TAC ACG\n",
      "True Structure:    ..........(((.((((............))))..)))......\n",
      "Predicted Structure: ..........(((.((((............))))..)))......\n",
      "\n",
      "Sequence 38: GTT TTG TGT GTC TCA CAT ATT TTT TTC TCG CGT GTC TCC CCT CTA TAG AGC GCG CGC GCT CTC TCT CTT TTA TAT ATG TGT GTT TTA TAG AGA GAG AGC GCC CCA CAA AAA AAG AGC GCA CAG AGG GGG\n",
      "True Structure:    .............(((.(((((((......)))))....))))).\n",
      "Predicted Structure: .............(((.(((((((......)))))...)))))).\n",
      "\n",
      "Sequence 39: CGA GAA AAG AGA GAC ACA CAT ATA TAT ATA TAC ACG CGT GTA TAC ACT CTC TCG CGT GTA TAG AGG GGC GCC CCT CTA TAG AGA GAA AAA AAC ACC CCC CCT CTA TAG AGT GTA TAA AAA AAC ACG CGA\n",
      "True Structure:    ..........((((....))))...((((.....)))).......\n",
      "Predicted Structure: ...........(((....)))....((((.....)))).......\n",
      "\n",
      "Sequence 40: ATC TCC CCC CCT CTG TGC GCT CTG TGA GAG AGT GTA TAC ACA CAC ACG CGA GAA AAA AAG AGC GCC CCA CAA AAT ATG TGG GGC GCG CGC GCA CAG AGC GCG CGG GGT GTG TGC GCA CAA AAG AGG GGT\n",
      "True Structure:    ......(((...........))).....((((....)))).....\n",
      "Predicted Structure: .....(((((......(....))(...)))(......))).....\n",
      "\n",
      "Sequence 41: ATA TAG AGG GGG GGT GTT TTA TAG AGT GTA TAC ACA CAT ATA TAT ATT TTG TGG GGA GAC ACT CTG TGC GCC CCG CGG GGA GAC ACC CCA CAC ACG CGA GAA AAA AAA AAC ACC CCC CCG CGA GAG AGG\n",
      "True Structure:    ...((((((((.((...)).)))..((.....))..)))))....\n",
      "Predicted Structure: ....((((((..((...))..)).))((....(....)))))...\n",
      "\n",
      "Sequence 42: GAA AAG AGT GTG TGT GTG TGT GTT TTG TGA GAT ATA TAC ACA CAC ACC CCA CAA AAA AAA AAG AGT GTT TTA TAA AAG AGA GAA AAC ACT CTG TGC GCA CAA AAT ATG TGA GAA AAC ACT CTT TTA TAA\n",
      "True Structure:    .....((((....))))...(((((.............)))))..\n",
      "Predicted Structure: ...((((((....))))...((((((....))......)))))))\n",
      "\n",
      "Sequence 43: GGA GAG AGC GCT CTC TCA CAG AGT GTC TCC CCC CCA CAA AAG AGG GGT GTA TAC ACC CCT CTC TCT CTC TCC CCA CAC ACC CCG CGG GGG GGT GTT TTG TGC GCA CAG AGC GCG CGC GCA CAT ATC TCA\n",
      "True Structure:    ..........(((..(((........))))))..((...))....\n",
      "Predicted Structure: .((.......(((..(((....))))..))))..((...))....\n",
      "\n",
      "Sequence 44: GCC CCC CCA CAC ACT CTG TGT GTA TAG AGT GTA TAA AAC ACT CTA TAT ATG TGG GGG GGT GTG TGT GTC TCC CCA CAT ATA TAG AGT GTG TGT GTG TGC GCC CCA CAT ATG TGA GAT ATG TGC GCT CTT\n",
      "True Structure:    .............(((((((....)))))))..((......))..\n",
      "Predicted Structure: ..........)).(((((((....)))))))...((.....))..\n",
      "\n",
      "Sequence 45: AGG GGG GGT GTG TGA GAA AAT ATG TGG GGG GGC GCA CAG AGT GTA TAG AGG GGT GTG TGA GAA AAA AAG AGA GAT ATT TTA TAG AGA GAC ACA CAC ACA CAT ATG TGG GGG GGA GAG AGG GGG GGT GTT\n",
      "True Structure:    ..................(((..........)))...........\n",
      "Predicted Structure: ..................(((..........)))...........\n",
      "\n",
      "Sequence 46: GCT CTT TTC TCC CCC CCA CAC ACA CAT ATT TTC TCT CTG TGG GGT GTA TAA AAA AAT ATC TCC CCC CCA CAG AGC GCG CGT GTA TAT ATT TTT TTA TAC ACT CTC TCA CAT ATA TAA AAA AAC ACG CGG\n",
      "True Structure:    ...............((((((........))))))..........\n",
      "Predicted Structure: ............((((......)))).((.((((....)))))).\n",
      "\n",
      "Sequence 47: CAA AAT ATC TCA CAG AGG GGA GAC ACC CCT CTT TTG TGT GTC TCT CTA TAA AAT ATC TCT CTC TCC CCA CAC ACT CTC TCG CGA GAG AGG GGT GTT TTT TTT TTA TAA AAT ATG TGA GAA AAG AGA GAA\n",
      "True Structure:    .......(((...)))....(((.....)))..............\n",
      "Predicted Structure: .......(((...)))....(((.....)))..............\n",
      "\n",
      "Sequence 48: TAC ACG CGT GTG TGT GTG TGT GTA TAC ACT CTA TAC ACC CCC CCC CCA CAT ATC TCC CCG CGG GGT GTG TGA GAA AAT ATC TCA CAC ACA CAG AGT GTG TGG GGC GCC CCG CGG GGA GAC ACA CAT ATA\n",
      "True Structure:    .((....)).........((((((...........))))))....\n",
      "Predicted Structure: .((....)).........((((((...........))))))....\n",
      "\n",
      "Sequence 49: ACA CAG AGG GGC GCG CGG GGT GTA TAT ATC TCC CCT CTC TCG CGA GAT ATC TCC CCT CTC TCA CAA AAA AAC ACC CCA CAA AAT ATC TCC CCT CTT TTA TAG AGG GGC GCC CCG CGT GTA TAC ACA CAG\n",
      "True Structure:    ..............((..(((.............))).)).....\n",
      "Predicted Structure: .....((((..(((.(.............))...)))))).....\n",
      "\n",
      "Sequence 50: AGG GGC GCG CGG GGA GAC ACG CGC GCG CGG GGG GGG GGG GGG GGT GTC TCC CCC CCA CAT ATC TCT CTG TGA GAT ATC TCA CAG AGA GAT ATC TCC CCT CTG TGG GGC GCT CTA TAA AAT ATC TCG CGG\n",
      "True Structure:    ....((((.......)))).((((....)))).............\n",
      "Predicted Structure: ..(((...)).(((...))).......((....))).........\n"
     ]
    }
   ],
   "source": [
    "# Pick some sequences from the validation set\n",
    "num_test_sequences = 50  # Number of sequences to test\n",
    "test_sequences = X2[:num_test_sequences]\n",
    "test_structures = y_struct2[:num_test_sequences]\n",
    "\n",
    "def enforce_symmetry_and_minimum_distance(pred_structure, min_distance=3):\n",
    "    pred_structure = list(pred_structure)  # Convert the string into a list of characters\n",
    "    stack = []\n",
    "    for i, char in enumerate(pred_structure):\n",
    "        if char == '(':\n",
    "            stack.append(i)\n",
    "        elif char == ')':\n",
    "            if stack:\n",
    "                opening_index = stack.pop()\n",
    "                # Enforce minimum distance rule\n",
    "                if i - opening_index - 1 < min_distance or ''.join(pred_structure[opening_index + 1:i]).count('.') < min_distance:\n",
    "                    # Replace invalid pair with dots\n",
    "                    pred_structure[opening_index] = '.'\n",
    "                    pred_structure[i] = '.'\n",
    "    # Replace unmatched '(' with '.'\n",
    "    for i in stack:\n",
    "        pred_structure[i] = '.'\n",
    "    return ''.join(pred_structure)  # Convert the list back to a string\n",
    "\n",
    "\n",
    "# Function to decode structure\n",
    "def decode_structure(encoded):\n",
    "    structure_mapping = {0: '.', 1: '(', 2: ')', 3: '-'}  # '-' represents padding\n",
    "    return ''.join([structure_mapping[code.item()] for code in encoded])\n",
    "\n",
    "# Generate reverse mapping for k-mers\n",
    "def generate_reverse_kmer_mapping(k):\n",
    "    \"\"\"Generate reverse mapping for decoding k-mer indices.\"\"\"\n",
    "    bases = ['A', 'T', 'C', 'G']\n",
    "    kmer_mapping = {\"\".join(kmer): idx for idx, kmer in enumerate(itertools.product(bases, repeat=k))}\n",
    "    reverse_kmer_mapping = {v: k for k, v in kmer_mapping.items()}\n",
    "    return reverse_kmer_mapping\n",
    "\n",
    "# Generate reverse k-mer mapping for k=3\n",
    "reverse_kmer_mapping = generate_reverse_kmer_mapping(kmer_size)\n",
    "\n",
    "# Decode k-mer sequences\n",
    "def decode_kmer_sequence(sequence, reverse_mapping):\n",
    "    \"\"\"Decode a sequence of k-mer indices into a string of k-mers.\"\"\"\n",
    "    return [reverse_mapping.get(idx.item(), '???') for idx in sequence]\n",
    "\n",
    "# Function to validate indices in sequences\n",
    "def validate_sequence_indices(sequence, vocab_size):\n",
    "    \"\"\"Validate that all indices in the sequence are within the valid range.\"\"\"\n",
    "    if not torch.all((sequence >= 0) & (sequence < vocab_size)):\n",
    "        invalid_indices = sequence[(sequence < 0) | (sequence >= vocab_size)]\n",
    "        raise ValueError(f\"Invalid indices in sequence: {invalid_indices.tolist()}\")\n",
    "\n",
    "# Testing loop\n",
    "print(\"Testing the model on some sequences from the test set:\")\n",
    "with torch.no_grad():\n",
    "    for i, (sequence, true_structure) in enumerate(zip(test_sequences, test_structures)):\n",
    "        sequence = sequence.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        true_structure = true_structure.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        \n",
    "        # Validate sequence indices\n",
    "        try:\n",
    "            validate_sequence_indices(sequence[0], vocab_size=4**kmer_size)  # Ensure indices are in range\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping sequence {i + 1} due to invalid indices: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Predict structure\n",
    "        pred_structure_logits = model(sequence)\n",
    "        pred_structure = torch.argmax(pred_structure_logits.squeeze(0), dim=-1)  # Remove batch dimension\n",
    "        \n",
    "        # Decode sequence and structures\n",
    "        decoded_sequence = decode_kmer_sequence(sequence[0], reverse_kmer_mapping)  # Decode k-mers\n",
    "        decoded_true_structure = decode_structure(true_structure.squeeze(0))\n",
    "        decoded_pred_structure = decode_structure(pred_structure)\n",
    "\n",
    "        # Enforce symmetry and minimum distance rule\n",
    "        corrected_pred_structure = enforce_symmetry_and_minimum_distance(decoded_pred_structure)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\nSequence {i + 1}: {' '.join(decoded_sequence)}\")\n",
    "        print(f\"True Structure:    {decoded_true_structure}\")\n",
    "        print(f\"Predicted Structure: {corrected_pred_structure}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8d758-7dc8-4ffb-b9fe-527ef1b766ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc7cd1-6d06-4ad1-b9c1-c9844b458390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
