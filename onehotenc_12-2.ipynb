{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f8839ca-b2fc-4009-831a-97a7f6b2eaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of combined dataset after filtering: 1294216\n",
      "Training set size: 1292921\n",
      "Test set size: 1295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load all datasets\n",
    "with open('database1_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database1_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database2_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database2_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database3_allstructs_34ave.pkl', 'rb') as file:\n",
    "    database3_allstructs_34ave = pickle.load(file)\n",
    "\n",
    "with open('database4_1structsonly_34ave.pkl', 'rb') as file:\n",
    "    database4_1structsonly_34ave = pickle.load(file)\n",
    "\n",
    "with open('database5_1structsonly_50ave.pkl', 'rb') as file:\n",
    "    database5_1structsonly_50ave = pickle.load(file)\n",
    "\n",
    "with open('database6_allstructs_50ave.pkl', 'rb') as file:\n",
    "    database6_allstructs_50ave = pickle.load(file)\n",
    "\n",
    "with open('database7_allstructs_50ave.pkl', 'rb') as file:\n",
    "    database7_allstructs_50ave = pickle.load(file)\n",
    "\n",
    "with open('database9_allstructs_40ave.pkl', 'rb') as file:\n",
    "    database9_allstructs_40ave = pickle.load(file)\n",
    "\n",
    "with open('database10_allstructs_40ave.pkl', 'rb') as file:\n",
    "    database10_allstructs_40ave = pickle.load(file)\n",
    "\n",
    "with open('database11_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database11_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database13_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database13_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database14_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database14_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database15_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database15_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database16_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database16_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database17_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database17_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database18_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database18_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database19_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database19_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database20_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database20_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database21_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database21_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database22_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database22_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database23_allstructs_45ave.pkl', 'rb') as file:\n",
    "    database23_allstructs_45ave = pickle.load(file)\n",
    "\n",
    "with open('database24_allstructs_45only.pkl', 'rb') as file:\n",
    "    database24_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database25_allstructs_45only.pkl', 'rb') as file:\n",
    "    database25_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database26_allstructs_45only.pkl', 'rb') as file:\n",
    "    database26_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database27_allstructs_45only.pkl', 'rb') as file:\n",
    "    database27_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database28_allstructs_45only.pkl', 'rb') as file:\n",
    "    database28_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database29_allstructs_45only.pkl', 'rb') as file:\n",
    "    database29_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database30_allstructs_45only.pkl', 'rb') as file:\n",
    "    database30_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database31_allstructs_45only.pkl', 'rb') as file:\n",
    "    database31_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database32_allstructs_45only.pkl', 'rb') as file:\n",
    "    database32_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database33_allstructs_45only.pkl', 'rb') as file:\n",
    "    database33_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database34_allstructs_45only.pkl', 'rb') as file:\n",
    "    database34_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database35_allstructs_45only.pkl', 'rb') as file:\n",
    "    database35_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database36_allstructs_45only.pkl', 'rb') as file:\n",
    "    database36_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database37_allstructs_45only.pkl', 'rb') as file:\n",
    "    database37_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database38_allstructs_45only.pkl', 'rb') as file:\n",
    "    database38_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database39_allstructs_45only.pkl', 'rb') as file:\n",
    "    database39_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database40_allstructs_45only.pkl', 'rb') as file:\n",
    "    database40_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database41_allstructs_45only.pkl', 'rb') as file:\n",
    "    database41_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database42_allstructs_45only.pkl', 'rb') as file:\n",
    "    database42_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database43_allstructs_45only.pkl', 'rb') as file:\n",
    "    database43_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database44_allstructs_45only.pkl', 'rb') as file:\n",
    "    database44_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database45_allstructs_45only.pkl', 'rb') as file:\n",
    "    database45_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database46_allstructs_45only.pkl', 'rb') as file:\n",
    "    database46_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database47_allstructs_45only.pkl', 'rb') as file:\n",
    "    database47_allstructs_45only = pickle.load(file)\n",
    "\n",
    "with open('database48_allstructs_45only.pkl', 'rb') as file:\n",
    "    database48_allstructs_45only = pickle.load(file)\n",
    "    \n",
    "\n",
    "# Combine datasets into a single dictionary\n",
    "combined_data = {}\n",
    "datasets = [\n",
    "    database1_allstructs_34ave, database2_allstructs_34ave, database3_allstructs_34ave,\n",
    "    database4_1structsonly_34ave, database5_1structsonly_50ave, database6_allstructs_50ave,\n",
    "    database7_allstructs_50ave, database9_allstructs_40ave, database10_allstructs_40ave, \n",
    "    database11_allstructs_45ave, database13_allstructs_45ave, database14_allstructs_45ave,\n",
    "    database15_allstructs_45ave, database16_allstructs_45ave, database17_allstructs_45ave,\n",
    "    database18_allstructs_45ave, database19_allstructs_45ave, database20_allstructs_45ave,\n",
    "    database21_allstructs_45ave, database22_allstructs_45ave, database23_allstructs_45ave,\n",
    "    database24_allstructs_45only, database25_allstructs_45only, database26_allstructs_45only,\n",
    "    database27_allstructs_45only, database28_allstructs_45only, database29_allstructs_45only,\n",
    "    database30_allstructs_45only, database31_allstructs_45only, database32_allstructs_45only,\n",
    "    database33_allstructs_45only, database34_allstructs_45only, database35_allstructs_45only,\n",
    "    database36_allstructs_45only, database37_allstructs_45only, database38_allstructs_45only,\n",
    "    database39_allstructs_45only, database40_allstructs_45only, database41_allstructs_45only,\n",
    "    database42_allstructs_45only, database43_allstructs_45only, database44_allstructs_45only,\n",
    "    database45_allstructs_45only, database46_allstructs_45only, database47_allstructs_45only,\n",
    "    database48_allstructs_45only\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    for seq, (temp, structs) in dataset.items():\n",
    "        if temp is not None:\n",
    "            combined_data[seq] = (temp, structs)\n",
    "\n",
    "combined_data2 = {}\n",
    "for i, j in combined_data.items():\n",
    "    if len(i) == len(j[1][-1]):\n",
    "        combined_data2[i] = j\n",
    "\n",
    "combined_data = combined_data2\n",
    "\n",
    "# Verify combined data size after filtering\n",
    "print(f\"Total size of combined dataset after filtering: {len(combined_data)}\")\n",
    "\n",
    "# Prepare data for train-test split\n",
    "sequences = list(combined_data.keys())\n",
    "labels = list(combined_data.values())\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% test)\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(\n",
    "    sequences, labels, test_size=0.001, random_state=42\n",
    ")\n",
    "\n",
    "# Create train and test sets as dictionaries\n",
    "train_set = {seq: label for seq, label in zip(train_sequences, train_labels)}\n",
    "test_set = {seq: label for seq, label in zip(test_sequences, test_labels)}\n",
    "\n",
    "# Display the split summary\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18845b5-4f8e-42fb-aace-c5a264d0b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n",
    "top_structures = [train_set[seq][1] for seq in dna_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23140db8-0bd2-48b5-a756-4a48cfa6d3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGGGGGATACATGTTTCTTATATAGAGTACGTGACGTGCCCTTTT',\n",
       " 'TCCTGGCGGTTCAAGGATACGATGCCTGCCTTCATTTTTGAGCGA',\n",
       " 'AAGCACTGCCTTCTCCTTATAACAACTATGTGTTATGTCTGTTTA',\n",
       " 'TATCTCAAACCACGGCTTTTCAACAAAATTGTGACGACATGCGCC',\n",
       " 'AGCGTAGTGGAGGTAGAAGTCTTTAAGGCGATCATCTTATCATCA',\n",
       " 'GTTAAGTATTGTCTCAGTAGACATGGTAGTACGCGTGGGATGAGG',\n",
       " 'CTGGCATTCTGTTGCCGAGCCCATTGGTGCATCGTCGTGACAGGG',\n",
       " 'GGTAGACGATACAGAGCTCGAATTCTGCTATGCTGGGACGCTCTG',\n",
       " 'GTAGCGAGAAGCTAAATGGCCCGAAACGTCTAGGAGTGTCCGGGC',\n",
       " 'CGGTGCGTCGGAGGATTGGGATCACTATCCATACGGGGGCTAATT']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b0f2fef-8766-4b31-9e5d-52bd39902ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['((((.....(((((.(((.....)))..))))).....))))...',\n",
       "  '..(((.((.(((((.(((.....)))..)))))..)).)))....'],\n",
       " ['.((....))....(((........))).....((....)).....',\n",
       "  '.(((.........)))................((....)).....',\n",
       "  '....((((..............)))).((..(((....)))))..',\n",
       "  '....(((......(((........))))))..((....)).....',\n",
       "  '....(((((.((........))..)).)))..((....)).....',\n",
       "  '....((((..............))))......((....)).....',\n",
       "  '....((((((.............))).)))..((....)).....',\n",
       "  '....(((((..((.........)).)))))..((....)).....'],\n",
       " ['.((............)).((((((......)))))).........',\n",
       "  '.((.........))....((((((......)))))).........',\n",
       "  '(((......)))......((((((......)))))).........',\n",
       "  '..((...)).........((((((......)))))).........'],\n",
       " ['......(((........)))..(((....)))..((.....))..',\n",
       "  '....................(((.....)))...((.....))..',\n",
       "  '..........((((..((((....)))).)))).((.....))..',\n",
       "  '......................(((....)))..((.....))..'],\n",
       " ['................((....)).....(((......)))....',\n",
       "  '...............((.(((.....)))..))............',\n",
       "  '..............(((.................)))........',\n",
       "  '..(.....).....((....)).......(((......)))....',\n",
       "  '................(((................))).......',\n",
       "  '..............((....)).......(((.........))).',\n",
       "  '..(((......................)))...............',\n",
       "  '..(...).......((....)).......(((......)))....',\n",
       "  '..............((....))..(((........))).......',\n",
       "  '..............((....)).......(((......)))....'],\n",
       " ['...((...))((((....)))).......................',\n",
       "  '..........((((....))))...((...)).............',\n",
       "  '..........((((....)))).........(.........)...',\n",
       "  '.....(((((((((....))))).....)))).............',\n",
       "  '..........((((....))))........(....).........',\n",
       "  '..........((((....))))...........((.....))...',\n",
       "  '..........((((....)))).......................'],\n",
       " ['..((((......)))).........(...)...((....))....',\n",
       "  '..((((......))))..((........)).....(......)..',\n",
       "  '((((((......)))).))..............((....))....',\n",
       "  '........((((((((((((........)).)))..)))))))..',\n",
       "  '..((((......))))...(((.(...............)..)))',\n",
       "  '..((((......)))).....((..............))......',\n",
       "  '........((((...((((((....)))......)))..))))..',\n",
       "  '..((((......))))...(((.....((...........)))))',\n",
       "  '..(((.............)))............((....))....',\n",
       "  '..((((......))))..((........))..(((....)).)..',\n",
       "  '..((((......))))...(((..((.(((......))).)))))',\n",
       "  '..((((......))))...(((..((..............)))))',\n",
       "  '..((((......))))...((....))....((.....)).....',\n",
       "  '..((((......)))).....((....))....((....))....',\n",
       "  '..((((......))))...((....))..((......))......',\n",
       "  '..((((......))))...(((....................)))',\n",
       "  '..((((......))))...((....))......((....))....',\n",
       "  '..((((......))))..((........))...((....))....'],\n",
       " ['.(((.....)))..(((..............)))...........',\n",
       "  '......(((........)))...........((.(...)))....',\n",
       "  '...........((.(((.........))).)).............',\n",
       "  '...........((((........))))....((.(...)))....',\n",
       "  '...........((((((..(...((.((...)).))..)))))))',\n",
       "  '.(((.....)))..(((.........)))..((.(...)))....',\n",
       "  '...........((((((((.................)).))))))',\n",
       "  '...........((((((.......(.((...)).)....))))))',\n",
       "  '...........((((((......................))))))'],\n",
       " ['..(((.....))).....((((((....)...........)))))',\n",
       "  '......((...)).....(((((..((..........)).)))))',\n",
       "  '(((((.....))))..).(((((..((..........)).)))))',\n",
       "  '..(((.....))).....(((((..((....(....))).)))))',\n",
       "  '..(((.....))).....(((((..........(.....))))))',\n",
       "  '..(((.....))).....(((((..((..(.....).)).)))))',\n",
       "  '..(((.....))).....(((((..((..........)).)))))'],\n",
       " ['......(((....)))..((((....))))...............',\n",
       "  '....((.(((..((((..(.....).))))...)))..)).....',\n",
       "  '.............(((....))).....((.....))........',\n",
       "  '....((.(((..((((((....))..))))...)))..)).....',\n",
       "  '((...))...........((((....))))...............',\n",
       "  '....((.(((..((((..........))))...)))..)).....',\n",
       "  '.....(((.(((.(((....)))....)))..)))..........',\n",
       "  '.....(((.(((...............)))..)))..........',\n",
       "  '........(...).....((((....))))...............',\n",
       "  '((......))........((((....))))...............',\n",
       "  '..................((((....))))...............']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_structures[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57cdfc1c-f97a-446a-9b51-04d3017a6c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Number of sequences in dna_sequences:  777256\n",
      "Sample weights stats:\n",
      "Min: 0.1343396008014679, Max: 0.3759748339653015, Mean: 0.22687213122844696\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.utils as nn_utils\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 45\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "num_shared_transformer_blocks = 12\n",
    "num_task_transformer_blocks = 6\n",
    "dropout_rate = 0.2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# One-hot encoding functions\n",
    "def one_hot_encode_sequence(seq):\n",
    "    mapping = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "    encoded = np.zeros((len(seq), 4), dtype=np.float32)\n",
    "    for i, base in enumerate(seq):\n",
    "        encoded[i, mapping[base]] = 1\n",
    "    return encoded\n",
    "\n",
    "def one_hot_encode_structure(structure):\n",
    "    structure_mapping = {'.': 0, '(': 1, ')': 2}\n",
    "    encoded = np.zeros((len(structure), 3), dtype=np.float32)\n",
    "    for i, char in enumerate(structure):\n",
    "        encoded[i, structure_mapping[char]] = 1\n",
    "    return encoded\n",
    "\n",
    "# Assume train_set is already defined\n",
    "dna_sequences = [seq for seq in train_set.keys() if len(seq) == 45]\n",
    "print(\"Number of sequences in dna_sequences: \", len(dna_sequences))\n",
    "top_structures = [train_set[seq][1] for seq in dna_sequences]\n",
    "\n",
    "# One-hot encode DNA sequences\n",
    "encoded_sequences = [one_hot_encode_sequence(seq) for seq in dna_sequences]\n",
    "\n",
    "# One-hot encode structures using the most favorable structure\n",
    "encoded_structures = [one_hot_encode_structure(structs[-1]) for structs in top_structures]\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(np.array(encoded_sequences), dtype=torch.float32)\n",
    "y_struct = torch.tensor(np.array(encoded_structures), dtype=torch.float32)\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_struct_train, y_struct_val = train_test_split(X, y_struct, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\"\n",
    "class_counts = torch.tensor(\n",
    "    [sum(struct.count(char) for struct in [\"\".join(top_struct) for top_struct in top_structures]) for char in \".()\"], \n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Ensure no division by zero\n",
    "total_count = class_counts.sum()\n",
    "if total_count == 0 or any(class_counts == 0):\n",
    "    raise ValueError(\"Class counts are invalid, resulting in division by zero.\")\n",
    "\n",
    "# Compute class weights (Inverse frequency weighting)\n",
    "class_weights = total_count / (class_counts + 1e-5)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.clamp(class_weights, min=0)  # Ensure non-negative weights\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "# Create weighted sampler for the training set\n",
    "sample_weights = []\n",
    "for y in y_struct_train:\n",
    "    # Convert one-hot encoded structure to class indices\n",
    "    valid_indices = torch.argmax(y, dim=1).long()  # Extract class indices (e.g., 0, 1, 2 for '.', '(', ')')\n",
    "    weight = [class_weights[class_idx].item() for class_idx in valid_indices]\n",
    "    sample_weights.append(sum(weight) / len(weight))  # Average weight for the sequence\n",
    "\n",
    "# Convert to tensor and validate\n",
    "sample_weights = torch.tensor(sample_weights, dtype=torch.float32)\n",
    "sample_weights = torch.nan_to_num(sample_weights, nan=1.0, posinf=1.0, neginf=1.0)  # Replace NaN/infs with default value\n",
    "sample_weights = torch.clamp(sample_weights, min=0)  # Ensure weights are non-negative\"\"\"\n",
    "\n",
    "class_weights = torch.load(\"class_weights_only45s.pt\").to(device)\n",
    "sample_weights = torch.load(\"sample_weights_only45s.pt\").to(device)\n",
    "\n",
    "\n",
    "# Debugging\n",
    "print(\"Sample weights stats:\")\n",
    "print(f\"Min: {sample_weights.min()}, Max: {sample_weights.max()}, Mean: {sample_weights.mean()}\")\n",
    "assert torch.all(sample_weights >= 0), \"Sample weights contain negative values!\"\n",
    "assert not torch.any(torch.isnan(sample_weights)), \"Sample weights contain NaN values!\"\n",
    "\n",
    "# Create sampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_struct_train)\n",
    "val_dataset = TensorDataset(X_val, y_struct_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04f965f5-1330-4772-8776-d457d9a96807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn.utils as nn_utils\n",
    "\n",
    "class TransformerEncoderBlockWithPairingAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.2, sequence_length=45):\n",
    "        super(TransformerEncoderBlockWithPairingAttention, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.pairing_bias = nn.Parameter(torch.randn(sequence_length, sequence_length))\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        q, k, v = x, x, x\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (q.size(-1) ** 0.5)\n",
    "        seq_len = q.size(1)\n",
    "        pairing_bias_resized = self.pairing_bias[:seq_len, :seq_len]\n",
    "        pairing_bias_resized = pairing_bias_resized.unsqueeze(0).expand(x.size(0), -1, -1).to(x.device)\n",
    "        attn_scores = attn_scores + pairing_bias_resized\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        paired_attn_output = torch.matmul(attn_weights, v)\n",
    "        x = x + self.dropout1(attn_output + paired_attn_output)\n",
    "        x = self.layernorm1(x)\n",
    "        x = x + self.dropout2(self.ffn(x))\n",
    "        x = self.layernorm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StructurePredictor(nn.Module):\n",
    "    def __init__(self, sequence_length, embedding_dim, num_heads, ff_dim, num_shared_blocks, num_task_blocks):\n",
    "        super(StructurePredictor, self).__init__()\n",
    "        self.embedding_layer = nn.Linear(4, embedding_dim)\n",
    "        self.positional_encoding = self.create_sinusoidal_positional_encoding(sequence_length, embedding_dim)\n",
    "        self.shared_transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=sequence_length)\n",
    "            for _ in range(num_shared_blocks)\n",
    "        ])\n",
    "        self.struct_transformer_blocks = nn.ModuleList([\n",
    "            TransformerEncoderBlockWithPairingAttention(embedding_dim, num_heads, ff_dim, sequence_length=sequence_length)\n",
    "            for _ in range(num_task_blocks)\n",
    "        ])\n",
    "        self.structure_head = nn.Sequential(\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "            nn.Linear(embedding_dim, 3)\n",
    "        )\n",
    "\n",
    "    def create_sinusoidal_positional_encoding(self, seq_len, d_model):\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pos_enc = torch.zeros(seq_len, d_model)\n",
    "        pos_enc[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pos_enc[:, 1::2] = torch.cos(pos * div_term)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device \n",
    "        positional_encoding = self.positional_encoding.to(device)\n",
    "\n",
    "        # Map one-hot input to embedding space\n",
    "        x = self.embedding_layer(x)\n",
    "\n",
    "        # Combine embedded input with positional encoding\n",
    "        x = x + positional_encoding\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Shared Transformer blocks\n",
    "        for block in self.shared_transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Task-specific Transformer blocks\n",
    "        for block in self.struct_transformer_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Output layers\n",
    "        output = self.structure_head(x.permute(1, 0, 2))\n",
    "        return output\n",
    "\n",
    "\n",
    "class RewardedThermodynamicallyBalancedCategoricalCrossEntropy(nn.Module):\n",
    "    def __init__(self, weights, pairing_penalty=0.2, thermo_penalty=0.3, specificity_reward=0.05):\n",
    "        super(RewardedThermodynamicallyBalancedCategoricalCrossEntropy, self).__init__()\n",
    "        self.weights = weights\n",
    "        self.pairing_penalty = pairing_penalty\n",
    "        self.thermo_penalty = thermo_penalty\n",
    "        self.specificity_reward = specificity_reward\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Mask valid indices\n",
    "        mask = (y_true.sum(dim=-1) != 0)\n",
    "        y_pred_masked = y_pred[mask]\n",
    "        y_true_masked = y_true[mask]\n",
    "\n",
    "        # Compute weighted categorical cross-entropy\n",
    "        log_probs = F.log_softmax(y_pred_masked, dim=-1)\n",
    "        loss = -torch.sum(self.weights * y_true_masked * log_probs, dim=-1).mean()\n",
    "\n",
    "        # Compute pairing imbalance penalty\n",
    "        pred_labels = torch.argmax(y_pred_masked, dim=-1)\n",
    "        true_labels = torch.argmax(y_true_masked, dim=-1)\n",
    "        open_count = (pred_labels == 1).sum().float()\n",
    "        close_count = (pred_labels == 2).sum().float()\n",
    "        imbalance_penalty = self.pairing_penalty * torch.abs(open_count - close_count)\n",
    "\n",
    "        # Compute thermodynamic penalty for mismatches\n",
    "        mismatch_penalty = ((pred_labels == 1) & (true_labels == 2)).sum().float() * self.thermo_penalty\n",
    "\n",
    "        # Compute specificity reward for correct pairings\n",
    "        correct_pairings = ((pred_labels == true_labels) & ((true_labels == 1) | (true_labels == 2))).sum().float()\n",
    "        specificity_reward = self.specificity_reward * correct_pairings\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = loss + imbalance_penalty + mismatch_penalty - specificity_reward\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate model and loss function\n",
    "model = StructurePredictor(sequence_length, embedding_dim, num_heads, ff_dim, num_shared_transformer_blocks, num_task_transformer_blocks).to(device)\n",
    "loss_fn_struct = RewardedThermodynamicallyBalancedCategoricalCrossEntropy(class_weights)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n",
    "\n",
    "# Training loop with early stopping and metrics\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 100\n",
    "patience_counter = 0\n",
    "\n",
    "def calculate_class_metrics(y_true, y_pred, num_classes=3):\n",
    "    metrics = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        tp = ((y_pred == class_idx) & (y_true == class_idx)).sum().item()\n",
    "        fp = ((y_pred == class_idx) & (y_true != class_idx)).sum().item()\n",
    "        fn = ((y_pred != class_idx) & (y_true == class_idx)).sum().item()\n",
    "        precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "        recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "        metrics[class_idx] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "    return metrics\n",
    "\n",
    "def print_validation_metrics(val_metrics, printer=True):\n",
    "    total_f1 = 0\n",
    "    num_classes = len(val_metrics)\n",
    "    \n",
    "    # Print metrics for each class\n",
    "    for cls, metrics in val_metrics.items():\n",
    "        if printer==True:\n",
    "            print(f\"Class {cls} - Precision: {metrics['precision']:.4f}, \"\n",
    "                  f\"Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1']:.4f}\")\n",
    "        total_f1 += metrics['f1']\n",
    "    \n",
    "    # Calculate the average F1 score\n",
    "    avg_f1 = total_f1 / num_classes if num_classes > 0 else 0.0\n",
    "    \n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7d5519d-6457-4ca3-8de0-3a1d750ad502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Save sample weights\\ntorch.save(sample_weights, \"sample_weights_onehot.pt\")\\n\\n# Load sample weights\\ntorch.save(class_weights, \"class_weights_onehot.pt\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Save sample weights\n",
    "torch.save(sample_weights, \"sample_weights_onehot.pt\")\n",
    "\n",
    "# Load sample weights\n",
    "torch.save(class_weights, \"class_weights_onehot.pt\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f7a4014-35f5-4431-b51c-f349c75001ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run this cell if the gradients explode!\n",
    "\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.00020, steps_per_epoch=len(train_dataloader), epochs=200)\n",
    "model_path = \"12-2-onehotenc.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab17b5c5-554d-4d1d-8070-50167f6a4b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 14.2667, Accuracy: 0.3046, F1: 0.3105\n",
      "Average Gradient Norms per Layer:\n",
      "embedding_layer: 0.0011\n",
      "shared_transformer_blocks: 0.0017\n",
      "struct_transformer_blocks: 0.0033\n",
      "structure_head: 0.0258\n",
      "Class 0 - Precision: 0.8805, Recall: 0.0869, F1-Score: 0.1581\n",
      "Class 1 - Precision: 0.2481, Recall: 0.7026, F1-Score: 0.3668\n",
      "Class 2 - Precision: 0.2497, Recall: 0.6917, F1-Score: 0.3669\n",
      "Validation Loss: 8.0006, Accuracy: 0.2904, F1: 0.2973\n",
      "\n",
      "\n",
      "Epoch 2, Training Loss: 8.4255, Accuracy: 0.4404, F1: 0.4283\n",
      "Average Gradient Norms per Layer:\n",
      "embedding_layer: 0.0015\n",
      "shared_transformer_blocks: 0.0016\n",
      "struct_transformer_blocks: 0.0034\n",
      "structure_head: 0.0264\n",
      "Class 0 - Precision: 0.8014, Recall: 0.3297, F1-Score: 0.4672\n",
      "Class 1 - Precision: 0.2878, Recall: 0.6382, F1-Score: 0.3967\n",
      "Class 2 - Precision: 0.2889, Recall: 0.6169, F1-Score: 0.3935\n",
      "Validation Loss: 7.4892, Accuracy: 0.4290, F1: 0.4192\n",
      "\n",
      "\n",
      "Epoch 3, Training Loss: 8.1210, Accuracy: 0.4520, F1: 0.4395\n",
      "Average Gradient Norms per Layer:\n",
      "embedding_layer: 0.0015\n",
      "shared_transformer_blocks: 0.0018\n",
      "struct_transformer_blocks: 0.0048\n",
      "structure_head: 0.0283\n",
      "Class 0 - Precision: 0.8378, Recall: 0.3095, F1-Score: 0.4520\n",
      "Class 1 - Precision: 0.2905, Recall: 0.6522, F1-Score: 0.4019\n",
      "Class 2 - Precision: 0.2923, Recall: 0.6649, F1-Score: 0.4061\n",
      "Validation Loss: 4.5862, Accuracy: 0.4259, F1: 0.4200\n",
      "\n",
      "\n",
      "Epoch 4, Training Loss: 7.1863, Accuracy: 0.4467, F1: 0.4378\n",
      "Average Gradient Norms per Layer:\n",
      "embedding_layer: 0.0016\n",
      "shared_transformer_blocks: 0.0020\n",
      "struct_transformer_blocks: 0.0056\n",
      "structure_head: 0.0304\n",
      "Class 0 - Precision: 0.8438, Recall: 0.2961, F1-Score: 0.4383\n",
      "Class 1 - Precision: 0.2925, Recall: 0.6793, F1-Score: 0.4089\n",
      "Class 2 - Precision: 0.2914, Recall: 0.6619, F1-Score: 0.4046\n",
      "Validation Loss: 6.3854, Accuracy: 0.4210, F1: 0.4173\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     layer_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Use only the first part as layer name\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mnorm()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_grad_norms:\n\u001b[0;32m     34\u001b[0m         layer_grad_norms[layer_name] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, train_accuracies = [], [], []\n",
    "val_losses, val_f1s, val_accuracies = [], [], []\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    layer_grad_norms = {}\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    for batch_X, batch_y_struct in train_dataloader:\n",
    "        batch_X, batch_y_struct = batch_X.to(device), batch_y_struct.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred_struct = model(batch_X)\n",
    "\n",
    "        # Loss computation\n",
    "        loss = loss_fn_struct(pred_struct, batch_y_struct)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        nn.utils.clip_grad_value_(model.parameters(), clip_value=0.1)\n",
    "\n",
    "        # Accumulate gradient norms by layer\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                layer_name = name.split('.')[0]\n",
    "                grad_norm = param.grad.norm().item()\n",
    "                if layer_name not in layer_grad_norms:\n",
    "                    layer_grad_norms[layer_name] = []\n",
    "                layer_grad_norms[layer_name].append(grad_norm)\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Convert predictions to class indices for metrics\n",
    "        y_pred = torch.argmax(pred_struct, dim=-1)\n",
    "        y_true = torch.argmax(batch_y_struct, dim=-1)\n",
    "\n",
    "        all_true_labels.append(y_true.cpu())\n",
    "        all_predicted_labels.append(y_pred.cpu())\n",
    "\n",
    "        # Calculate correct predictions\n",
    "        correct_preds += (y_pred == y_true).sum().item()\n",
    "        total_preds += y_true.numel()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    all_true_labels = torch.cat(all_true_labels)\n",
    "    all_predicted_labels = torch.cat(all_predicted_labels)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    train_metrics = calculate_class_metrics(all_true_labels, all_predicted_labels)\n",
    "    avg_train_f1 = print_validation_metrics(train_metrics, printer=False)\n",
    "    accuracy = correct_preds / total_preds\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "    train_f1s.append(avg_train_f1)\n",
    "\n",
    "    # Calculate average gradient norms per layer\n",
    "    avg_layer_grad_norms = {layer: sum(norms) / len(norms) for layer, norms in layer_grad_norms.items()}\n",
    "\n",
    "    # Print epoch summary for training\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, F1: {avg_train_f1:.4f}\")\n",
    "    print(\"Average Gradient Norms per Layer:\")\n",
    "    for layer, avg_norm in avg_layer_grad_norms.items():\n",
    "        print(f\"{layer}: {avg_norm:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y_struct in val_dataloader:\n",
    "            val_X, val_y_struct = val_X.to(device), val_y_struct.to(device)\n",
    "            val_pred_struct = model(val_X)\n",
    "\n",
    "            # Loss computation\n",
    "            val_loss += loss_fn_struct(val_pred_struct, val_y_struct).item()\n",
    "\n",
    "            # Convert predictions to class indices for metrics\n",
    "            y_pred = torch.argmax(val_pred_struct, dim=-1)\n",
    "            y_true = torch.argmax(val_y_struct, dim=-1)\n",
    "\n",
    "            all_y_true.append(y_true)\n",
    "            all_y_pred.append(y_pred)\n",
    "\n",
    "            # Calculate correct predictions\n",
    "            correct_preds += (y_pred == y_true).sum().item()\n",
    "            total_preds += y_true.numel()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    all_y_true = torch.cat(all_y_true)\n",
    "    all_y_pred = torch.cat(all_y_pred)\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_metrics = calculate_class_metrics(all_y_true, all_y_pred)\n",
    "    avg_val_f1 = print_validation_metrics(val_metrics)\n",
    "    val_accuracy = correct_preds / total_preds\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1s.append(avg_val_f1)\n",
    "\n",
    "    # Print validation summary\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {avg_val_f1:.4f}\")\n",
    "\n",
    "    # Check for early stopping and save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"12-2_onehotenc.pth\")\n",
    "        print(f\"Best model saved with validation loss: {avg_val_loss:.4f}\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9410a4f5-0e05-4f32-83df-fea89d7f560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save lists to CSV files with filenames related to the model name\n",
    "model_name = \"12-2_onehotenc\"\n",
    "\n",
    "# Create a dictionary for each list to be saved\n",
    "data_to_save = {\n",
    "    f\"{model_name}_train_losses1.csv\": train_losses,\n",
    "    f\"{model_name}_train_f1s1.csv\": train_f1s,\n",
    "    f\"{model_name}_train_accuracies1.csv\": train_accuracies,\n",
    "    f\"{model_name}_val_losses1.csv\": val_losses,\n",
    "    f\"{model_name}_val_f1s1.csv\": val_f1s,\n",
    "    f\"{model_name}_val_accuracies1.csv\": val_accuracies,\n",
    "}\n",
    "\n",
    "# Loop through each list and save it as a CSV\n",
    "for filename, data_list in data_to_save.items():\n",
    "    df = pd.DataFrame(data_list, columns=[filename.split('_')[-1].split('.')[0]])\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "print(\"Metrics saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a20c6d2-8632-48b3-bc5b-d1050d25028f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '12-2_onehotenc.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12-2_onehotenc.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Function to decode structure\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '12-2_onehotenc.pth'"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = \"12-2_onehotenc.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Function to decode structure\n",
    "def decode_structure(encoded):\n",
    "    structure_mapping = {0: '.', 1: '(', 2: ')', 3: '-'}\n",
    "    return ''.join([structure_mapping[code.item()] for code in encoded])\n",
    "\n",
    "def enforce_symmetry_and_minimum_distance(pred_structure, min_distance=3):\n",
    "    stack = []\n",
    "    for i, char in enumerate(pred_structure):\n",
    "        if char == '(':\n",
    "            stack.append(i)\n",
    "        elif char == ')':\n",
    "            if stack:\n",
    "                opening_index = stack.pop()\n",
    "                if i - opening_index - 1 < min_distance or ''.join(pred_structure[opening_index + 1:i]).count('.') < min_distance:\n",
    "                    pred_structure[opening_index] = '.'\n",
    "                    pred_structure[i] = '.'\n",
    "    for i in stack:\n",
    "        pred_structure[i] = '.'\n",
    "    return pred_structure\n",
    "\n",
    "\n",
    "# Pick some sequences from the validation set\n",
    "num_test_sequences = 50\n",
    "val_sequences = X_val[:num_test_sequences]\n",
    "val_structures = y_struct_val[:num_test_sequences]\n",
    "\n",
    "# Run predictions and compare with ground truth\n",
    "print(\"Testing the model on some sequences from the validation set:\")\n",
    "with torch.no_grad():\n",
    "    for i, (sequence, true_structure) in enumerate(zip(val_sequences, val_structures)):\n",
    "        sequence = sequence.unsqueeze(0).to(device)\n",
    "        true_structure = true_structure.to(device)\n",
    "        \n",
    "        # Predict structure\n",
    "        pred_structure_logits = model(sequence, true_structure.unsqueeze(0))\n",
    "        pred_structure = torch.argmax(pred_structure_logits.view(-1, 3), dim=-1)\n",
    "        \n",
    "        # Decode sequence and structures\n",
    "        decoded_sequence = ''.join([list('ATCG-')[x.item()] for x in sequence[0]])\n",
    "        decoded_true_structure = decode_structure(true_structure)\n",
    "        decoded_pred_structure = decode_structure(pred_structure)\n",
    "\n",
    "        # Enforce symmetry and minimum distance rule\n",
    "        decoded_pred_structure = enforce_symmetry_and_minimum_distance(list(decoded_pred_structure))\n",
    "\n",
    "        # Print results\n",
    "        print(f\"\\nSequence {i + 1}: {decoded_sequence}\")\n",
    "        print(f\"True Structure:    {decoded_true_structure}\")\n",
    "        print(f\"Predicted Structure: {''.join(decoded_pred_structure)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8234b9-44fd-40d8-81d5-5e9dcd909e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
